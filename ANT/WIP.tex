\documentclass[12pt,oneside]{book}
\usepackage{import}
\input{preamble}

%=================%
%  Title & Index  %
%=================%
\title{Analytic Number Theory}
\author{Henry Twiss}
\date{2024}
\makeindex

\begin{document}
\maketitle
\pagestyle{empty}
\addtocontents{toc}{\protect\thispagestyle{empty}}
\tableofcontents
\setcounter{page}{0}

 \part{Half-integral Weight Modular Forms \& Trace Formulas}
  \chapter{Half-integral Weight Modular Forms}
    \todo{Introduction}
    \section{The Quadratic Theta Function \texorpdfstring{$\t(z)$}{O(z)}}
      We begin with a special modular form of half-integral weight. This requires working over at least the level $4$ congruence subgroup $\G_{0}(4)$. One can work over $\G_{0}(N)$ with $N \equiv 0 \pmod{4}$, but we will not need this level of generality. Our goal is to prove the existance of a modular form of half-integral weight on $\G_{0}(4)\backslash\H$. We first establish a generating set for $\G_{0}(N)$ which will simplify many calculations soon to come:

      \begin{proposition}\label{prop:Hecke_congruence_generator}
        \[
          \G_{0}(N) = \left\<\begin{pmatrix} 1 & 0 \\ N & 1 \end{pmatrix},\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}\right\>.
        \]
      \end{proposition}
      \begin{proof}
        Set $R_{N}$ and $T$ to be the first and second generators respectively. It is clear that they both belong to $\G_{0}(N)$ so it suffices to show that for any $\g = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \G_{0}(4)$, we have $\g \in \<R_{N},T\>$. Observe
        \[
          \g R_{N} = \begin{pmatrix} a & b \\ c & d \end{pmatrix}R_{N} = \begin{pmatrix} a+Nb & b \\ c+Nd & d \end{pmatrix} \quad \text{and} \quad \g T^{n} = \begin{pmatrix} a & b \\ c & d \end{pmatrix}T^{n} = \begin{pmatrix} a & b+na \\ c & d+nc \end{pmatrix},
        \]
        where $n \in \Z$. Note that $R_{N}$ and $T^{n}$ are acting on the right. In particular, $R_{N}$ adds an $N$ multiple of the lower right entry to the lower right entry and $T^{n}$ adds an $n$ multiple of the lower left entry to the lower right entry. We will now prove $\g \in \<R_{N},T\>$ by showing that the inverse is in $\<R_{N},T\>$. If $|c| = 0$ then $\g$ is the identity since $\det(\g) = 1$ so suppose $|c| \neq 0$. By Euclidean division, $d = qc+r$ for some $q \in \Z$ and $|r| < |c|$. Then
        \[
          \g T^{-q} = \begin{pmatrix} a & b-qa \\ c & d-qc \end{pmatrix} = \begin{pmatrix} a & b-qa \\ c & r \end{pmatrix}.
        \]
        By Euclidean division again, write $c = q'Nr+r'$ with $|r'| < |Nr|$. Then
        \[
          \g T^{-q}R_{N}^{-q'} = \begin{pmatrix} a & b-qa \\ c & r \end{pmatrix}R_{N}^{-q'} = \begin{pmatrix} a-q'N(b-qa) & b-qa \\ c-q'Nr & r \end{pmatrix} =  \begin{pmatrix} a-q'N(b-qa) & b-qa \\ r' & r \end{pmatrix}.
        \]
        This is a matrix whose lower right entry is smaller than the lower left entry we began with in norm. Moreover, the lower left entry no larger than the lower left entry we began with in norm and at the same time is less than an $N$ multiple of the lower right entry in norm. In other words, the lower left entry is never increasing in norm, the lower right entry is always decreasing in norm, and up to an $N$ multiple the lower right entry bounds the size of the lower left entry. Therefore if we repeatedly apply this procedure, it must terminate with one of the lower entries vanishing. Since the lower left entry is always equivalent to $0$ modulo $4$, and $\det(\g) = 1$, we must have that the lower right entry is always equivaent to $1$ or $3$ modulo $4$. Therefore the lower left entry must vanish. But then we have reached the identity matrix and so we have show $\g$ has an inverse in $\<R_{N},T\>$.
      \end{proof}

      In particular \cref{prop:Hecke_congruence_generator} implies,

      \[
        \G_{0}(4) = \left\<\begin{pmatrix} 1 & 0 \\ 4 & 1 \end{pmatrix},\begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix}\right\>.
      \]

      Now we are ready to investigate modular forms on $\G_{0}(4)\backslash\H$. The modular form we are interested in is the \textbf{quadratic theta function}\index{quadratic theta function} $\t(z)$ defined by
      \[
          \t(z) = \sum_{n \in \Z}e^{2\pi in^{2}z},
      \]
      for $z \in \H$. The relation to Jacobi's theta function is
      \begin{equation}\label{equ:Jacobi_theta_relation}
          \t\left(\frac{iz}{2}\right) = \vt(z),
      \end{equation}
      and thus $\t(z)$ converges absolutely uniformly on compacta because $\vt(z)$ does. In short, $\t(z)$ is holomorphic on $\H$. It turns out that $\t(z)$ is a modular form of weight $\frac{1}{2}$ and level $4$ on $\G_{0}(4)\backslash\H$. However, the factor of modularity with be fundamentally different that in the integral weight case. The factor of modularity is often referred to as the \textbf{theta multiplier}\index{theta multiplier}, defined by
      \[
          j(\g,z) = \e(\g)\sqrt{cz+d} = \legendre{c}{d}\e_{d}^{-1}\sqrt{cz+d},
      \]
      where we take the principal branch of the square root and where $\legendre{c}{d}$ is the Jacobi symbol ($d$ is necessarily odd since $\det(\g) = 1$ and $c \equiv 0 \tmod{4}$) with the stipulations $\legendre{c}{d} = \legendre{-c}{-d}$ (so that we may take $d > 0$) and $\legendre{0}{d} = 1$. This last requirement is simply $\legendre{0}{1} = 1$ because if $c = 0$ then $\det(\g) = 1$ implies $d = \pm 1$. Also, we recall that $\e_{d} = 1,i$ depending on if $d \equiv 1,3 \tmod{4}$ as $d$ is odd. We have already noted that $\t(z)$ is holomorphic on $\H$. We now show that it is modular on $\G_{0}(4)\backslash\H$ with factor of modularity given by the theta multiplier:

      \begin{proposition}
        Let $\g = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \G_{0}(4)$. Then for $z \in \H$,
        \[
          \t(\g z) = \legendre{c}{d}\e_{d}^{-1}\sqrt{cz+d}\t(z),
        \]
        where we take the principal branch of the square root.
      \end{proposition}
      \begin{proof}
        We first argue that
        \[
          \G_{0}(4) = \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}^{-1} \G(2) \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}.
        \]
        This is seen by using our generating set for $\G_{0}(4)$ and observing that the matrices
        \[
          \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 1 & 0 \\ 4 & 1 \end{pmatrix} \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}^{-1} = \begin{pmatrix} 1 & 0 \\ 2 & 1 \end{pmatrix} \quad \text{and} \quad \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 1 & 1 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}^{-1} = \begin{pmatrix} 1 & 2 \\ 0 & 1 \end{pmatrix},
        \]
        generate $\G(2)$. Now define $\wtilde{\t}(z) = \theta\left(\frac{z}{2}\right)$. Since $\theta$ is $1$-periodic, $\wtilde{\t}$ is $2$-periodic. Moreover for any $\g \in \G_{0}(4)$, let $\eta = \begin{pmatrix} a & 2b \\ \frac{c}{2} & d\end{pmatrix} \in \G(2)$ so that
        \[
          \g = \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}^{-1} \eta \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}.
        \]
        Then we have
        \[
          \t(\g z) = \wtilde{\t}\left(2\begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}^{-1} \eta \begin{pmatrix} 2 & 0 \\ 0 & 1 \end{pmatrix}z\right) = \wtilde{\t}(2\eta z).
        \]
        Therefore we are reduced to proving an analogous transformation law for $\wtilde{\t}(\eta z)$. Now let $w = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}z = -\frac{1}{z}$. Then by \cref{equ:Jacobi_theta_relation} and the transformation formula for Jacobi's theta function, we see that
        \[
          \wtilde{\t}(w) = \vt(-iw) = \frac{1}{\sqrt{-iw}}\vt\left(-\frac{1}{iw}\right) = \frac{1}{\sqrt{-iw}}\wtilde{\t}\left(\frac{-1}{w}\right) = \sqrt{\frac{z}{i}}\wtilde{\t}(z).
        \]
        Since $\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}^{2} = I$, if we let $\eta' = \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix}$ where the entries are defined by
        \[
          \eta' = \eta\begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix} = \begin{pmatrix} 2b & -a \\ d & -\frac{c}{2} \end{pmatrix},
        \]
        then
        \[
          \wtilde{\t}(\eta z) = \wtilde{\t}\left(\eta \begin{pmatrix} 0 & -1 \\ 0 & 1 \end{pmatrix}^{2} z\right) = \wtilde{\t}(\eta'w).
        \]
        So it further suffices to prove a transformation law for $\wtilde{\t}(\eta'w)$. First observe
        \[
          \eta' w = \frac{a'w+b'}{c'w+d'} = \frac{c'(a'w+b')}{c'(c'w+d')} = \frac{a'c'w+a'd'-1}{c'(c'w+d')} = \frac{a'(c'w+d')-1}{c'(c'w+d')} = \frac{a'}{c'}-\frac{1}{c'(c'w+d')},
        \]
        Thus
        \begin{align*}
          \wtilde{\t}(\eta'w) &= \sum_{n \in \Z}e^{\pi in^{2}\eta'w} \\
          &= \sum_{n \in \Z}e^{\pi in^{2}\left(\frac{a'}{c'}-\frac{1}{c'(c'w+d')}\right)} \\
          &= \sum_{n \in \Z}e^{\frac{2\pi in^{2}\frac{a'}{2}}{c'}}e^{-\frac{\pi in^{2}}{c'(c'w+d')}} \\
          &= \sum_{\a \tmod{c'}}e^{\frac{2\pi in^{2}\frac{a'}{2}}{c'}}\sum_{m \in \Z}e^{-\frac{\pi i(c'm+\a)^{2}}{c'(c'w+d')}} \\
          &= \sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}\sum_{m \in \Z}e^{-\frac{\pi ic'\left(m+\frac{\a}{c'}\right)^{2}}{c'w+d'}},
        \end{align*}
        where the second to last equality follows because $e^{\frac{2\pi in^{2}\frac{a'}{2}}{c'}}$ only depends on $n$ modulo $c'$. Indeed, $\frac{a'}{2} = b$ is an integer and writing $n = mc'+\a$ with $\a$ taken modulo $c'$ we have $(mc'+\a)^{2} \equiv \a^{2} \tmod{c'}$. By the identity theorem, it suffices to prove a transformation formula for $\wtilde{\t}(\eta w)$ on a set containing a limit point. We will prove this on a vertical line in $\H$ and we take $w = \frac{iy-d'}{c'}$ for $y$ real with $y > 0$. Now set $f(x) = e^{-\frac{\pi ic'\left(x+\frac{\a}{c'}\right)^{2}}{c'w+d'}}$. Then $f(x)$ is a Schwarz function. We compute its Fourier transform:
        \[
          \hat{f}(t) = \int_{-\infty}^{\infty}f(x)e^{-2\pi itx}\,dx = \int_{-\infty}^{\infty}e^{-\frac{\pi ic'\left(x+\frac{\a}{c'}\right)^{2}}{c'w+d'}}e^{-2\pi itx}\,dx = \int_{-\infty}^{\infty}e^{-\pi\left(\frac{ic'\left(x+\frac{\a}{c'}\right)^{2}}{c'w+d'}+2itx\right)}\,dx.
        \]
        Making the change of variables $x \to \sqrt{-\frac{i(c'w+d')}{c'}}x-\frac{\a}{c'}$, the last integral above becomes
        \[
          \sqrt{-\frac{i(c'w+d')}{c'}}e^{\frac{2\pi i t\a}{c'}}\int_{-\infty}^{\infty}e^{-\pi\left(x^{2}+2itx\sqrt{-\frac{i(c'w+d')}{c'}}\right)}\,dx = \sqrt{\frac{c'w+d'}{ic'}}e^{\frac{2\pi i t\a}{c'}}\int_{-\infty}^{\infty}e^{-\pi\left(x^{2}+2itx\sqrt{-\frac{i(c'w+d')}{c'}}\right)}\,dx.
        \]
        Complete the square in the exponent by observing
        \[
          -\pi\left(x^{2}+2itx\sqrt{-\frac{i(c'w+d')}{c'}}\right) = -\pi\left(\left(x+it\sqrt{-\frac{i(c'w+d')}{c'}}\right)^{2}-\frac{it^{2}(c'w+d')}{c'}\right),
        \]
        where we take the principal branch of the square root. Taking exponentials, this implies that the previous integral is equal to
        \[
          \sqrt{\frac{c'w+d'}{ic'}}e^{\frac{2\pi i t\a}{c'}}e^{\frac{\pi it^{2}(c'w+d')}{c'}}\int_{-\infty}^{\infty}e^{-\pi\left(x+it\sqrt{-\frac{i(c'w+d')}{c'}}\right)^{2}}\,dx.
        \]
        The change of variables $x \to x-it\sqrt{-\frac{i(c'w+d')}{c'}}$ is valid by viewing the integral as a complex integral, noting that the integrand is entire as a complex function, and shifting the line of integration. After the change of variables we get
        \[
          \sqrt{\frac{c'w+d'}{ic'}}e^{\frac{2\pi i t\a}{c'}}e^{\frac{\pi it^{2}(c'w+d')}{c'}}\int_{-\infty}^{\infty}e^{-\pi x^{2}}\,dx = \sqrt{\frac{c'w+d'}{ic'}}e^{\frac{2\pi i t\a}{c'}}e^{\frac{\pi it^{2}(c'w+d')}{c'}},
        \]
        where the last equality follows because the integral above is $1$ since it is the Gaussian integral. The Poisson summation formula then gives the second equality in the following chain:
        \begin{align*}
          \wtilde{\t}(\eta' w) &= \sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}\sum_{m \in \Z}f(m) \\
          &= \sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}\sum_{t \in \Z}\hat{f}(t) \\
          &= \sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}\sum_{t \in \Z}\sqrt{\frac{c'w+d'}{ic'}}e^{\frac{2\pi i t\a}{c'}}e^{\frac{\pi it^{2}(c'w+d')}{c'}} \\
          &= \sqrt{\frac{c'w+d'}{ic'}}\sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}\sum_{t \in \Z}e^{\frac{2\pi i t\a}{c'}}e^{\frac{\pi it^{2}(c'w+d')}{c'}} \\
          &= \sqrt{\frac{c'w+d'}{ic'}}\sum_{t \in \Z}e^{\frac{\pi it^{2}(c'w+d')}{c'}}\sum_{\a \tmod{c'}}e^{\frac{2\pi i\a^{2}\frac{a'}{2}}{c'}}e^{\frac{2\pi i t\a}{c'}} \\
          &= \sqrt{\frac{c'w+d'}{ic'}}\sum_{t \in \Z}e^{\pi it^{2}w}\sum_{\a \tmod{c'}}e^{\frac{2\pi i\left(\a^{2}\frac{a'}{2}+t\a+t^{2}\frac{d'}{2}\right)}{c'}}.
        \end{align*}
        Now $\det(\eta') = 1$ implies $a'd' \equiv 1 \tmod{c'}$. In other words, $a'$ and $d'$ are inverses modulo $c'$. Then $\frac{a'}{2}(\a+td')^{2} \equiv \a^{2}\frac{a'}{2}+t\a+t^{2}\frac{d'}{2} \tmod{c'}$, so the double sum above is equivalent to
        \[
          \sqrt{\frac{c'w+d'}{ic'}}\sum_{t \in \Z}e^{\pi it^{2}w}\sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{a'}{2}(\a+td')^{2}}{c'}}.
        \]
        For fixed $t$, $\a \to \a-td'$ is a bijection on $\Z/c'\Z$ so we have
        \[
          \sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{a'}{2}(\a+td')^{2}}{c'}} = \sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{a'}{2}\a^{2}}{c'}} = \sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{a'}{2}(\a d')^{2}}{c'}} = \sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{d'}{2}\a^{2}}{c'}} = g\left(\frac{d'}{2},c'\right).
        \]
        where the second equality follows because $\det(\eta') = 1$ implies $(d',c') = 1$ so that $\a \to \a d'$ is a bijection on $\Z/c'\Z$, and the third equality holds because $a'd' \equiv 1 \tmod{c'}$. The quadratic Gauss sum evaluates to
        \[
          g\left(\frac{d'}{2},c'\right) = \legendre{\frac{d'}{2}}{c'}\e_{c'}\sqrt{c'}.
        \]
        Therefore
        \[
          \sqrt{\frac{c'w+d'}{ic'}}\sum_{t \in \Z}e^{\pi it^{2}w}\sum_{\a \tmod{c'}}e^{\frac{2\pi i\frac{a'}{2}(\a+td')^{2}}{c'}} = \legendre{\frac{d'}{2}}{c'}\e_{c'}\sqrt{c'}\sqrt{\frac{c'w+d'}{ic'}}\sum_{t \in \Z}e^{\pi it^{2}w} = \legendre{\frac{d'}{2}}{c'}\e_{c'}\sqrt{\frac{c'w+d'}{i}}\wtilde{\t}(w).
        \]
        So all together we have shown
        \[
          \wtilde{\t}(\eta' w) = \legendre{\frac{d'}{2}}{c'}\e_{c'}\sqrt{\frac{c'w+d'}{i}}\wtilde{\t}(w).
        \]
        Rewriting in terms of $\eta$, and noting that $\legendre{\frac{c}{4}}{d} = \legendre{c}{d}$ because $4$ is a square and $c \equiv 0 \tmod{4}$, gives
        \[
          \wtilde{\t}(\eta z) = \legendre{c}{d}\legendre{-1}{d}\e_{d}\sqrt{\frac{dz-\frac{c}{2}}{i}}\wtilde{\t}(z).
        \]
        By changing variables $z \to 2z$ and rewriting in terms of $\t(z)$, we find
        \[
          \t(\g z) = \legendre{c}{d}\legendre{-1}{d}\e_{d}\sqrt{\frac{-\left(\frac{d}{2z}+\frac{c}{2}\right)}{i}}\sqrt{\frac{2z}{i}}\t(z) = \legendre{c}{d}\e_{d}^{-1}\sqrt{cz+d}\t(z),
        \]
        where the last equality follows because $\legendre{-1}{d} = 1,-1$ depending on if $d \equiv 1,3 \tmod{4}$ so that $\legendre{-1}{d}\e_{d} = \e_{d}^{-1}$. This finishes the proof.
      \end{proof}

      To complete the verification that $\t(z)$ is a modular form is to check holomorphy at the cusps. There are three cusps of $\G_{0}(4)$ and they are $\infty$, $0$, and $\frac{1}{2}$ respectively. To see this, observe that the corresponding orbits are
      \begin{align*}
        \G_{0}(4)\infty &= \left\{\frac{a}{c}:(a,c) = 1, c \equiv 0 \tmod{4} \right\} \\
        \G_{0}(4)0 &= \left\{\frac{b}{d}:(b,d) = 1, d \equiv 1,3 \tmod{4} \right\} \\
        \G_{0}(4)\frac{1}{2} &= \left\{\frac{b}{d}:(b,d) = 1, d \equiv 2 \tmod{4} \right\},
      \end{align*}
      and every element of $\Q \cup \{\infty\}$ belongs to one of these three sets. We only need to verify holomorphy on a set of scaling matrices, so let us choose the scaling matrices $\s_{\infty} = I$, $\s_{0} = \begin{pmatrix} 0 & -1 \\ 1 & 0 \end{pmatrix}$, and $\s_{\frac{1}{2}} = \begin{pmatrix} 1 & 1 \\ 2 & 3 \end{pmatrix}$ for the three cusps respectively. For the cusp at $\infty$, just observe
      \[
        \lim_{\Im(z) \to \infty}|\t(z)| \le \lim_{z \to \infty}\sum_{n \in \Z}|e^{2\pi inz}| = \lim_{y \to \infty}\sum_{n \in \Z}e^{-2\pi ny} \le \sum_{n \in \Z}e^{-2\pi n} = \vt(2).
      \]
      For the cusps at $\infty$ and $\frac{1}{2}$, we have
      \[
        \t(\s_{0} z) = \sum_{n \in \Z}e^{-\frac{2\pi in}{z}} = \sum_{n \in \Z}e^{-\frac{2\pi in\conj{z}}{|z|^{2}}} \quad \text{and} \quad \t(\s_{\frac{1}{2}} z) = \sum_{n \in \Z}e^{\frac{2\pi in(z+1)}{2z+3}} = \sum_{n \in \Z}e^{\frac{2\pi in(2|z|+3z+2\conj{z}+1)}{|2z+3|^{2}}},
      \]
      and a completely analogous computation shows that these series are also bounded as $\Im(z) \to \infty$. Therefore $\t(z)$ is holomorphic at the cusps and all together is a modular form on $\G_{0}(4)\backslash\H$ of weight $\frac{1}{2}$. We package this into a theorem:

      \begin{theorem}
        The quadratic theta function
        \[
            \t(z) = \sum_{n \in \Z}e^{2\pi in^{2}z},
        \]
        is a modular form of of weight $\frac{1}{2}$ on $\G_{0}(4)\backslash\H$ with factor of modularity given by the theta multiplier:
        \[
          \t(\g z) = \legendre{c}{d}\e_{d}^{-1}\sqrt{cz+d}\t(z),
        \]
        where $\g = \begin{pmatrix} a & b \\ c & d \end{pmatrix} \in \G_{0}(4)$.
      \end{theorem}

      $\t(z)$ is an example of a half-integral weight modular form. If we consider the squared quadratic theta function $\t^{2}(z)$, then we immediately see
      \[
        \t^{2}(\g z) = \legendre{-1}{d}(cz+d)\t^{2}(z),
      \]
      with $\g = \begin{pmatrix} a & b \\ c & d \end{pmatrix}$. So $\t^{2}(z)$ is a modular form of weight $1$ on $\G_{0}(4)$ with nontrivial nebentypus. This is our first example of a modular form of odd integral weight. The most surprising fact about $\t(z)$ and $\t^{2}(z)$ is that their factors of modularity contain (modified) Jacobi symbols. The reason this is surprising is that these symbols have nothing to do with the congruence subgroup $\G_{0}(4)$, and so the modular forms are ``seeing more'' than what the congruence subgroup is controlling. We would then hope that additional interesting arithmetic information could be deduced from these theta functions. For example, as a consequence of the cocycle relation we get an interesting identity:

      \begin{corollary}
        Let $\g = \begin{pmatrix} a & b \\ c & d \end{pmatrix},\g' = \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix} \in \G_{0}(4)$. Then
        \[
          \legendre{c'a+d'c}{c'b+d'd}\e_{d'd}^{-1} = \legendre{c'}{d'}\legendre{c}{d}\e_{d'}^{-1}\e_{d}^{-1}
        \]
      \end{corollary}
      \begin{proof}
        By modularity of $\t(z)$, $j(\g,z)$ satisfies the coycycle condition which implies
        \[
          \legendre{c'a+d'c}{c'b+d'd}\e_{c'b+d'd}^{-1} = \legendre{c'}{d'}\legendre{c}{d}\e_{d'}^{-1}\e_{d}^{-1}
        \]
        But $\e_{c'b+d'd}$ depends on $c'b+d'd$ modulo $4$ and we have $c'b+d'd \equiv d'd \tmod{4}$ because $c \equiv 0 \tmod{4}$.
      \end{proof}
    \section{\todo{The Quadratic Eisenstein Series}}
      Having discussed the existance of half-integral weight modular forms, namely the quadratic theta function $\t(z)$, we will now build an Eisenstein series on $\G_{0}(4)\backslash\H$ that is naturally associated to $\t(z)$ using the theta multiplier. Actually, this Eisenstein series will turn out to contain a lot of information. It will recover $\t(z)$ as a residue, and the Fourier coefficients will be intimately connected to the theory of multiple Dirichlet series. The existance of this Eisenstein series was originally studied by Maass (see \todo{maass1937konstruktion}), then Shimura (see \todo{shimura1973modular,shimura1975holomorphy}), and more recently Goldfeld and Hoffstein (see \todo{hoffstein1985eisenstein}). However, it is Goldfeld and Hoffstein who are creditied with connecting these Fourier coefficients to the birth of multiple Dirichlet series which will form the bulk of the latter part of this text. We define the \textbf{quadratic Eisenstein series}\index{quadratic Eisenstein series} $E_{\infty}^{(2)}(z,s)$ on $\G_{0}(4)\backslash\H$ to be
      \[
        E_{\infty}^{(2)}(z,s) = \sum_{\g \in \Gamma_{\infty}\backslash\G_{0}(4)}j(\g,z)^{-1}\Im(\g z)^{s}.
      \]
      We first show $E_{\infty}^{(2)}(z,s)$ is absolutely uniformly convergent on compacta for $\Re(s) > \frac{3}{4}$ provided $z \in \H$. To see this, the Bruhat decomposition applied to $\G_{\infty}\backslash\G_{0}(4)$ implies
      \[
        |E_{\infty}^{(2)}(z,s)| \le \sum_{(c,d) \in \Z^{2}-\{\mathbf{0}\}}\frac{\Im(z)^{s}}{|cz+d|^{2s+\frac{1}{2}}}.
      \]
      This latter series is absolutely uniformly convergent on compacta for $\Re(s) > \frac{3}{4}$ and $z \in \H$ by \todo{$prop:general_lattice_sum_convergence_for_two_variables$}. Since the terms in the sum are holomorphic on this region, it follows that $E_{\infty}^{(2)}(z,s)$ is too. It's quick to verify that $E_{\infty}^{(2)}(z,s)$ is modular in the $z$-variable:
      \begin{align*}
        E_{\infty}^{(2)}(\g z,s) &= \sum_{\g' \in \Gamma_{\infty}\backslash\G_{0}(4)}j(\g',\g z)^{-1}\Im(\g'\g z)^{s} \\
        &= \sum_{\g' \in \Gamma_{\infty}\backslash\G_{0}(4)}\left(\frac{j(\g'\g,z)}{j(\g,z)}\right)^{-1}\Im(\g'\g z)^{s} && \text{cocycle condition} \\
        &= j(\g,z)\sum_{\g' \in \Gamma_{\infty}\backslash\G_{0}(4)}j(\g'\g,z)^{-1}\Im(\g'\g z)^{s} \\
        &= j(\g,z)\sum_{\g' \in \Gamma_{\infty}\backslash\G_{0}(4)}j(\g',z)^{-1}\Im(\g'z)^{s} \\
        &= j(\g,z)E_{\infty}^{(2)}(z,s),
      \end{align*}
      where the second to last equality follows because $\g' \to \g'\g^{-1}$ is a bijection on $\G$. Lastly, we verify that $E_{\infty}^{(2)}(z,s)$ is of moderate growth at the cusps provided $\Re(s) > \frac{3}{4}$. Let $\s_{\mf{a}}$ be a scaling matrix for the cusp $\mf{a}$ and write $\s_{\mf{a}}^{-1} = \begin{pmatrix} a' & b' \\ c' & d' \end{pmatrix}$. Then
      \[
        |E_{\infty}^{(2)}(\s_{\mf{a}}z,s)| \le \sum_{(c,d) \in \Z^{2}-\{\mathbf{0}\}}\frac{\Im(\s_{\mf{a}}z)^{s}}{|c\s_{\mf{a}}z+d|^{2s+\frac{1}{2}}} = \frac{1}{|c'z+d'|^{2s}}\sum_{(c,d) \in \Z^{2}-\{\mathbf{0}\}}\frac{\Im(z)^{s}}{|c\s_{\mf{a}}z+d|^{2s+\frac{1}{2}}}.
      \]
      We can now proceed as for Maass forms to conclude that $E_{\infty}^{(2)}(z,s)$ is of moderate growth at the cusps. By now, it should be clear that the behavior of the quadratic theta series is quite interesting. We have shown that for fixed $\Re(s) > \frac{3}{4}$, $E_{\infty}^{(2)}(z,s)$ behaves like a half integral weight modular form in the $z$-variable. However, in the $s$-variable $E_{\infty}^{(2)}(z,s)$ has moderate growth at the cusps like a Maass form, but is not automorphic. It is useful to think of the $s$-variable as the variable of an $L$-function. That is, $E_{\infty}^{(2)}(z,s)$ should act like a modular form in the $z$-variable and like an $L$-function in the $s$-variable. Indeed, we will show that $E_{\infty}^{(2)}(z,s)$ exhibits meromorphic continuation in the $s$-variable and a functional equation as $s \to 1-s$.
    \section{\todo{The Shimura Correspondence}}
\part{Modern Theory}
   \section{The Ramanujan Conjecture on Average}
      Let $f$ be a weight $k$ primitive Hecke eigenform with Fourier coefficients $\l_{f}(n)$. As an application of the Rankin-Selberg method, it is possible to show the slightly weaker result that $\l_{f}(n) \ll n^{\frac{k-1}{2}+\e}$ holds on average, for any $\e > 0$, without assuming the Ramanujan conjecture. To see this, for any real $X$, we have
      \begin{equation}\label{equ:Ramanujan_conjecture_on_average_1}
        \left(\sum_{n \le X}\l_{f}(n)\right)^{2} \le X\sum_{n \le X}|\l_{f}(n)|^{2},
      \end{equation}
      by Cauchy-Schwarz. Now, without assuming the Ramanujan conjecture, the Rankin-Selberg square $L(s,f \ox f)$ is absolutely convergent for $\Re(s) > \frac{3}{2}$. So while the critical strip is wider, it still admits meromorphic continuation to $\C$ with a simple pole at $s = 1$. By Landau's theorem, the abscissa of absolute convergence of $L(s,f \ox f)$, and hence $L(s,f \x f)$ too, is $1$ so that $\sum_{n \le X}|\l_{f}(n)|^{2} \ll_{\e} X^{k+\e}$. Substiuting this bound into \cref{equ:Ramanujan_conjecture_on_average_1}, we obtain
      \[
        \left(\sum_{n \le X}\l_{f}(n)\right)^{2} \ll_{\e} X^{k-1+\e}.
      \]
      Upon taking the square root,
      \[
        \sum_{n \le X}\l_{f}(n) \ll_{\e} X^{\frac{k-1}{2}+\e},
      \]
      for some $\e > 0$. This bound should be compared with the implication $\l_{f}(n) \ll n^{\frac{k-1}{2}+\e}$ that follows from the Ramanujan conjecture.
    \section{Theta Functions}
        At this point we have shown that the Riemann zeta function, Dirichlet $L$-functions, and Hecke $L$-functions, all admit meromorphic continuation to $\C$ and satisfy a functional equation of shape $s \to 1-s$. In all of these cases, the idea was to find an integral representation that is meromorphic on $\C$ and symmetric under $s \to 1-s$. There is a unifying idea which encompasses all of these cases and more. That idea is lifting a transformation law of a theta function by taking its Mellin transform. To connect the Mellin transform to $L$-functions, we require theta functions. For our purposes, a \textbf{theta function}\index{theta function} is an infinite series indexed over a lattice whose terms are exponentials. We also require the theta function to be holomorphic on $\C$ and admit exponential decay to zero near $\infty$. Each of the $L$-functions we have studied, excluding the Rankin-Selberg convolution, is associated to a theta function:
        \begin{align*}
        \z(s) &\longleftrightarrow \vt(s) = \sum_{n \in \Z}e^{-\pi n^{2}s}, \\
        L(s,\chi) &\longleftrightarrow \vt_{\chi}(s) = \sum_{n \in \Z}\chi(n)n^{\mf{a}}e^{-\pi n^{2}s}, \\
        L(s,f) &\longleftrightarrow f(iy) = \sum_{n \in \Z}a(n)e^{-\pi ny},
        \end{align*}
        where in the last case we note that $a(n) = 0$ for $n < 0$ because $f$ is holomorphic and $a(0) = 0$ because $f$ is cuspidal. Now on the one hand, all of these theta functions can be written as sums over $n \ge 1$: the first two cases by symmetry of the $n$ and $-n$ terms and the last case by the above comment. Isolating the subsum over $n \ge 1$ and specializing at a nonnegative real variable we get $\w(x)$, $\w_{\chi}(x)$, and $f(iy)$ respectively. Taking the Mellin transform of these latter functions reproduced the associated $L$-functions up to gamma factors. We then decomposed the Mellin transform into two pieces and symmetrized the result by using transformation laws for the theta functions. The most difficult part of all of these arguments was cooking up the theta function that corresponds to the $L$-function solely from its representation as a Dirichlet series in the region of absolute convergence. For the Riemann zeta function this was essentially ``Riemann's insight'': start with the Gamma function, apply a change of variables, and sum over all $n \ge 1$ to obtain the Mellin transform of the corresponding theta function. For $L(s,\chi)$, the argument is adapted from that of Riemann although it is more complicated since the associated theta function depends on if the character $\chi$ is even or odd (odd being the more difficult case). On the other hand, $L(s,f)$ has the advantage that the theta function is easy to guess outright. It's the Fourier series of $f$ along the upper-half imaginary axis. Moreover, it comes equip with the necessary transformation law via the modularity of $f$. In more general settings, we need to know something algebraic or geometric about a given theta function in order to deduce a transformation law that can be used to prove meromorphic continuation and a functional equation for its associated $L$-function. In general the method of meromorphic continuation is as follows:

        \begin{method}
        Suppose we are given an $L$-series
        \[
            L(s,f) = \sum_{n \ge 1}\frac{a(n)}{n^{s}},
        \]
        that is locally absolutely uniformly convergent for $\Re(s) > 1$, and there is a theta function $\w_{f}(s)$ such that $L(s,f)$ is approximately the Mellin transform of $\w_{f}(s)$. That is, 
        \[
            L(s,f) \approx \int_{0}^{\infty}\w_{f}(s)x^{s}\,\frac{dx}{x}.
        \]
        Also suppose $\w_{f}(s)$ satisfies a tranformation law approximately of the form
        \[
            \w_{f}(x) \approx \w_{f}\left(\frac{1}{q(f)^{2}x}\right),
        \]
        for some constant $q(f)$ (that will be the conductor of the $L$-function). Then $L(s,f)$ admits meromorphic continuation to $\C$. To acomplish this, first decompose the Mellin transform into two pieces:
        \[
            \int_{0}^{\infty}\w_{f}(x)x^{s}\,\frac{dx}{x} = \int_{0}^{\frac{1}{q(f)}}\w_{f}(x)x^{s}\,\frac{dx}{x}+\int_{\frac{1}{q(f)}}^{\infty}\w_{f}(x)x^{s}\,\frac{dx}{x}.
        \]
        Then apply the transformation law for $\w_{f}(s)$ to the first piece and symmetrize the result to obtain an integral representation of the following form:
        \[
            L(s,f) \approx \text{polar factor}+\int_{\frac{1}{q(f)}}^{\infty}\w_{f}(x)x^{1-s}\,\frac{dx}{x}+\int_{\frac{1}{q(f)}}^{\infty}\w_{f}(x)x^{s}\,\frac{dx}{x},
        \]
        where the polar factor will appear if there is a constant term in $\w_{f}(x)$. Both of the integrals will be locally absolutely uniformly bounded by the exponential decay of $\w_{f}(x)$. Since the integral representation is symmetric under $s \to 1-s$, this gives the meromorphic continuation to $\C$.
        \end{method}

  \end{document}