\chapter{Analytic Preliminaries}
  We prove some useful summation formulas, discuss two complex analytic techniques, introduce the Fourier transform and the Poisson summation formula, the Mellin transform, and various properties of the Gamma function.
  \section{Summation Formulas}
    Summation formulas are important because they often allow for a difficult to estimate sums to be replaced with one that is much easier to estimate. In fact, the most useful summation formulas replace a discrete sum with an integral of a continuous function. This allows for much more precise estimation of the original sum. We first setup some notation. If $(a_{n})_{n \ge 1}$ is a sequence of complex numbers for every $X \ge 0$ let
    \[
        A(X) = \sum_{n \le X}a_{n}.
    \]
    Note that $A(X) = 0$ unless $X \ge 1$. The most well-known summation formula is (classical) \textbf{summation by parts}\index{summation by parts}:

    \begin{theorem*}[Summation by parts, classical]
      Let $(a_{n})_{n \ge 1}$ and $(b_{n})_{n \ge 1}$ be two sequences of complex numbers. Then for any positive integers $N$ and $M$ with $1 \le M \le N$, we have
      \[
        \sum_{M \le n \le N}a_{n}(b_{n+1}-b_{n}) = (a_{N+1}b_{N+1}-a_{M}b_{M})-\sum_{M \le n \le N}b_{n+1}(a_{n+1}-a_{n}).
      \]
    \end{theorem*}
    \begin{proof}
      It is equivalent to prove that
      \[
        \sum_{M \le n \le N}a_{n}(b_{n+1}-b_{n})+\sum_{M \le n \le N}b_{n+1}(a_{n+1}-a_{n}) = (a_{N+1}b_{N+1}-a_{M}b_{M}).
      \]
      This is just a computation:
      \begin{align*}
        \sum_{M \le n \le N}a_{n}(b_{n+1}-b_{n})+\sum_{M \le n \le N}b_{n+1}(a_{n+1}-a_{n}) &= \sum_{M \le n \le N}a_{n}b_{n+1}-a_{n}b_{n}+a_{n+1}b_{n+1}-a_{n}b_{n+1} \\
        &= \sum_{M \le n \le N}a_{n+1}b_{n+1}-a_{n}b_{n} \\
        &= a_{N+1}b_{N+1}-a_{M}b_{M}.
      \end{align*}
    \end{proof}

    Replacing the sequences $(a_{n})_{n \ge 1}$ and $(b_{n})_{n \ge 1}$ with $(b_{n})_{n \ge 0}$ and $(A(n-1))_{n \ge 1}$ respectively gives (partial sum) \textbf{summation by parts}\index{summation by parts}:

    \begin{theorem*}[Summation by parts, partial sum]
      Let $(a_{n})_{n \ge 1}$ and $(b_{n})_{n \ge 0}$ be two sequences of complex numbers. Then for any integers $M$ and $N$ with $0 \le M \le N$, we have
      \[
        \sum_{M+1 \le n \le N}a_{n}b_{n} = A(N)b_{N}-A(M)b_{M}-\sum_{M \le n \le N-1}A(n)(b_{n+1}-b_{n}).
      \]
    \end{theorem*}
    \begin{proof}
      Classical summation by parts gives
      \[
        \sum_{M+1 \le n \le N}b_{n}(A(n)-A(n-1)) = A(N)b_{N+1}-A(M)b_{M+1}-\sum_{M+1 \le n \le N}A(n)(b_{n+1}-b_{n}).
      \]
      As $A(n)-A(n-1) = a_{n}$, this formula becomes
      \[
        \sum_{M+1 \le n \le N}a_{n}b_{n} = A(N)b_{N+1}-A(M)b_{M+1}-\sum_{M+1 \le n \le N}A(n)(b_{n+1}-b_{n}),
      \]
      which we can rewrite as
      \[
        \sum_{M+1 \le n \le N}a_{n}b_{n} = A(N)b_{N}-A(M)b_{M}-\sum_{M \le n \le N-1}A(n)(b_{n+1}-b_{n}).
      \]
      This is the desired formula so the proof is complete.
    \end{proof}
    
    Taking $M = 0$ gives a useful corollary:

    \begin{corollary}\label{cor:partial_sum_summation_by_parts_corollary}
      Let $(a_{n})_{n \ge 1}$ and $(b_{n})_{n \ge 0}$ be two sequences of complex numbers. Then for any positive integer $N \ge 1$, we have
      \[
        \sum_{n \le N}a_{n}b_{n} = A(N)b_{N}-\sum_{n \le N-1}A(n)(b_{n+1}-b_{n}).
      \]
    \end{corollary}
    \begin{proof}
      Taking $M = 0$ in partial sum summation by parts and observing that $A(M) = 0$ gives the result.
    \end{proof}
    
    Both classical and partial sum summation by parts give ways of rewriting finite sums. If we want to express a finite sum in the form of an integral, we need to do more work. One of the most well-known results of this type is known as \textbf{Abel's summation formula}\index{Abel's summation formula}:

    \begin{theorem*}[Abel's summation formula]
      Let $(a_{n})_{n \ge 1}$ be a sequence of complex numbers. For any $X$ and $Y$ with $0 \le X < Y$ and continuously differentiable function $\phi:[X,Y] \to \C$, we have
      \[
        \sum_{X < n \le Y}a_{n}\phi(n) = A(Y)\phi(Y)-A(X)\phi(X)-\int_{X}^{Y}A(u)\phi'(u)\,du.
      \]
    \end{theorem*}
    \begin{proof}
      Let $M = \lfloor X \rfloor$ and $N = \lfloor Y \rfloor$ so that $0 \le M \le N$. Then $X < n \le Y$ if and only if $M+1 \le n \le N$, so that partial sum summation by parts gives
      \[
        \sum_{X < n \le Y}a_{n}\phi(n) = A(N)\phi(N)-A(M)\phi(M)-\sum_{M \le n \le N-1}A(n)(\phi(n+1)-\phi(n)).
      \]
      As $\phi$ is continuously differentiable, we can express the sum on the right-hand side as
      \begin{align*}
        \sum_{M \le n \le N-1}A(n)(\phi(n+1)-\phi(n)) &= \sum_{M \le n \le N-1}A(n)\int_{n}^{n+1}\phi'(u)\,du \\
        &= \sum_{M \le n \le N-1}\int_{n}^{n+1}A(u)\phi'(u)\,du \\
        &= \int_{M}^{N}A(u)\phi'(u)\,du,
      \end{align*}
      where in the second equality we have used that $A(u)$ is constant on the interval $[n,n+1)$ for every $n \ge 0$. Thus
      \[
        \sum_{X < n \le Y}a_{n}\phi(n) = A(N)\phi(N)-A(M)\phi(M)-\int_{M}^{N}A(u)\phi'(u)\,du.
      \]
      Using again the fact that $A(u)$ is constant on the interval $[n,n+1)$ for every $n \ge 0$, we can express the integral as
      \begin{align*}
        \int_{M}^{N}A(u)\phi'(u)\,du &= \int_{X}^{Y}A(u)\phi'(u)\,du+\int_{M}^{X}A(u)\phi'(u)\,du-\int_{N}^{Y}A(u)\phi'(u)\,du \\
        &= \int_{X}^{Y}A(u)\phi'(u)\,du+A(M)\int_{M}^{X}\phi'(u)\,du-A(N)\int_{N}^{Y}\phi'(u)\,du \\
        &= \int_{X}^{Y}A(u)\phi'(u)\,du+A(M)\phi(X)-A(M)\phi(M)-A(N)\phi(Y)+A(N)\phi(N) \\
        &= \int_{X}^{Y}A(u)\phi'(u)\,du+A(X)\phi(X)-A(M)\phi(M)-A(Y)\phi(Y)+A(N)\phi(N).
      \end{align*}
      Substituting this result gives 
      \[
        \sum_{X < n \le Y}a_{n}\phi(n) = A(Y)\phi(Y)-A(X)\phi(X)-\int_{X}^{Y}A(u)\phi'(u)\,du,
      \]
      which is the desired formula.
    \end{proof}

    There are also some useful corollaries. The first is when we sum every term up to $Y$:

    \begin{corollary}\label{cor:Abels_summation_formula_zero_version}
      Let $(a_{n})_{n \ge 1}$ be a sequence of complex numbers. For any $Y > 0$ and continuously differentiable function $\phi:(0,Y] \to \C$, we have
      \[
        \sum_{n \le Y}a_{n}\phi(n) = A(Y)\phi(Y)-\int_{1}^{Y}A(u)\phi'(u)\,du.
      \]
    \end{corollary}
    \begin{proof}
      This follows from Abel's summation formula upon letting $0 < X < 1$ and noting that $A(u) = 0$ on the interval $[0,1)$.
    \end{proof}
    
    The second corollary is useful as it extends Abel's summation formula to infinite sums:

    \begin{corollary}\label{cor:Abels_summation_formula_limit_version}
      Let $(a_{n})_{n \ge 1}$ be a sequence of complex numbers. For any $X \ge 0$ and continuously differentiable function $\phi:[X,\infty) \to \C$, we have
      \[
        \sum_{n > X}a_{n}\phi(n) = \lim_{Y \to \infty}A(Y)\phi(Y)-A(X)\phi(X)-\int_{X}^{\infty}A(u)\phi'(u)\,du.
      \]
    \end{corollary}
    \begin{proof}
      This follows from Abel's summation formula upon taking the limit as $Y \to \infty$.
    \end{proof}

    The last corollary is a combination of the former two:

    \begin{corollary}\label{cor:Abels_summation_formula_limit_version_specialization}
      Let $(a_{n})_{n \ge 1}$ be a sequence of complex numbers. For any continuously differentiable function $\phi:(0,\infty) \to \C$, we have
      \[
        \sum_{n \ge 1}a_{n}\phi(n) = \lim_{Y \to \infty}A(Y)\phi(Y)-\int_{1}^{\infty}A(u)\phi'(u)\,du.
      \]
    \end{corollary}
    \begin{proof}
       This follows from \cref{cor:Abels_summation_formula_zero_version} upon taking the limit as $Y \to \infty$.
    \end{proof}

    Abel's summation formula and its corollaries are immensely useful for approximating finite or infinite sums by integrals. In the special case where $a_{n} = 1$ for $n \ge 1$, we are really estimating the sum of a continuously differentiable function at integer values. We can very well use Abel's summation formula here, but it's possible to improve the result by appealing to integration by parts. If we do this, we obtain a result known as the \textbf{Euler-Maclaurin summation formula}\index{Euler-Maclaurin summation formula}:

    \begin{theorem*}[Euler-Maclaurin summation formula]
      For any $X$ and $Y$ with $0 \le X < Y$ and continuously differentiable function $\phi:[X,Y] \to \C$, we have
      \[
        \sum_{X < n \le Y}\phi(n) = \left(X-\lfloor X \rfloor-\frac{1}{2}\right)\phi(X)-\left(Y-\lfloor Y \rfloor-\frac{1}{2}\right)\phi(Y)+\int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du.
      \]
    \end{theorem*}
    \begin{proof}
      Let $M = \lfloor X \rfloor$ and $N = \lfloor Y \rfloor$ so that $0 \le M \le N$. Then $X < n \le Y$ if and only if $M+1 \le n \le N$, so that partial sum summation by parts gives
      \[
        \sum_{X < n \le Y}\phi(n) = N\phi(N)-M\phi(M)-\sum_{M \le n \le N-1}n(\phi(n+1)-\phi(n)).
      \]
      Now observe that
      \[
        \sum_{M \le n \le N-1}(n-M-1)(\phi(n+1)-\phi(n)) = (M+1)\phi(M)-(M+1)\phi(N)+\sum_{M \le n \le N-1}n(\phi(n+1)-\phi(n)),
      \]
      since the sum on the left-hand side telescopes. Using this identity to replace the sum above, we obtain
      \[
        \sum_{X < n \le Y}\phi(n) = (N-M-1)\phi(N)+\phi(M)-\sum_{M \le n \le N-1}(n-M-1)(\phi(n+1)-\phi(n)).
      \]
      As $\phi$ is continuously differentiable, we can express the sum on the right-hand side as
      \begin{align*}
       \sum_{M \le n \le N-1}(n-M-1)(\phi(n+1)-\phi(n)) &= \sum_{M \le n \le N-1}(n-M-1)\int_{n}^{n+1}\phi'(u)\,du \\
        &= \sum_{M \le n \le N-1}\int_{n}^{n+1}(\lfloor u \rfloor-M-1)\phi'(u)\,du \\
        &= \int_{M}^{N}(\lfloor u \rfloor-M-1)\phi'(u)\,du \\
        &= -(M+1)\int_{M}^{N}\phi'(u)\,du+\int_{M}^{N}\lfloor u \rfloor\phi'(u)\,du \\
        &= (M+1)\phi(M)-(M+1)\phi(N)+\int_{M}^{N}\lfloor u \rfloor\phi'(u)\,du,
      \end{align*}
      where in the second equality we have used that $\lfloor u \rfloor$ is constant on the interval $[n,n+1)$ for every $n \ge 0$. Thus
      \[
        \sum_{X < n \le Y}\phi(n) = N\phi(N)-M\phi(M)-\int_{M}^{N}\lfloor u \rfloor\phi'(u)\,du.
      \]
      We will continue to rewrite the right-hand side. Integration by parts shows that
      \[
        \int_{M}^{N}u\phi'(u)\,du = N\phi(N)-M\phi(M)-\int_{M}^{N}\phi(u)\,du,
      \]
      and therefore our previous identity becomes
      \begin{align*}
        \sum_{X < n \le Y}\phi(n) = \int_{M}^{N}\phi(u)+(u-\lfloor u \rfloor)\phi'(u)\,du.
      \end{align*}
      Using the identity
      \[
        \frac{\phi(N)-\phi(M)}{2} = \int_{M}^{N}\frac{1}{2}\phi'(u)\,du,
      \]
      we get
      \[
        \sum_{X < n \le Y}\phi(n) = \frac{\phi(N)-\phi(M)}{2}+\int_{M}^{N}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du.
      \]
      Using again that $\lfloor u \rfloor$ is constant on the interval $[n,n+1)$ for every $n \ge 0$, we can express the integral as
      \begin{align*}
        \int_{M}^{N}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du &= \int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du \\
        &+ \int_{M}^{X}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du \\
        &- \int_{N}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du \\
        &= \int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du \\
        &+M\phi(M)-M\phi(X)+\frac{\phi(M)-\phi(X)}{2}+\int_{M}^{X}\phi(u)+u\phi'(u)\,du \\
        &+N\phi(Y)-N\phi(N)+\frac{\phi(Y)-\phi(N)}{2}-\int_{N}^{Y}\phi(u)+u\phi'(u)\,du \\
        &= \int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du \\
        &+M\phi(M)-M\phi(X)+\frac{\phi(M)-\phi(X)}{2}+\int_{M}^{X}\phi(u)\,du+\int_{M}^{X}u\phi'(u)\,du \\
        &+N\phi(Y)-N\phi(N)+\frac{\phi(Y)-\phi(N)}{2}-\int_{N}^{Y}\phi(u)\,du-\int_{N}^{Y}u\phi'(u)\,du.
      \end{align*}
      Two more applications of integration by parts shows that
      \[
        \int_{M}^{X}u\phi'(u)\,du = X\phi(X)-M\phi(M)-\int_{M}^{X}\phi(u)\,du,
      \]
      and
      \[
        \int_{N}^{Y}u\phi'(u)\,du = Y\phi(Y)-N\phi(N)-\int_{N}^{Y}\phi(u)\,du,
      \]
      whence
      \begin{align*}
        \int_{M}^{N}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du &= \frac{\phi(M)-\phi(N)}{2}+\left(X-M-\frac{1}{2}\right)\phi(X)-\left(Y-N-\frac{1}{2}\right)\phi(Y) \\
        &+ \int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du.
      \end{align*}
      Substituting this result back into our formula above gives
      \[
        \sum_{X < n \le Y}\phi(n) = \left(X-M-\frac{1}{2}\right)\phi(X)-\left(Y-N-\frac{1}{2}\right)\phi(Y)+\int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du,
      \]
      which is equivalent to
      \[
        \sum_{X < n \le Y}\phi(n) = \left(X-\lfloor X \rfloor-\frac{1}{2}\right)\phi(X)-\left(Y-\lfloor Y \rfloor-\frac{1}{2}\right)\phi(Y)+\int_{X}^{Y}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du,
      \]
      since $M = \lfloor X \rfloor$ and $N = \lfloor Y \rfloor$, thus completing the proof.
    \end{proof}

    Like Abel's summation formula, there are some useful corollaries. The first one is in the special case where both $X$ and $Y$ are integers:

    \begin{corollary}\label{cor:Euler_Maclaurin_summation_formula_integer_version}
      For any integers $M$ and $N$ with $0 \le M < N$ and continuously differentiable function $\phi:[M,N] \to \C$, we have
      \[
        \sum_{M < n \le N}\phi(n) = \frac{\phi(M)-\phi(N)}{2}+\int_{M}^{N}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du.
      \]
    \end{corollary}
    \begin{proof}
      This follows immediately from the Euler-Maclaurin summation formula since $M-\lfloor M \rfloor = 0$ and $N-\lfloor N \rfloor = 0$.
    \end{proof}

    The second corollary deals with infinite sums:

    \begin{corollary}\label{cor:Euler_Maclaurin_summation_formula_integer_limit_version_specialization}
      For any integer $M \ge 0$ and continuously differentiable function $\phi:[M,\infty) \to \C$, we have
      \[
        \sum_{n > M}\phi(n) = \lim_{N \to \infty}\frac{\phi(M)-\phi(N)}{2}+\int_{M}^{\infty}\phi(u)+\left(u-\lfloor u \rfloor-\frac{1}{2}\right)\phi'(u)\,du.
      \]
    \end{corollary}
    \begin{proof}
      This follows from \cref{cor:Euler_Maclaurin_summation_formula_integer_version} upon taking the limit as $N \to \infty$.
    \end{proof} 
  \section{Complex Integration Techniques}
    Complex integrals are a core backbone of many number theory techniques. An extremely useful one is called \textbf{shifting the line of integration}\index{shifting the line of integration}:

    \begin{theorem*}[Shifting the line of integration]
      Suppose we are given an integral
      \[
        \int_{\Re(z) = a}f(z)\,dz \quad \text{or} \quad \int_{\Im(z) = a}f(z)\,dz,
      \]
      and some real $b$ with $b < a$ in the first case and $b > a$ in the second case. Suppose $f(z)$ is meromorphic on a strip bounded by the lines $\Re(z) = a,b$ or $\Im(z) = a,b$ and is holomorphic about the lines $\Re(z) = a,b$ or $\Im(z) = a,b$ respectively. Moreover, suppose $f(z) \to 0$ as $y \to \infty$ or $x \to \infty$ respectively. Then
      \[
        \int_{(a)}f(z)\,dz = \int_{(b)}f(z)\,dz+2\pi i\sum_{\rho \in P}\Res_{z = \rho}f(z),
      \]
      where $P$ is the set of poles inside of the strip bounded by the lines $\Re(z) = a,b$ or $\Im(z) = a,b$ respectively.
    \end{theorem*}
    \begin{proof}
      To collect these cases, let $(a)$ stand for the line $\Re(z) = a$ or $\Im(z) = a$ respectively with positive orientation. Let $R_{T}$ be a positively oriented rectangle of height or width $T$ and with its edges on $(a)$ or $(b)$ respectively. Consider the limit
      \[
        \lim_{T \to \infty}\int_{R_{T}}f(z)\,dz.
      \]
      On the one hand, the residue theorem implies the integral is a sum of a $2\pi i$ multiple of the residues $r_{i}$ in the rectangle $R_{T}$ and hence the limit is a $2\pi i$ multiple of the sum of the residues in the strip bounded by $(a)$ and $(b)$. On the other hand, the integral can be decomposed into a sum of four integrals along the edges of $R_{T}$ and by taking the limit, the edges other than $(a)$ and $(b)$ will tend to zero because $f(z) \to 0$ as $y \to \infty$ or $x \to \infty$ respectively. What remains in the limit is the difference between the integral along $(a)$ and $(b)$. So in total,
      \[
        \int_{(a)}f(z)\,dz = \int_{(b)}f(z)\,dz+2\pi i\sum_{\rho \in P}\Res_{z = \rho}f(z).
      \]
    \end{proof}

    A particular application of interest is when the integral in question is real and over the entire real line, the integrand is entire as a complex function, and one is trying to shift the line of integration of the complexified integral to $\Im(z) = a$. In this case, shifting the line of integration amounts to making the change of variables $x \mapsto x-ia$ without affecting the initial line of integration. The second integral technique we will use is when we are summing integrals over a group and is called the \textbf{unfolding/folding method}\index{unfolding/folding method}:

    \begin{theorem*}[Unfolding/folding method]
      Suppose $f(z)$ is holomorphic on some region $\W$. Moreover, suppose $G$ is a countable group acting by automorphisms on $\W$ and let $D$ and $F$ be regions such that
      \[
        D = \bigcup_{g \in G}gF,
      \]
      where the intersections $gF \cap hF$ are measure zero for all $g,h \in G$ with respect to some $G$-invariant measure $d\mu$. Then 
      \[
        \int_{F}\sum_{g \in G}f(g z)\,d\mu = \int_{D}f(z)\,d\mu,
      \]
      provided either side is absolutely convergent.
    \end{theorem*}
    \begin{proof}
      First suppose $\int_{F}\sum_{g \in G}f(g z)\,d\mu$ converges absolutely. By the Fubiniâ€“Tonelli theorem, we may interchange the sum and integral. Upon making the change of variables $z \mapsto g^{-1}z$, the invariance of $d\mu$ implies that the integral takes the form
      \[
        \sum_{g \in G}\int_{gF}f(z)\,d\mu.
      \]
      As $G$ is countable and the intersections $gF \cap hF$ are measure zero, the overlap in $\bigcup_{g \in G}gF$ is also measure zero. As $D = \bigcup_{g \in G}gF$, the result follows. Moreover, we can run the argument in reverse provided $\int_{D}f(z)\,d\mu$ converges absolutely. This completes the proof.
    \end{proof}

    In the unfolding/folding method, we refer to the going from the left-hand side to right-hand as \textbf{unfolding}\index{unfolding} and going from the right-hand to left-hand side as \textbf{folding}\index{folding}.
  \section{The Fourier Transform}
    The first type of integral transform we will need is the Fourier transform. Suppose $f(\mathbf{x})$ is absolutely integrable on $\R^{n}$. The \textbf{Fourier transform}\index{Fourier transform} $(\mc{F}f)(\boldsymbol{\xi})$ of $f(\mathbf{x})$ is defined by
    \[
      (\mc{F}f)(\boldsymbol{\xi}) = \int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}\>}\,d\mathbf{x},
    \]
    for $\boldsymbol{\xi} \in \R^{n}$. This integral is absolutely convergent precisely because $f(\mathbf{x})$ is absolutely integrable on $\R^{n}$. The Fourier transform is intimately related to periodic functions. If $f(\mathbf{x})$ is $1$-periodic in each component and integrable on $[0,1]^{n}$ then we define the $\mathbf{n}$-th \textbf{Fourier coefficient}\index{Fourier coefficient} $\hat{f}(\mathbf{n})$ of $f(\mathbf{x})$ by
    \[
      \hat{f}(\mathbf{n}) = \int_{[0,1]^{n}}f(\mathbf{x})e^{-2\pi i\<\mathbf{n},\mathbf{x}\>}\,d\mathbf{x}.
    \]
    The \textbf{Fourier series}\index{Fourier series} of $f(\mathbf{x})$ is defined by the series
    \[
      \sum_{\mathbf{n} \in \Z^{n}}\hat{f}(\mathbf{n})e^{2\pi i\<\mathbf{n},\mathbf{x}\>}.
    \]
    There is the question of whether the Fourier series of $f(\mathbf{x})$ converges at all and if so does it even converge to $f(\mathbf{x})$ itself. Under reasonable conditions this is possible as the following proposition shows (see \cite{grafakos2008classical} for a proof):

    \begin{theorem}\label{thm:existance_of_Fourier_series}
      Suppose $f(\mathbf{x})$ is a smooth function on $\R^{n}$ and is $1$-periodic in each component. Then the Fourier series of $f(\mathbf{x})$ converges uniformly everywhere to $f(\mathbf{x})$.
    \end{theorem}

    In the case of $1$-periodic functions of a single variable, we can do better. This is known as the \textbf{Dirichlet-Jordan test}\index{Dirichlet-Jordan test} (see \cite{zygmund2002trigonometric} for a proof):

    \begin{theorem}[Dirichlet-Jodan test]
      Suppose $f(x)$ is a function on $\R$ that is $1$-periodic and of bounded variation. Then the Fourier series of $f(x)$ converges locally uniformly to $f(x)$ on every set where $f(x)$ is continuous. Moreover, at any jump discontinuity, the Fourier series of $f(x)$ converges to the average of the left-hand and right-hand limits of $f(x)$. In particular, this holds for all continuously differentiable functions with at most a finite number of jump discontinuities.
    \end{theorem}

    Returning to the general setting, suppose $f(\mathbf{x})$ is an absolutely integrable function on $\R^{n}$. There are two ways of building a function from $f(\mathbf{x})$ that is $1$-periodic in each component. Namely, averaging $f(\mathbf{x})$ over all unit translates of $\Z^{n}$ or considering the Fourier series of $f(\mathbf{x})$:
    \[
      \sum_{\mathbf{n} \in \Z^{n}}f(\mathbf{x}+\mathbf{n}) \quad \text{or} \quad \sum_{\mathbf{t} \in \Z^{n}}(\mc{F}f)(\mathbf{t})e^{2\pi i\<\mathbf{t},\mathbf{x}\>}.
    \]
    The link between the Fourier transform and Fourier series is given by the \textbf{Poisson summation formula}\index{Poisson summation formula} which says that these two expressions are the same under some mild assumptions. In fact, we may replace $\Z^{n}$ with any complete integral lattice $\L$ in $\R^{n}$:

    \begin{theorem*}[Poisson summation formula]
      Suppose $\L$ is a complete integral lattice in $\R^{n}$, $f(\mathbf{x})$ is absolutely integrable on $\R^{n}$, and the function
      \[
        F(\mathbf{x}) = \sum_{\l \in \L}f(\mathbf{x}+\l),
      \]
      is smooth. Then
      \[
        \sum_{\l \in \L}f(\mathbf{x}+\l) = \frac{1}{V_{\L}}\sum_{\l^{\vee} \in \L^{\vee}}(\mc{F}f)(\l^{\vee})e^{2\pi i\<\l^{\vee},\mathbf{x}\>},
      \]
      and
      \[
        \sum_{\l \in \L}f(\l) = \frac{1}{V_{\L}}\sum_{\l^{\vee} \in \L^{\vee}}(\mc{F}f)(\l^{\vee}).
      \]
    \end{theorem*}
    \begin{proof}
      Fix a basis $\l_{1},\ldots,\l_{n}$ for $\L$ and let $P$ be the associated generator matrix. Then $P$ is the base change matrix from the standard basis to $\l_{1},\ldots,\l_{n}$. In particular, $P$ is an invertible linear transformation on $\R^{n}$ satisfying $\L = P\Z^{n}$ and $\L^{\vee} = (P^{-1})^{t}\Z^{n}$. Letting $ F_{P}(\mathbf{x}) = F(P\mathbf{x})$, we may write
      \[
        F_{P}(\mathbf{x}) = \sum_{\mathbf{n} \in \Z^{n}}f(P\mathbf{x}+P\mathbf{n}).
      \]
      Now $F_{P}(\mathbf{x})$ is smooth and $1$-periodic in each component because $F(\mathbf{x})$ is smooth and invariant under translation by $\L$. Therefore $F_{P}(\mathbf{x})$ admits a Fourier series converging uniformly everywhere to $F_{P}(\mathbf{x})$ by \cref{thm:existance_of_Fourier_series}. Moreover, $F_{P}(\mathbf{x})$ is absolutely integrable on $[0,1]^{n}$ since it is smooth. We compute the $\mathbf{t}$-th Fourier coefficient of $F_{P}(\mathbf{x})$ as follows:
      \begin{align*}
        \hat{F}_{P}(\mathbf{t}) &= \int_{[0,1]^{n}}F_{P}(\mathbf{x})e^{-2\pi i\<\mathbf{t},\mathbf{x}\>}\,d\mathbf{x} \\
        &= \int_{[0,1]^{n}}\sum_{\mathbf{n} \in \Z^{n}}f(P\mathbf{x}+P\mathbf{n})e^{-2\pi i\<\mathbf{t},\mathbf{x}\>}\,d\mathbf{x} \\
        &= \sum_{\mathbf{n} \in \Z^{n}}\int_{[0,1]^{n}}f(P\mathbf{x}+P\mathbf{n})e^{-2\pi i\<\mathbf{t},\mathbf{x}\>}\,d\mathbf{x} && \text{FTT} \\
        &= \frac{1}{V_{\L}}\sum_{\mathbf{n} \in \Z^{n}}\int_{P[0,1]^{n}}f(\mathbf{x}+P\mathbf{n})e^{-2\pi i\<\mathbf{t},P^{-1}\mathbf{x}\>} && \text{$\mathbf{x} \mapsto P^{-1}\mathbf{x}$ and \cref{prop:covolume_of_dual_is_inverse}} \\
        &= \frac{1}{V_{\L}}\sum_{\mathbf{n} \in \Z^{n}}\int_{P[0,1]^{n}}f(\mathbf{x}+P\mathbf{n})e^{-2\pi i\<\mathbf{t},P^{-1}\mathbf{x}\>}\,d\mathbf{x} \\
        &= \frac{1}{V_{\L}}\sum_{\mathbf{n} \in \Z^{n}}\int_{P[0,1]^{n}}f(\mathbf{x}+P\mathbf{n})e^{-2\pi i\left\<(P^{-1})^{t}\mathbf{t},\mathbf{x}\right\>}\,d\mathbf{x} \\
        &= \frac{1}{V_{\L}}\int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\left\<(P^{-1})^{t}\mathbf{t},\mathbf{x}\right\>}\,d\mathbf{x} \\
        &= \frac{1}{V_{\L}}(\mc{F}f)\left((P^{-1})^{t}\mathbf{t}\right).
      \end{align*}
      Therefore the definition of $F_{P}(\mathbf{x})$ and its representation as a Fourier series together gives
      \[
        \sum_{\l \in \L}f(P\mathbf{x}+\l) = \frac{1}{V_{\L}}\sum_{\mathbf{t} \in \Z^{n}}(\mc{F}f)\left((P^{-1})^{t}\mathbf{t}\right)e^{2\pi i\<\mathbf{t},\mathbf{x}\>}.
      \]
      Changing variables $\mathbf{x} \mapsto P^{-1}\mathbf{x}$ and using the fact $\L^{\vee} = (P^{-1})^{t}\Z^{n}$ results in
      \[
        \sum_{\l \in \L}f(\mathbf{x}+\l) = \frac{1}{V_{\L}}\sum_{\l^{\vee} \in \L^{\vee}}(\mc{F}f)(\l^{\vee})e^{2\pi i\<\l^{\vee},\mathbf{x}\>}.
      \]
      This proves the first statement. Setting $\mathbf{x} = \mathbf{0}$ proves the second statement.
    \end{proof}

    For convenience, we state the Poisson summation formula in the simplified case for the self-dual integral lattice $\L = \Z^{n}$ as a corollary since it is how the Poisson summation formula is usually applied:

    \begin{corollary}
      Suppose $f(\mathbf{x})$ is absolutely integrable on $\R^{n}$, and the function
      \[
        F(\mathbf{x}) = \sum_{\mathbf{n} \in \Z^{n}}f(\mathbf{x}+\mathbf{n}),
      \]
      is smooth. Then
      \[
        \sum_{\mathbf{n} \in \Z^{n}}f(\mathbf{x}+\mathbf{n}) = \sum_{\mathbf{t} \in \Z^{n}}(\mc{F}f)(\mathbf{t})e^{2\pi i\<\mathbf{t},\mathbf{x}\>},
      \]
      and
      \[
        \sum_{\mathbf{n} \in \Z^{n}}f(\mathbf{n}) = \sum_{\mathbf{t} \in \Z^{n}}(\mc{F}f)(\mathbf{t}).
      \]
    \end{corollary}
    \begin{proof}
      This is the Poisson summation formula when $\L = \Z^{n}$ since $\Z^{n}$ is self-dual.
    \end{proof}

    Using the Dirichlet-Jordan test, we can prove a slightly stronger form of the Poisson summation formula in the single variable setting:

    \begin{theorem}\label{thm:Poisson_summation_formula_Dirichlet-Jordan_test}
      Suppose $f(x)$ is absolutely integrable on $\R$, and the function
      \[
        F(x) = \asum_{n \in \Z}f(x+n),
      \]
      satisfies the Dirichlet-Jordan test, where the $\ast$ indicates that $f(x+n)$ is meant to represent the average of the left-hand and right-hand limits at jump discontinuities. Then
      \[
        \asum_{n \in \Z}f(x+n) = \sum_{t \in \Z}(\mc{F}f)(t)e^{2\pi inx},
      \]
      and
      \[
        \asum_{n \in \Z}f(n) = \sum_{t \in \Z}(\mc{F}f)(t).
      \]
    \end{theorem}
    \begin{proof}
      Observe that $F(x)$ is $1$-periodic. As $F(x)$ satisfies the Dirichlet-Jordan test by assumption, it admits a Fourier series converging locally uniformly to $F(x)$ wherever $F(x)$ is continuous. In fact, by the construction of $F(x)$ and that the Fourier series of $F(x)$ converges to the average of the left-hand and right-hand limits at jump discontinuities, the Fourier series of $F(x)$ converges locally uniformly to $F(x)$ everywhere. Moreover, $F(x)$ is absolutely integrable on $[0,1]$ since it is smooth. We compute the $t$-th Fourier coefficient of $F(x)$ as follows:
      \begin{align*}
        \hat{F}(t) &= \int_{0}^{1}F(x)e^{-2\pi itx}\,dx \\
        &= \int_{0}^{1}\sum_{n \in \Z}f(x+n)e^{-2\pi itx}\,dx \\
        &= \sum_{n \in \Z}\int_{0}^{1}f(x+n)e^{-2\pi itx}\,dx && \text{FTT} \\
        &= \int_{-\infty}^{\infty}f(x)e^{-2\pi itx}\,dx \\
        &= (\mc{F}f)(t).
      \end{align*}
      Therefore the definition of $F(x)$ and its representation as a Fourier series together gives
      \[
        \asum_{n \in \Z}f(x+n) = \sum_{t \in \Z}(\mc{F}f)(t)e^{2\pi itx}.
      \]
      This proves the first statement. Setting $x = 0$ proves the second statement.
    \end{proof}

    In practical settings, we need a class of functions $f(\mathbf{x})$ for which the assumptions of the Poisson summation formula hold. We say that $f(\mathbf{x})$ is of \textbf{Schwarz class}\index{Schwarz class} if $f \in C^{\infty}(\R^{n})$ and $f(\mathbf{x})$ along with all of its partial derivatives have rapid decay. If $f(\mathbf{x})$ is of Schwarz class, the rapid decay implies that $f(\mathbf{x})$ and all of its derivatives are absolutely integrable over $\R^{n}$. Moreover, this also implies $F(\mathbf{x}) = \sum_{\mathbf{n} \in \Z^{n}}f(\mathbf{x}+\mathbf{n})$ and all of its derivatives are locally absolutely uniformly convergent by the Weierstrass $M$-test. The uniform limit theorem then implies $F(\mathbf{x})$ is smooth and thus the conditions of the Poisson summation formula are satisfied. We will now derive some properties of the Fourier transform including a case specific to Schwarz class functions:

    \begin{proposition}\label{prop:Fourier_transform_properties}
      Let $f(\mathbf{x})$ and $g(\mathbf{x})$ be absolutely integrable on $\R^{n}$. Then the following hold:
      \begin{enumerate}[label*=(\roman*)]
        \item For any $\a,\b \in \R$, we have
        \[
          (\mc{F}(\a f+\b g))(\boldsymbol{\xi}) = \a(\mc{F}f)(\boldsymbol{\xi})+\b(\mc{F}g)(\boldsymbol{\xi}).
        \]
        \item If $g(\mathbf{x}) = f(\mathbf{x}+\boldsymbol{\a})$ for any $\boldsymbol{\a} \in \R^{n}$ then
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = e^{2\pi i\<\boldsymbol{\a},\boldsymbol{\xi}\>}(\mc{F}f)(\boldsymbol{\xi}).
        \]
        \item If $g(\mathbf{x}) = f(A\mathbf{x})$ for any $A \in \GL_{n}(\R)$ then
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = \frac{1}{|\det(A)|}(\mc{F}f)((A^{-1})^{t}\boldsymbol{\xi}).
        \]
        \item If $f(\mathbf{x})$ is of Schwarz class and $g(\mathbf{x}) = \frac{\del}{\del \mathbf{x}}^{\mathbf{k}}f(\mathbf{x})$ for some $\mathbf{k} \in \Z_{\ge 0}^{n}$ then
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = (2\pi i\boldsymbol{\xi})^{\mathbf{k}}(\mc{F}f).
        \]
      \end{enumerate}
    \end{proposition}
    \begin{proof}
      We will prove the statements separately:
      \begin{enumerate}[label*=(\roman*)]
        \item This is immediate from linearity of the integral.
        \item Applying the change of variables $\mathbf{x} \mapsto \mathbf{x}-\boldsymbol{\a}$ to
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = \int_{\R^{n}}f(\mathbf{x}+\boldsymbol{\a})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}\>}\,d\mathbf{x}
        \]
        gives
        \[
          \int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}-\boldsymbol{\a}\>}\,d\mathbf{x} = e^{2\pi i\<\boldsymbol{\xi},\boldsymbol{\a}\>}\int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}\>}\,d\mathbf{x} = e^{2\pi i\<\boldsymbol{\a},\boldsymbol{\xi}\>}(\mc{F}f)(\boldsymbol{\xi}).
        \]
        \item Applying the change of variables $\mathbf{x} \mapsto A^{-1}\mathbf{x}$ to
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = \int_{\R^{n}}f(A\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}\>}\,d\mathbf{x},
        \]
        gives
        \[
          \frac{1}{|\det(A)|}\int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},A^{-1}\mathbf{x}\>}\,d\mathbf{x} = \frac{1}{|\det(A)|}\int_{\R^{n}}f(\mathbf{x})e^{-2\pi i\left\<(A^{-1})^{t}\boldsymbol{\xi},\mathbf{x}\right\>}\,d\mathbf{x} = (\mc{F}f)((A^{-1})^{t}\boldsymbol{\xi}),
        \]
        since the Jacobian matrix is $A$.
        \item We may assume $\mathbf{k} \neq \mathbf{0}$ for otherwise there is nothing to prove. Since $f(\mathbf{x})$ is of Schwarz class, so is $g(\mathbf{x})$. First suppose $n = 1$ so that $f(\mathbf{x}) = f(x)$, $g(\mathbf{x}) = g(x)$, and $\mathbf{k} = k \ge 1$. Then 
        \[
          (\mc{F}g)(\z) = \int_{-\infty}^{\infty}\frac{d^{k}}{dx^{k}}f(x)e^{-2\pi i\z x}\,dx = 2\pi i\z\int_{-\infty}^{\infty}\frac{d^{k-1}}{dx^{k-1}}f(x)e^{-2\pi i\z x}\,dx,
        \]
        where the second equality follows by an application of integration by parts and that $f(x)$ is of Schwarz class. Repeating this procedure $k-1$ times results in
        \[
          (2\pi i\z)^{k}\int_{-\infty}^{\infty}f(x)e^{-2\pi i\z x}\,dx = (2\pi i\z)^{k}(\mc{F})(\z),
        \]
        proving the case when $n = 1$. The general case follows from what we have shown by applying repeated integration by parts in each variable to
        \[
          (\mc{F}g)(\boldsymbol{\xi}) = \int_{\R^{n}}\frac{\del}{\del \mathbf{x}}^{\mathbf{k}}f(\mathbf{x})e^{-2\pi i\<\boldsymbol{\xi},\mathbf{x}\>}\,d\mathbf{x}.
        \]
      \end{enumerate}
    \end{proof}

    The properties in \cref{prop:Fourier_transform_properties} are immensely useful when computing Fourier transforms. We now introduce examples of Schwarz class functions and compute their Fourier transforms. The classic example of a Schwarz class function is $e^{-2\pi x^{2}}$. This function is particularly important because it is essentially its own Fourier transform:

    \begin{proposition}\label{prop:Fourier_transform_of_exponential_single_variable}
      Let $\a > 0$ and set $f(x) = e^{-2\pi\a x^{2}}$. Then
      \[
        (\mc{F}f)(\z) = \frac{e^{-\frac{\pi\z^{2}}{2\a}}}{\sqrt{2\a}}.
      \]
      In particular, $e^{-\pi x^{2}}$ is its own Fourier transform.
    \end{proposition}
    \begin{proof}
      Note that $f(x)$ is absolutely integrable because it exhibits exponential decay. We compute its Fourier transform
      \[
        (\mc{F}f)(\z) = \int_{-\infty}^{\infty}e^{-2\pi\a x^{2}}e^{-2\pi i\z x}\,dx = \int_{-\infty}^{\infty}e^{-2\pi(\a x^{2}+i\z x)}\,dx.
      \]
      By performing the change of variables $x \mapsto \frac{x}{\sqrt{\a}}$, the last integral becomes
      \[
        \frac{1}{\sqrt{\a}}\int_{-\infty}^{\infty}e^{-2\pi\left(x^{2}+\frac{i\z x}{\sqrt{\a}}\right)}\,dx.
      \]
      Complete the square in the exponent by observing
      \[
        x^{2}+\frac{i\z x}{\sqrt{\a}} = \left(x+\frac{i\z}{2\sqrt{\a}}\right)^{2}+\frac{\z^{2}}{4\a},
      \]
      so that the previous integral is equal to
      \[
        \frac{e^{-\frac{\pi\z^{2}}{2\a}}}{\sqrt{\a}}\int_{-\infty}^{\infty}e^{-2\pi\left(x+\frac{i\z}{2\sqrt{\a}}\right)^{2}}\,dx.
      \]
      The change of variables $x \mapsto \frac{x}{\sqrt{2}}-\frac{i\z}{\sqrt{\a}}$ is permitted without affecting the line of integration by viewing the integral as a complex integral, noting that the integrand is entire as a complex function, and shifting the line of integration. Then the integral takes the form
      \[
        \frac{e^{-\frac{\pi\z^{2}}{2\a}}}{\sqrt{2\a}}\int_{-\infty}^{\infty}e^{-\pi x^{2}}\,dx = \frac{e^{-\frac{\pi\z^{2}}{2\a}}}{\sqrt{2\a}},
      \]
      where the equality holds because the integral is $1$ since it is the Gaussian integral (see \cref{append:Special_Integrals}). This proves the first statement. The second statement follows by taking $\a = \frac{1}{2}$.
    \end{proof}

    The analog of $e^{-2\pi x^{2}}$ on $\R^{n}$ is $e^{-2\pi\<\mathbf{x},\mathbf{x}\>}$ which is clearly Schwarz class because $e^{-2\pi x^{2}}$ is. We also obtain an analog of \cref{prop:Fourier_transform_of_exponential_single_variable} for this Schwarz class function as a corollary:

    \begin{corollary}\label{cor:Fourier_transform_of_exponential_single_variable}
      Let $\a > 0$ and set $f(\mathbf{x}) = e^{-2\pi\a\<\mathbf{x},\mathbf{x}\>}$. Then
      \[
        (\mc{F}f)(\boldsymbol{\xi}) = \frac{e^{-\frac{\pi\<\boldsymbol{\xi},\boldsymbol{\xi}\>}{2\a}}}{(2\a)^{\frac{n}{2}}}.
      \]
      In particular, $e^{-\pi\<\mathbf{x},\mathbf{x}\>}$ is its own Fourier transform.
    \end{corollary}
    \begin{proof}
      Applying \cref{prop:Fourier_transform_of_exponential_single_variable} to each variable separately proves the first statement. The second statement follows upon setting $\a = \frac{1}{2}$.
    \end{proof}
  \section{The Mellin Transform}
    Like the Fourier transform, the Mellin transform is another type of integral transform. If $f(\mathbf{x})$ is a continuous function on $\R_{+}^{n}$ then the \textbf{Mellin transform}\index{Mellin transform} $(\mc{M}f)(\mathbf{s})$ of $f(\mathbf{x})$ is defined by
    \[
      (\mc{M}f)(\mathbf{s}) = \int_{\R_{+}^{n}}f(\mathbf{x})\mathbf{x}^{\mathbf{s}}\,\frac{d\mathbf{x}}{\mathbf{x}},
    \]
    for $\mathbf{s} \in \C^{n}$. However, this integral is not guaranteed to converge unless specific conditions upon $f(\mathbf{x})$ are imposed. For example, if $f(\mathbf{x})$ exhibits rapid decay and remains bounded as $\mathbf{x} \to 0$ then the integral is locally absolutely uniformly convergent for $\s > 0$. We will only be interested in the case when $\mathbf{s} = (s,\ldots,s)$ so that the Mellin transform is a function on $\C$. Moreover, most of the time we will take $n = 1$ so that the initial function we are taking the Mellin transform of is defined on $\R_{+}$. There is also an inverse transform in this case. If $g(s)$ holomorphic and tends to zero as $t \to \infty$ in a vertical strip $a < \s < b$ then the inverse \textbf{inverse Mellin transform}\index{inverse Mellin transform} $(\mc{M}^{-1}g)(x)$ of $g(s)$ is given by
    \[
      (\mc{M}^{-1}g)(x) = \frac{1}{2\pi i}\int_{(c)}g(s)x^{-s}\,ds,
    \]
    for any $a < c < b$.
    It is not immediately clear that this integral converges or is independent of $c$. The following theorem makes precise what properties $f(x)$ needs to satisfy so that the inverse Mellin transform recovers $f(x)$ (see \cite{debnath2002integral} for a proof):

    \begin{theorem*}[Mellin inversion formula]
      Let $a < b$ and suppose $g(s)$ is analytic in the strip vertical $a < \s < b$, tends to zero uniformly as $t \to \infty$ along any line $\s = c$ for $a < c < b$, and that the integral of $g(s)$ along this line is locally absolutely uniformly convergent. Then if
      \[
        f(x) = \frac{1}{2\pi i}\int_{(c)}g(s)x^{-s}\,ds,
      \]
      this integral is independent of $c$ and moreover $g(s) = (\mc{M}f)(s)$. Conversely, suppose $f(x)$ is piecewise continuous such that its value is halfway between the limit values at any jump discontinuity and
      \[
        g(s) = \int_{0}^{\infty}f(x)x^{s}\,\frac{dx}{x},
      \]
      is locally absolutely uniformly convergent in the vertical strip $a < \s < b$. Then $f(x) = (\mc{M}^{-1}g)(x)$.
    \end{theorem*}
  \section{The Gamma Function}
    The gamma function is ubiquitous in number theory and the better one understands this function the better one will be at seeing the forest for the trees. The \textbf{gamma function}\index{gamma function} $\G(s)$ is defined to be the Mellin transform of $e^{-x}$:
    \[
      \G(s) = \int_{0}^{\infty}e^{-x}x^{s-1}\,dx,
    \]
    for $\s > 0$. The integral is locally absolutely uniformly convergent in this region. Indeed, let $K$ is a compact subset in this region and set $\a = \min_{s \in K}(\s)$. Then we have to show that $\G(s)$ is absolutely uniformly convergent on $K$. Now split the integral by writing
    \[
      \G(s) = \int_{0}^{1}e^{-x}x^{s-1}\,dx+\int_{1}^{\infty}e^{-x}x^{s-1}\,dx.
    \]
    The second integral is absolutely uniformly convergent on $K$ since the integrand exhibits exponential decay. As for the first integral, we have
    \[
      \int_{0}^{1}e^{-x}x^{s-1}\,dx \ll \int_{0}^{1}x^{\s-1}\,dx \ll_{\a} 1,
    \]
    so that this integral is absolutely uniformly convergent on $K$ too. Thus $\G(s)$ is absolutely uniformly convergent on $K$. Also note that $\G(s)$ is real for $s > 0$. The most basic properties of $\G(s)$ are the following:

    \begin{proposition}\label{prop:Factorial_properties_of_gamma_function}
      $\G(s)$ satisfies the following properties:
      \begin{enumerate}[label*=(\roman*)]
        \item $\G(1) = 1$.
        \item $\G(s+1) = s\G(s)$.
        \item $\G(\conj{s}) = \conj{\G(s)}$.
      \end{enumerate}
    \end{proposition}
    \begin{proof}
      We obtain (i) by direct computation:
      \[
        \G(1) = \int_{0}^{\infty}e^{-x}\,dx = 1.
      \]
      An application of integration by parts gives (ii):
      \[
        \G(s+1) = \int_{0}^{\infty}e^{-x}x^{s}\,dx = s\int_{0}^{\infty}e^{-x}x^{s-1}\,dx = s\G(s).
      \]
      For (iii), since $\G(s)$ is real for $s >0$ we have $\G(\conj{s}) = \conj{\G(s)}$ on this half-line and then the identity theorem implies that this holds everywhere.
    \end{proof}

    From \cref{prop:Factorial_properties_of_gamma_function} we see that for $s = n$ a positive integer, $\G(n) = (n-1)!$. So $\G(s)$ can be thought of as a holomorphic extension of the factorial function. We can use property (ii) of \cref{prop:Factorial_properties_of_gamma_function} to extended $\G(s)$ to a meromorphic function on all of $\C$:

    \begin{theorem}\label{thm:continuation_of_gamma_function}
      $\G(s)$ admits meromorphic continuation to $\C$ with poles at $s = -n$ for $n \ge 0$. All of these poles are simple and with residue $\frac{(-1)^{n}}{n!}$ at $s = -n$.
    \end{theorem}
    \begin{proof}
      Using \cref{prop:Factorial_properties_of_gamma_function}, (ii) repeatedly, for any integer $n \ge 0$ we have
      \[
        \G(s) = \frac{\G(s+1+n)}{s(s+1) \cdots (s+n)}.
      \]
      The right-hand side defines an meromorphic function in the region $\s > -n$ and away from the points $0,-1,\ldots,-n$. Letting $n$ be arbitrary, we see that $\G(s)$ has meromorphic continuation to $\C$ with poles at $0,-1,-2,\ldots$. We now compute the residue at $s = -n$. Around this point $\G(s)$ admits meromorphic continuation with representation
      \[
        \frac{\G(s+1+n)}{s(s+1) \cdots (s+n)},
      \]
      where all of the factors except for $s+n$ are holomorphic at $s = -n$. Thus the pole is simple, and
      \[
        \Res_{s = -n}\G(s) = \lim_{z \to -n}\frac{\G(s+1+n)(s+n)}{s(s+1) \cdots (s+n)} = \frac{\G(1)}{(-n)(1-n) \cdots (-1)} = \frac{(-1)^{n}}{n!}.
      \]
    \end{proof}

    In particular, \cref{thm:continuation_of_gamma_function} implies $\Res_{s = 0}\G(s) = 1$ and $\Res_{s = 1}\G(s) = -1$. There are a few other properties of the gamma function that are famous and which we will use frequently. The first of which is the \textbf{Legendre duplication formula}\index{Legendre duplication formula} (see \cite{remmert1998classical} for a proof):

    \begin{theorem*}[Legendre duplication formula]
      For any $s \in \C-\{0,-1,-2,\ldots\}$,
      \[
        \G(s)\G\left(s+\frac{1}{2}\right) = 2^{1-2s}\sqrt{\pi}\G(2s).
      \]
    \end{theorem*}

    As a first application, we can use this formula to compute $\G\left(\frac{1}{2}\right)$. Letting $z = \frac{1}{2}$ in the Legendre duplication formula and recalling $\G(1) = 1$, we see that $\G\left(\frac{1}{2}\right) = \sqrt{\pi}$. There is also the important Hadamard factorization of the reciprocal of $\G(s)$ (see \cite{stein2003complex} for a proof):

    \begin{proposition}\label{prop:Hadamard_factorization_for_reciprocial_of_gamma}
      For all $s \in \C$,
      \[
        \frac{1}{\G(s)} = se^{\g s}\prod_{n \ge 1}\left(1+\frac{s}{n}\right)e^{-\frac{s}{n}},
      \]
      where $\g$ is the Euler-Mascheroni constant.
    \end{proposition}

    In particular, $\frac{1}{\G(s)}$ is entire so that $\G(s)$ is nowhere vanishing on $\C$. Also, $\frac{1}{\G(s)}$ is of order $1$ (see \cref{append:Factorizations_and_Finite_Order}). In particular, this means that $\G(s)$ is also order $1$ for $\s > 0$. We call $\frac{\G'}{\G}(s)$ the \textbf{digamma function}\index{digamma function}. Equivalently, the digamma function is the logarithmic derivative of the gamma function. Note that upon taking the logarithmic derivative of $\G(s+1) = s\G(s)$, we see that the digamma function satisfies the related formula
    \[
      \frac{\G'}{\G}(s+1) = \frac{\G'}{\G}(s)+\frac{1}{s}.
    \]
    If we take the logarithmic derivative of the Hadamard factorization for $\frac{1}{s\G(s)}$, we obtain a useful expression for the digamma function:

    \begin{corollary}\label{cor:logarithmic_derivative_of_gamma}
      For all $s \in \C$,
      \[
        \frac{\G'}{\G}(s+1) = -\g+\sum_{n \ge 1}\left(\frac{1}{n}-\frac{1}{s+n}\right),
      \]
      where $\g$ is the Euler-Mascheroni constant. In particular, the digamma function has simple poles of residue $-1$ at the poles of the gamma function.
    \end{corollary}
    \begin{proof}
      By \cref{prop:Factorial_properties_of_gamma_function} (ii), $\frac{1}{\G(s+1)} = \frac{1}{s\G(s)}$. Taking the logarithmic derivative using \cref{prop:Hadamard_factorization_for_reciprocial_of_gamma} we obtain
      \[
        -\frac{\G'}{\G}(s+1) = \g+\sum_{n \ge 1}\left(\frac{1}{s+n}-\frac{1}{n}\right),
      \]
      provided $s$ is distance $\e$ away from the poles of $\G(s)$. This is the desired formula and the statement regarding the poles follows immediately.
    \end{proof}
    
    We will also require a well-known approximation for the gamma function known as \textbf{Stirling's formula}\index{Stirling's formula} (see \cite{remmert1998classical} for a proof):

    \begin{theorem*}[Stirling's formula]
      \phantom{}
      \[
        \G(s) \sim \sqrt{2\pi}s^{s-\frac{1}{2}}e^{-s},
      \]
      provided $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$.
    \end{theorem*}

    If $\s$ is bounded, Stirling's formula gives a useful asymptotic showing that $\G(s)$ decays as $s \to \infty$:
    
    \begin{corollary}\label{equ:weaker_Stirling_formula}
    Let $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$. Then if $\s$ is bounded, we have
      \[
        \G(s) \sim \sqrt{2\pi}t^{\s-\frac{1}{2}}e^{-\frac{\pi}{2}|t|}.
      \]
    \end{corollary}
    \begin{proof}
      Stirling's formula can be equivalently expressed as
      \[
        \G(s) \sim \sqrt{2\pi}(\s+it)^{\s-\frac{1}{2}+it}e^{-\s-it}.
      \]
      Since $\s$ is bounded, $e^{-\s-it} \ll 1$ and we obtain the simplified asymptotic
      \[
        \G(s) \sim \sqrt{2\pi}(it)^{\s-\frac{1}{2}+it}.
      \]
      Similarly, $x$ being bounded implies $i^{\s-\frac{1}{2}} \ll 1$ and we compute
      \[
        (it)^{it} = e^{i|t|\log(i|t|)} = e^{i|t|(\log(i)+\log|t|)} = e^{-\frac{\pi}{2}|t|+i|t|\log|t|} \sim e^{-\frac{\pi}{2}|t|},
      \]
      where we have used the fact that $\log(i) = i\frac{\pi}{2}$. Together, we obtain the further simplified asymptotic
      \[
        \G(s) \sim \sqrt{2\pi}t^{\s-\frac{1}{2}}e^{-\frac{\pi}{2}|t|},
      \]
      which is the desired result
    \end{proof}
    Equivalent to Stirling's formula is the asymptotic
    \begin{equation}\label{equ:Stirlings_formula_equivalent_version}
        \G(s) = \sqrt{2\pi}s^{s-\frac{1}{2}}e^{-s}(1+O_{\e,\d}(1)),
    \end{equation}
    provided $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$. Taking the logarithm (since $|\arg(s)| < \pi-\e$ the logarithm is defined) of this asymptotic gives
    \begin{equation}\label{equ:log_gamma_estimate}
      \log\G(s) = \frac{1}{2}\log(2\pi)+\left(s-\frac{1}{2}\right)\log(s)-s+O_{\e,\d}\left(1\right),
    \end{equation}
    which will be useful. In fact, from \cref{equ:log_gamma_estimate} we can obtain another useful estimate formula for the digamma function:

    \begin{proposition}\label{equ:approximtion_for_digamma}
    \[
      \frac{\G'}{\G}(s) = \log(s)+O_{\e,\d}(1),
    \]
    provided $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$.
    \end{proposition}
    \begin{proof}
      \cref{equ:log_gamma_estimate} give the simplified estimate
      \[
        \log\G(s) = \frac{1}{2}\log(2\pi)+s\log(s)-s+O_{\e,\d}(1).
      \]
      Set $g(s) = \frac{1}{2}\log(2\pi)+s\log(s)-s$ so that $\log\G(s) = g(s)+O_{\e,\d}(1)$. Then $\log\G(s)-g(s) = O_{\e,\d}(1)$, and by Cauchy's integral formula, we have
      \begin{align*}
        \frac{\G'}{\G}(s) &= \frac{d}{ds}\left(g(s)+O_{\e,\d}(1)\right) \\
        &= g'(s)+\frac{d}{ds}(\log\G(s)-g(s)) \\
        &= \log(s)+\frac{1}{2\pi i}\int_{C}\frac{\log\G(u)-g(u)}{(u-s)^{2}}\,du,
      \end{align*}
      where $C$ is the circle about $s$ of sufficiently small radius $\eta$ depending upon $\e$ and $\d$. Therefore
      \[
        \left|\frac{\G'}{\G}(s)-\log(s)\right| \le \frac{1}{2\pi}\int_{C}\frac{|\log\G(u)-g(u)|}{\eta^{2}}\,|du| \ll_{\e,\d} 1,
      \]
      where the last estimate follows because $\log\G(s)-g(s) = O_{\e,\d}(1)$.
    \end{proof}

    Lastly, we introduce a useful function related to the Gamma function. We define the \textbf{beta function}\index{beta function} $B(s,u)$ by
    \[
        B(s,u) = \int_{0}^{1}t^{s-1}(1-t)^{u-1}\,dt,
    \]
    for $\s > 0$ and $\tau > 0$. The integral is locally absolutely uniformly convergent in this region. Indeed, let $K \x L$ be a compact subset in this region and set $\a = \min_{s \in K}(\s)$ and $\b = \min_{u \in L}(\tau)$. Then we have to show that $B(s,u)$ is absolutely uniformly convergent on $K \x L$. Observe
    \[
      \int_{0}^{1}t^{s-1}(1-t)^{u-1}\,dt \ll \int_{0}^{1}t^{\a-1}(1-t)^{\b-1}\,dt \ll_{\a,\b} 1,
    \]
    so that this integral is absolutely uniformly convergent on $K \x L$. Thus $B(s,u)$ is absolutely uniformly convergent on $K \x L$. Most importantly, the beta function is related to the gamma function in this region (see \cite{remmert1998classical} for a proof):
    
    \begin{proposition}\label{prop:integral_reprepsentation_for_beta_function}
      For $\Re(s) > 0$ and $\Re(u) > 0$,
      \[
        B(s,u) = \frac{\G(s)\G(u)}{\G(s+u)}.
      \]
    \end{proposition}

    In particular, \cref{prop:integral_reprepsentation_for_beta_function} shows that $B(s,u)$ has meromorphic continuation to $\C^{2}$ since the gamma function does by \cref{thm:continuation_of_gamma_function}.