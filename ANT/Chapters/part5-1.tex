\chapter{Moments of \texorpdfstring{$L$}{L}-functions}
  \section{\todo{An Overview of Moments}}
  \section{\todo{The Katz-Sarnak Philosophy}}
    The Katz-Sarnak philosophy is an idea that certain statistics about families of $L$-functions should match statistics for random matrices coming from some particular compact matrix group. One starts with some class of zeros to look at, say zeros of an individual $L$-function very high up the critical strip or zeros of for some collection of $L$-functions very low down on the critical strip. Actually, one works with the corresponding unfolded nontrivial zeros since they are evenly spaced on average. Then some class of test functions are introduced to carry out the statistical calculations in order to reveal the similarity with some class of matrices. In the following, we give a loose introduction to the Katz-Sarnak philosophy.
    \subsection*{The Work of Montgomery \& Dyson}
      The beginning of the connection between random matrix theory and analytic number theory was at Princeton in the 1970s via discussions between Montgomery and Dyson (see \todo{cite}). They found similarities between statistical information about the nontrivial distribution of the zeros of the Riemann zeta function and calculations in random matrix theory about unitary matrices. To do this, they considered the unfolded nontrivial zeros $\rho_{\text{unf}} = \b+i\w$ of $\z(s)$ with positive ordinate, that is $\w > 0$, and indexed them according to the size of ordinate. So let $\W = (\w_{n})_{n \ge 1}$ denote the increasing sequence of positive ordinates of the unfolded nontrivial zeros of $\z(s)$. Montgomery and Dyson considered the \textbf{two-point correlation function}\index{two-point correlation function} $F_{\z}(\a,\b;W)$ for $\z(s)$ defined by
      \[
        F_{\z}(\a,\b;W) = \frac{1}{W}|\{(\w_{n},\w_{m}) \in \W^{2}:\text{$\w_{n},\w_{m} \le W$ and $\w_{n}-\w_{m} \in [\a,\b]$}\}|,
      \]
      for any real $\a$ and $\b$ with $\a < \b$ and $W > 0$. What this function measures is the probability of how close pairs of zeros tend to be with respect to some fixed distance and up to some fixed height. In other words, the correlation between distances of zeros. They wanted to understand if the limiting distribution
      \[
        F_{\z}(\a,\b) = \lim_{W \to \infty}F_{\z}(\a,\b;W),
      \]
      exists and what can be said about it. The following conjecture made by Montgomery, known as Montgomery's pair correlation conjecture, answers this:

      \begin{conjecture}[Montgomery's pair correlation conjecture]
        For any $\a$ and $\b$ with $\a < \b$, $F_{\z}(\a,\b)$ exists provided the Riemann hypothesis for the Riemann zeta function holds. Moreover,
        \[
          F_{\z}(\a,\b) = \int_{\a}^{\b}\left(1-\left(\frac{\sin(\pi x)}{\pi x}\right)^{2}+\d(x)\right)\,dx,
        \]
        where $\d(x)$ is the Dirac delta function.
      \end{conjecture}      

      Montgomery's pair correlation conjecture still remains out of reach, but there is very good numerical evidence supporting it from the work of Odlyzko (see \todo{cite}). Dyson recognized that Montgomery's pair correlation conjecture mimics a similar situation in random matrix theory that he had investigated earlier. Consider an $N \x N$ unitary matrix $A \in U(N)$ with eigenphases $\t_{n}$ for $1 \le n \le N$ denoted in increasing order. Clearly the average density of the eigenphases of $A$ in $[0,2\pi)$ is $\frac{N}{2\pi}$. For any eigenphase $\t$, let $\phi$ be the \textbf{unfolded eigenphase}\index{unfolded eigenphase} corresponding to $\t$ be defined by
      \[ 
        \phi = \frac{N}{2\pi}\t.
      \]
      It follows that the average density of the unfolded eigenphases of $A$ in $[0,N)$ is $1$. Let $\Phi = (\phi_{n})_{1 \le n \le N}$ denote the increasing sequence of unfolded eigenphases of $A$. We consider the \textbf{two-point correlation function}\index{two-point correlation function} $F_{U}(\a,\b;A,N)$ for $A$ defined by
      \[
        F_{U}(\a,\b;A,N) = \frac{1}{N}|\{(\phi_{n},\phi_{m}) \in \Phi^{2}:\phi_{n}-\phi_{m} \in [\a,\b]\}|,
      \]
      for any real $\a$ and $\b$ with $\a < \b$. Since $U(N)$ has a Haar measure $dA$, we can compute the average of $F(\a,\b;A,N)$ over $U(N)$:
      \[
        F_{U}(\a,\b;N) = \int_{U(N)}F(\a,\b;A,N)\,dA.
      \]
      Analogously, we want to understand if the limiting distribution
      \[
        F_{U}(\a,\b) = \lim_{N \to \infty}F_{U}(\a,\b;N),
      \]
      exists and what can be said about it. Dyson showed the following (see \todo{cite} for a proof):

      \begin{proposition}\label{prop:Dyson_unitary_distribution}
        For any real $\a$ and $\b$ with $\a < \b$, $F_{U}(\a,\b)$ exists. Moreover,
        \[
          F_{U}(\a,\b) = \int_{\a}^{\b}\left(1-\left(\frac{\sin(\pi x)}{\pi x}\right)^{2}+\d(x)\right)\,dx,
        \]
        where $\d(x)$ is the Dirac delta function.
      \end{proposition}

      The right-hand side of \cref{prop:Dyson_unitary_distribution} is exactly the same formula given in Montgomery's pair correlation conjecture. In other words, if Montgomery's pair correlation conjecture is true then the two-point correlation of the unfolded nontrivial zeros of the Riemann zeta function in the limit as we move up the critical line exactly match the two-point correlation of the unfolded eigenphases of unitary matrices in the limit as the size of the matrices increase. In short, statistical information about the Riemann zeta function agrees with statistical information about the eigenvalues of unitary matrices. This is the origin of the Katz-Sarnak philosophy.
    \subsection*{Characteristic Polynomials of Unitary Matrices}
      Montgomery and Dyson's work demonstrated a similarity between the statistics of the unfolded nontrivial zeros of the Riemann zeta function and statistics of the unfolded eigenphases of unitary matrices. If this idea is to hold for other $L$-functions, we might further suspect that $L$-functions are modeled by the characteristic polynomial of unitary matrices since the zeros of the characteristic polynomial are the eigenvalues of the associated unitary matrix. This heuristic does indeed work to a surprising degree which we now demonstrate. For $A \in U(N)$, let
      \[
        L(s,A) = \det(I-sA) = \prod_{1 \le n \le N}(1-se^{i\t_{n}}),
      \]
      be the characteristic polynomial of $A$. It will turn out that $L(s,A)$ has strikingly similar properties to an $L$-function. The product expression for $L(s,A)$ is clearly analogous to the Euler product expression for an $L$-function. Upon expanding the product, we obtain
      \[
        L(s,A) = \sum_{0 \le n \le N}a_{n}s^{n},
      \]
      for some coefficients $a_{n}$. This expression is the analogue to the Dirichlet series representation for an $L$-function. Of course, as $L(s,A)$ is a polynomial it is analytic on $\C$. Moreover, $L(s,A)$ possesses a functional equation of shape $s \to \frac{1}{s}$. To see this, first observe that multiplicativity of the determinant gives
      \[
        L(s,A) = (-1)^{N}\det(A)s^{N}\det(I-s^{-1}A^{-1}).
      \]
      As $A$ is unitary, $L(s,A^{-1}) = L(s,A^{\ast}) = L(s,\conj{A})$. So the above equation can be expressed as
      \[
        L(s,A) = (-1)^{N}\det(A)s^{N}L\left(\frac{1}{s},\conj{A}\right).
      \]
      This is the analogue of the functional equation for $L(s,A)$ and it is of shape $s \to \frac{1}{s}$. We identify the analogues of the gamma factor and conductor as $1$ and $N$ respectively. Letting $\L(s,A)$ be defined by
      \[
        \L(s,A) = s^{-\frac{N}{2}}L(s,A),
      \]
      the functional equation can be expressed as
      \[
         \L(s,A) = (-1)^{N}\det(A) \L\left(\frac{1}{s},\conj{A}\right).
      \]
      From it, the analogue of root number is seen to be $(-1)^{N}\det(A)$ and $L(s,A)$ has dual $L(s,\conj{A})$. As the transformation $s \to \frac{1}{s}$ leaves the unit circle invariant, the unit circle is the analogue of the critical line. The fixed point of the transformation $s \to \frac{1}{s}$ is $s = 1$ which is the analogue of the central point. Moreover, as the zeros of $L(s,A)$ are precisely the eigenvalues of $A$ which lie on the unit circle, because $A$ is unitary, the analogue of the Riemann hypothesis is true for $L(s,A)$. We also have an analogue of the approximate functional equation. By substituting the polynomial representation of $L(s,A)$ into the functional equation, we obtain
      \[
        \sum_{0 \le n \le N}a_{n}s^{n} = (-1)^{N}\det(A)s^{N}\sum_{0 \le n \le N}\conj{a_{n}}s^{-n} = (-1)^{N}\det(A)\sum_{0 \le n \le N}\conj{a_{n}}s^{N-n}.
      \]
      Upon comparing coefficients, we find that
      \[
        a_{n} = (-1)^{N}\det(A)\conj{a_{N-n}},
      \]
      for $0 \le n \le N$. So for odd $N$,
      \[
        L(s,A) = \sum_{0 \le n \le \frac{N-1}{2}}a_{n}s^{n}+(-1)^{N}\det(A)s^{N}\sum_{0 \le n \le \frac{N-1}{2}}\conj{a_{n}}s^{-n},
      \]
      and for even $N$,
      \[
        L(s,A) = a_{\frac{N}{2}}s^{\frac{N}{2}}+\sum_{0 \le n \le \frac{N}{2}-1}a_{n}s^{n}+(-1)^{N}\det(A)s^{N}\sum_{0 \le n \le \frac{N}{2}-1}\conj{a_{n}}s^{-n}.
      \]
      These equations together are the analogue of the approximate functional equation. All of this is suggestive of the fact that characteristic polynomials of unitary matrices model $L$-functions at least heuristically speaking. Katz and Sarnak were able to carry this heuristic forward for certain families of $L$-functions in the limit as the analytic conductor tends to infinity.
    \iffalse
    \subsection*{Families of \texorpdfstring{$L$}{L}-functions}
      Katz and Sarnak generalized the work of Montgomery and Dyson by establishing a connection between families of $L$-functions and other compact matrix groups. For the ease of categorization, Katz and Sarnak associated a \textbf{symmetry type}\index{symmetry type} to each compact matrix group that they studied. The underlying groups for the symmetry types are referred to as \textbf{matrix ensembles}\index{matrix ensembles}. We table these pairings as follows:
      \begin{center}
        \begin{stabular}[1.5]{|c|c|c|}
          \hline
          Symmetry Type & Matrix Ensemble \\
          \hline
          $\mathrm{CUE}$ Circular Unitary Ensemble & $\U(N)$ \\
          \hline
          $\mathrm{SOE}$ Special Orthogonal Ensemble & $\SO(N)$ \\
          \hline
          $\mathrm{SpE}$ Symplectic Ensemble & $\mathrm{USp}(2N)$ \\
          \hline
          $\mathrm{COE}$ Circular Orthogonal Ensemble & $\U(N)/\O(N)$ \\
          \hline
          $\mathrm{CSE}$ Circular Symplectic Ensemble & $\U(2N)/\mathrm{USp}(2N)$ \\
          \hline
        \end{stabular}
      \end{center}

      Let $G(N)$ be a matrix ensemble and let $dA$ denote the Haar measure. For any $A \in G(N)$, let $\Phi = (\phi_{n})_{1 \le n \le N}$ denote the increasing sequence of unfolded eigenphases of $A$. One of the statistics that Katz and Sarnak investigated was the \textbf{$k$-th consecutive spacing function}\index{$k$-th consecutive spacing function} for $A$:
      \[
        \mu_{k}(\a,\b;A,G(N)) = \frac{1}{N}|\{(\t_{j+k},\t_{j}) \in \Phi^{2}:\text{$1 \le j \le N$ and $\t_{j+k}-\t_{j} \in [\a,\b]$}\}|,
      \]
      for any real $\a$ and $\b$ with $\a < \b$. They were able the prove the following result (see \todo{cite} for a proof):

      \begin{proposition}\label{prop:Katz_Sarnak_limit_distribution_independent}
        Let $G(N)$ be a matrix ensemble of type CUE, SOE, or SpE. For any real $\a$ and $\b$ with $\a < \b$ and $k \ge 1$, the limit
        \[
           \lim_{N \to \infty}\int_{G(N)}\mu_{k}(\a,\b;A,G(N))\,dA,
        \]
        exists and is independent of the matrix ensemble $G(N)$.
      \end{proposition}

      In other words, \cref{prop:Katz_Sarnak_limit_distribution_independent} says that the average value of $\mu_{k}(\a,\b;A,G(N))$, in the limit of the size of the matrices, is independent of the particular matrix ensemble chosen. This is an example of a statistic that is independent of the particular matrix ensemble. However, there are statistics that depend upon the particular matrix ensemble as well.
      
      For example, we can define the distribution of the $k$-th eigenphase over $G(N)$ as follows:
      \[
        \nu_{k}(G(N))[a,b] = dA\left(\left\{A \in G(N):\frac{\t_{k}(A)N}{2\pi} \in [a,b]\right\}\right),
      \]
      where $\t_{k}(A)$ is the $k$-th eigenphase of $A$. Katz and Sarnak showed that 
      \[
        \nu_{k}(G)[a,b] = \lim_{N \to \infty}\nu_{k}(G(N))[a,b],
      \]
      exists for all $a < b$ but that $\nu_{k}$ depends upon the particular ensemble chosen (see \todo{cite}).

      Heuristically, the statistic $\mu_{k}(A)[a,b]$ is a generalization of the two-point correlation function and so should mimic statistics about the distribution of the zeros of a single $L$-function lying high up on the critical line. That is, the statistics of \textbf{high zeros}\index{high zeros}. On the other hand, the statistic $\nu_{k}(G(N))[a,b]$ is modeling the distribution of a single zero of a family of related $L$-functions. That is, the statistics of \textbf{low zeros}\index{low zeros}. Katz and Sarnak then proposed that statistics regarding the distribution of high zeros of and single $L$-function should mimic those of $U(N)$, while statistics regarding the distribution of low zeros for a family of $L$-functions should mimic one of the matrix ensembles. For example, below are some well-studied families and their symmetry type:
      \begin{center}
        \begin{stabular}[1.5]{|c|c|c|}
          \hline
          Symmetry Type & Family \\
          \hline
          \multirow{2}{*}{$\mathrm{CUE}$} & $\{L\left(\frac{1}{2}+it,f\right):t \ge 0\}$ ordered by $t$ \\& $\{L(s,\chi):\text{$\chi \tmod{q}$ with $q \ge 1$}\}$ ordered by $q$ where $\chi$ is a Dirichlet character modulo $q \ge 1$ \\
          \hline
          \multirow{2}{*}{$\mathrm{SOE}$} & $\{L(s,f):f \in \mc{S}_{k}(\G_{0}(N)), k \ge 4\}$ ordered by $k$ where $N \ge 1$ is fixed \\& $\{L(s,f):f \in \mc{S}_{k}(\G_{0}(N)), N \ge 1\}$ ordered by $N$ where $k \ge 4$ is fixed \\
          \hline
          \multirow{2}{*}{$\mathrm{SpE}$} & $\{L(s,\chi_{d}):\text{$d$ a fundamental discriminant}\}$ ordered by $|d|$ where $\chi_{d}(n) = \legendre{d}{n}$ \\& $\{L(s,\mathrm{sym}^{2}f):f \in \mc{S}_{k}(\G_{0}(1))\}$ ordered by $k \ge 4$ \\
          \hline
        \end{stabular}
      \end{center}
      The following two questions we need to address:
      \begin{enumerate}[label=(\arabic{enumi})]
        \item What is the precisely meant by a family of $L$-functions?
        \item Given a family how do we determine its symmetry type?
      \end{enumerate}
      The first question has an unfortunate answer. There is not yet a precise definition of a family of $L$-functions. Families are determined by if interesting statistical data arises from their study. However, it is generally believed that the family should be indexed by either a real parameter, such as $y > 0$ for the unitary family $\{L(s+iy):y \ge 0\}$, or partially ordered by the conductor of the $L$-function as is the case for every other family in the table above. 
      
      As for the second question, the symmetry type can be determined but it is, in general, a difficult question. The method used by Katz and Sarnak is that for some families, one can define an analogous family over finite fields. The $L$-functions here are polynomials (in $q^{-s}$ with $q$ the order of the field), and the Grothendieck-Lefschetz trace formula implies that the $L$-functions are characteristic polynomials of matrices in the monodromy group of the family (see \todo{cite}). By the function field number field analogy, the symmetry type of this monodromy group is then assumed to by the symmetry type of the original family.
    \subsection*{Modeling $L$-functions by Characteristic Polynomials of Unitary Matrices}
      Another example of important statistical information about $\z(s)$ is the following: at a given height $t$ up the critical line, how are the the real and imaginary parts of $\log\z(\frac{1}{2}+it)$ distributed? In the limit as we move up the critical line, this question is famously answered by \textbf{Selberg's central limit theorem}\index{Selberg's central limit theorem} (see \todo{cite}):

      \begin{theorem}[Selberg's central limit theorem]
        For any rectangle $B \in \C$,
        \[
          \lim_{T \to \infty}\frac{1}{T}\mc{L}\left(\left\{t:t \in [T,2T],\frac{\log\z(\frac{1}{2}+it)}{\sqrt{\frac{1}{2}\log\log(T)}} \in B\right\}\right) = \frac{1}{2\pi}\iint_{B}e^{-\frac{1}{2}(x^{2}+y^{2})}\,dx\,dy.
        \]
      \end{theorem}

      We interpret the left-hand side in Selberg's central limit theorem as the limiting value distribution, and the right-hand side as two independent Gaussian distributions with unit variance and zero mean. So as we move up the critical line, the real and imaginary parts of $\frac{\log\z(\frac{1}{2}+it)}{\sqrt{\frac{1}{2}\log\log(T)}}$ both independently tend to normal distributions. Interestingly, numerical computations show that when $T \sim t_{10^{20}}$ the computed values are still quite far from the Gaussian distributions. So the convergence in Selberg's central limit theorem is very slow. This does, however, beg the question of how $\log\z(\frac{1}{2}+it)$ should be modeled by random matrices when $t$ is large but finite. The answer is quite natural.
      \fi