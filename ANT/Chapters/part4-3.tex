\chapter{Explicit Formulas \& Prime Number Theorems}
  Our main aim is to prove the prime number theorem and its variant for primes restricted to a certain residue class, the Siegel–Walfisz theorem, in the classical manner. These results will follow from explicit formulas for Chebyshev functions. After deriving these results, we prove the prime number theorem and the Siegel–Walfisz theorem.
  \section{Explicit Formulas for Chebyshev Functions}
    \subsection*{The Explicit Formula for \texorpdfstring{$\psi(x)$}{$\psi(x)$}}
      The \textbf{Chebychef function}\index{Chebychef function} $\psi(x)$, for $x > 1$, is defined by
      \[
        \psi(x) = \sum_{n \le x}\L(n).
      \]
      The explicit formula for $\psi(x)$ will be obtained by applying truncated Perron's formula to the logarithmic derivative of $\z(s)$. Since $\psi(x)$ is discontinuous when $x$ is a prime power, we need to work with a slightly modified function to apply the Mellin inversion formula. Define $\psi_{0}(x)$ by
      \[
        \psi_{0}(x) = \begin{cases} \psi(x) & \text{if $x$ is not a prime power}, \\ \psi(x)-\frac{1}{2}\L(x) & \text{if $x$ is a prime power}. \end{cases}
      \]
      Equivalently, $\psi_{0}(x)$ is $\psi(x)$ except that its value is halfway between the limit values when $x$ is a prime power. Stated another way, if $x$ is a prime power the last term in the sum for $\psi_{0}(x)$ is multiplied by $\frac{1}{2}$. The \textbf{explicit formula}\index{explicit formula} for $\psi(x)$ is the following:

      \begin{theorem}[Explicit formula for $\psi(x)$]
        For $x \ge 2$,
        \[
          \psi_{0}(x) = x-\sum_{\rho}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2}),
        \]
        where $\rho$ runs over the nontrivial zeros of $\z(s)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{theorem}

      A few comments are in order before we prove the explicit formula for $\psi(x)$. First, since $\rho$ is conjectured to be of the form $\rho = \frac{1}{2}+i\g$ under the Riemann hypothesis, $x$ is conjectured to be the main term in the explicit formula. The constant $\frac{\z'}{\z}(0)$ can be shown to be $\log(2\pi)$ (see \cite{davenport1980multiplicative} for a proof). Also, using the Taylor series of the logarithm, the last term can be expressed as
      \[
        \frac{1}{2}\log(1-x^{-2}) = \frac{1}{2}\sum_{m \ge 1}(-1)^{m-1}\frac{(-x^{-2})^{m}}{m} = \sum_{m \ge 1}(-1)^{2m-1}\frac{x^{-2m}}{2m} = \sum_{m \ge 1}\frac{x^{-2m}}{-2m} = \sum_{\w}\frac{x^{\w}}{\w},
      \]
      where $\w$ runs over the trivial zeros of $\z(s)$. We will now prove the explicit formula for $\psi(x)$:

      \begin{proof}[Proof of the explicit formula for $\psi(x)$]
        Recalling \cref{equ:Drichlet_series_log_derivative_zeta} and that $\psi(x) = \sum_{n \le x}\L(n)$, applying truncated Perron's formula to $-\frac{\z'}{\z}(s)$ gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_1}
          \psi_{0}(x)-J(x,T) \ll x^{c}\sum_{\substack{n \ge 1 \\ n \neq x}}\frac{\L(n)}{n^{c}}\min\left(1,\frac{1}{T\left|\log\left(\frac{x}{n}\right)\right|}\right)+\d_{x}\L(x)\frac{c}{T},
        \end{equation}
        where
        \[
          J(x,T) = \frac{1}{2\pi i}\int_{c-iT}^{c+iT}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s},
        \]
        $c > 1$, and it is understood that $\d_{x} = 0$ unless $x$ is a prime power. Take $T > 2$ not coinciding with the ordinate of a nontrivial zero and let $c = 1+\frac{1}{\log(x^{2})}$ so that $x^{c} = \sqrt{e}x$. The first step is to estimate the right-hand side of \cref{equ:explicit_formula_zeta_proof_1}. We deal with the terms corresponding to $n$ such that $n$ is boudned away from $x$ before anything else. So suppose $n \le \frac{3}{4}x$ or $n \ge \frac{5}{4}x$. For these $n$, $\log\left(\frac{x}{n}\right)$ is bounded away from zero so that their contribution is
        \begin{equation}\label{equ:explicit_formula_zeta_proof_2}
          \ll \frac{x^{c}}{T}\sum_{n \ge 1}\frac{\L(n)}{n^{c}} \ll \frac{x^{c}}{T}\left(-\frac{\z'}{\z}(c)\right) \ll \frac{x\log(x)}{T},
        \end{equation}
        where the last estimate follows from \cref{equ:classical_zero-free_region_zeta_1} and our choice of $c$. Now we deal with the terms $n$ close to $x$. Consider those $n$ for which $\frac{3}{4}x < n < x$. Let $x_{1}$ be the largest prime power less than $x$. We may also suppose $\frac{3}{4}x < x_{1} < x$ since otherwise $\L(n) = 0$ and these terms do not contribute anything. Moreover, $\frac{x^{c}}{n^{c}} \ll 1$. For the term $n = x_{1}$, we have
        \[
          \log\left(\frac{x}{n}\right) = -\log\left(1-\frac{x-x_{1}}{x}\right) \ge \frac{x-x_{1}}{x},
        \]
        where we have obtained the inequality by using Taylor series of the logarithim truncated after the first term. The contribution of this term is then
        \begin{equation}\label{equ:explicit_formula_zeta_proof_3}
          \ll \L(x_{1})\min\left(1,\frac{x}{T(x-x_{1})}\right) \ll \log(x)\min\left(1,\frac{x}{T(x-x_{1})}\right).
        \end{equation}
        For the other such $n$, we can write $n = x_{1}-v$, where $v$ is an integer satisfying $0 < v < \frac{1}{4}x$, so that
        \[
          \log\left(\frac{x}{n}\right) \ge \log\left(\frac{x_{1}}{n}\right) = -\log\left(1-\frac{v}{x_{1}}\right) \ge \frac{v}{x_{1}},
        \]
        where we have obtained the latter inequality by using Taylor series of the logarithim truncated after the first term. The contribution for these $n$ is then
        \begin{equation}\label{equ:explicit_formula_zeta_proof_4}
          \ll \sum_{0 < v < \frac{1}{4}x}\L(x_{1}-v)\frac{x_{1}}{Tv} \ll \frac{x}{T}\sum_{0 < v < \frac{1}{4}x}\frac{\L(x_{1}-v)}{v} \ll \frac{x\log(x)}{T}\sum_{0 < v < \frac{1}{4}x}\frac{1}{v} \ll \frac{x\log^{2}(x)}{T}.
        \end{equation}
        The contribution for those $n$ for which $x < n < \frac{5}{4}x$ is handeled in exactly the same way with $x_{1}$ being the least prime power larger than $x$. Let $\<x\>$ be the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power. Combining \cref{equ:explicit_formula_zeta_proof_3,equ:explicit_formula_zeta_proof_4} with our previous comment, the contribution for those $n$ with $\frac{3}{4}x < n < \frac{5}{4}x$ is
        \begin{equation}\label{equ:explicit_formula_zeta_proof_5}
          \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Putting \cref{equ:explicit_formula_zeta_proof_2,equ:explicit_formula_zeta_proof_5} together and noticing that the error term in \cref{equ:explicit_formula_zeta_proof_2} is absorbed by the second error term in \cref{equ:explicit_formula_zeta_proof_5}, we obtain
        \begin{equation}\label{equ:explicit_formula_zeta_proof_6}
          \psi_{0}(x)-J(x,T) \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        This is the first part of the proof. Now we estimate $J(x,T)$ by appealing to the residue theorem. Let $U \ge 1$ be an odd integer. Let $\W$ be the region enclosed by the contours $\eta_{1},\ldots,\eta_{4}$ in \cref{fig:explict_formula_zeta_contour} and set $\eta = \sum_{1 \le i \le 4}\eta_{i}$ so that $\eta = \del \W$.

        \begin{figure}[ht]
          \centering
          \begin{tikzpicture}[scale=2]
            \def\xmin{-3.5} \def\xmax{1.5}
            \def\ymin{-2} \def\ymax{2}
            \draw[thick] (\xmin,0) -- (\xmax,0);
            \draw[thick] (0,\ymin) -- (0,\ymax);
            \draw[dashed] (0.5,\ymin) -- (0.5,\ymax);

            \draw[->-] (1,-1.5) -- (1,1.5);
            \draw[->-] (1,1.5) -- (-3,1.5);
            \draw[->-] (-3,1.5) -- (-3,-1.5);
            \draw[->-] (-3,-1.5) -- (1,-1.5);

            \node at (1,0) [below right] {\tiny{$\eta_{1}$}};
            \node at (-1,1.5) [above] {\tiny{$\eta_{2}$}};
            \node at (-3,0) [below left] {\tiny{$\eta_{3}$}};
            \node at (-1,-1.5) [below] {\tiny{$\eta_{4}$}};

            \node at (1,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (1,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,-1.5) [circle,fill,inner sep=1.5pt]{};

            \node at (1,-1.5) [below left] {\tiny{$c-iT$}};
            \node at (1,1.5) [above] {\tiny{$c+iT$}};
            \node at (0.5,1.5) [above left] {\tiny{$\frac{1}{2}+iT$}};
            \node at (-3,1.5) [above] {\tiny{$-U+iT$}};
            \node at (-3,-1.5) [below left] {\tiny{$-U-iT$}};
            \node at (0.5,-1.5) [below left] {\tiny{$\frac{1}{2}-iT$}};
          \end{tikzpicture}
          \caption{Contour for the explict formula for $\psi(x)$}
          \label{fig:explict_formula_zeta_contour}
        \end{figure}

        We may express $J(x,T)$ as
        \[
          J(x,T) = \frac{1}{2\pi i}\int_{\eta_{1}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s}.
        \]
        The residue theorem together with the explicit formula for $\frac{\z'}{\z}(s)$ and \cref{cor:logarithmic_derivative_of_gamma} imply
        \begin{equation}\label{equ:explicit_formula_zeta_proof_7}
          J(x,T) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\sum_{0 < 2m < U}\frac{x^{-2m}}{-2m}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $\z$. We will estimate $J(x,T)$ by estimating the remaining integral. By \cref{cor:Riemann_von_Mangoldt_corollary} (i), the number of nontrivial zeros satisfying $|\g-T| < 1$ is $O(\log(T))$. Among the ordinates of these zeros, there must be a gap of size $\gg \frac{1}{\log(T)}$. Upon varrying $T$ by a bounded amount (we are varrying in the interval $[T-1,T+1]$) so that it belongs to this gap, we can additionally ensure
        \[
          |\g-T| \gg \frac{1}{\log(T)},
        \]
        for all the nontrivial zeros of $\z(s)$. To estimate part of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$, \cref{equ:Riemann_von_Mangoldt_14} with $s = \s+iT$ for $-1 \le \s \le 2$ gives
        \[
          \frac{\z'}{\z}(s) = \sum_{|\g-T| < 1}\frac{1}{s-\rho}+O(\log(T)).
        \]
        By our choice of $T$, $|s-\rho| \ge |\g-T| \gg \frac{1}{\log(T)}$ so that each term in the sum is $O(\log(T))$. There are at most $O(\log(T))$ such terms by \cref{cor:Riemann_von_Mangoldt_corollary} (i), so we find that
        \[
          \frac{\z'}{\z}(s) = O(\log^{2}(T)),
        \]
        for $-1 \le \s \le 2$. It follows that the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with  $-1 \le \s \le c$ (as $x \ge 2$ our choice of $c$ ensures $c < 2$) contribute
        \begin{equation}\label{equ:explicit_formula_zeta_proof_8}
          \ll \frac{\log^{2}(T)}{T}\int_{-1}^{c}x^{\s}\,d\s \ll \frac{\log^{2}(T)}{T}\int_{-\infty}^{c}x^{\s}\,d\s \ll \frac{x\log^{2}(T)}{T\log(x)},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim T$ and in the last estimate we have used the choice of $c$. To estimate the remainder of the horizontal integrals, we need a bound for $\frac{\z'}{\z}(s)$ when $\s < -1$ and away from the trivial zeros. To this end, write the functional equation for $\z(s)$ in the form
        \[
          \z(s) = \pi^{s-1}\frac{\G\left(\frac{1-s}{2}\right)}{\G\left(\frac{s}{2}\right)}\z(1-s),
        \]
        and take the logarithmic derivative to get
        \[
          \frac{\z'}{\z}(s) = \log(\pi)+\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{s}{2}\right)+\frac{\z'}{\z}(1-s).
        \]
        Let $s$ be such that $\s < -1$ and suppose $s$ is distance $\frac{1}{2}$ away from the trivial zeros. We will estimate every term on the right-hand side of the previous identity. The first term is contant and the last term is bounded by \cref{equ:Drichlet_series_log_derivative_zeta}. As for the digamma terms, since $s$ is away from the trivial zeros, \cref{equ:approximtion_for_digamma} implies $\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right) = O(\log|1-s|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s}{2}\right) = O(\log|s|)$. However, as $\s < -1$ and $s$ is away from the trivial zeros, $s$ and $1-s$ are bounded away from zero so that $\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right) = O(\log|s|)$. Putting these estimates together gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_9}
          \frac{\z'}{\z}(s) \ll \log(|s|),
        \end{equation}
        for $\s < -1$. Using \cref{equ:explicit_formula_zeta_proof_9}, the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with $-U \le \s \le -1$ contribute
        \begin{equation}\label{equ:explicit_formula_zeta_proof_10}
          \ll \frac{\log(T)}{T}\int_{-U}^{-1}x^{\s}\,d\s \ll \frac{\log(T)}{Tx\log(x)},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim T$. Combining \cref{equ:explicit_formula_zeta_proof_8,equ:explicit_formula_zeta_proof_10} gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_11}
          \frac{1}{2\pi i}\int_{\eta_{2}+\eta_{4}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s} \ll \frac{x\log^{2}(T)}{T\log(x)}+\frac{\log(T)}{Tx\log(x)} \ll \frac{x\log^{2}(T)}{T\log(x)}.
        \end{equation}
        To estimate the vertical integral, we use \cref{equ:explicit_formula_zeta_proof_9} again to conclude that
        \begin{equation}\label{equ:explicit_formula_zeta_proof_12}
          \frac{1}{2\pi i}\int_{\eta_{3}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s} \ll \frac{\log(U)}{U}\int_{-T}^{T}x^{-U}\,dt \ll \frac{T\log(U)}{Ux^{U}},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim U$. Combining \cref{equ:explicit_formula_zeta_proof_7,equ:explicit_formula_zeta_proof_11,equ:explicit_formula_zeta_proof_12} and taking the limit as $U \to \infty$, the error term in \cref{equ:explicit_formula_zeta_proof_12} vanishes and the sum over $m$ in \cref{equ:explicit_formula_zeta_proof_7} evaulates to $\frac{1}{2}\log(1-x^{-2})$ (as we have already mentioned) giving
        \begin{equation}\label{equ:explicit_formula_zeta_proof_13}
          J(x,T) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(T)}{T\log(x)}.
        \end{equation}
        Substiuting \cref{equ:explicit_formula_zeta_proof_13} into \cref{equ:explicit_formula_zeta_proof_6}, we at last obtain
        \begin{equation}\label{equ:explicit_formula_zeta_proof_14}
          \psi_{0}(x) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        where the second to last term on the right-hand side is obtained by combining error term in \cref{equ:explicit_formula_zeta_proof_11} with the first error term in \cref{equ:explicit_formula_zeta_proof_6}. The theorem follows by taking the limit as $T \to \infty$.
      \end{proof}

      Note that the convergence of the right-hand side in the explicit formula for $\psi(x)$ is uniform in any interval not containing a prime power since $\psi(x)$ is continuous there. Moreover, we have an approximate formula for $\psi(x)$ as a corollary:

      \begin{corollary}\label{cor:explicit_formula_zeta_corollary}
         For $x \ge 2$ and $T > 2$,
        \[
           \psi_{0}(x) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        where $\rho$ runs over the nontrivial zeros of $\z(s)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{corollary}
      \begin{proof}
        This is \cref{equ:explicit_formula_zeta_proof_14}.
      \end{proof}
    \subsection*{The Explicit Formula for \texorpdfstring{$\psi(x,\chi)$}{$\psi(x,\chi)$}}
      Let $\chi$ be a Dirichlet character modulo $m > 1$. The \textbf{Dirichlet-Chebychef function} $\psi(x,\chi)$, for $x > 1$, is defined by
      \[
        \psi(x,\chi) = \sum_{n \le x}\chi(n)\L(n).
      \]
      This object plays the analogous role of $\psi(x)$ but for Dirichlet $L$-functions. Accordingly, we will derive an explicit formula for $\psi(x,\chi)$ in a similar manner to that of $\psi(x)$. Because $\psi(x,\chi)$ is discontinuous when $x$ is a prime power, we also introduce a slightly modified function. Define $\psi_{0}(x,\chi)$ by
      \[
        \psi_{0}(x,\chi) = \begin{cases} \psi(x,\chi) & \text{if $x$ is not a prime power}, \\ \psi(x,\chi)-\frac{1}{2}\chi(x)\L(x) & \text{if $x$ is a prime power}. \end{cases}
      \]
      Thus $\psi_{0}(x,\chi)$ is $\psi(x,\chi)$ except that its value is halfway between the limit values when $x$ is a prime power. The \textbf{explicit formula}\index{explicit formula} for $\psi(x,\chi)$ is the following:

      \begin{theorem}[Explicit formula for $\psi(x,\chi)$]
        Let $\chi$ be a primitive Dirichlet character of conductor $q > 1$. Then for $x \ge 2$,
        \[
          \psi_{0}(x,\chi) = -\sum_{\rho}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)+\tanh^{-1}(x^{-1}),
        \]
        if $\chi$ is odd, and
        \[
          \psi_{0}(x,\chi) = -\sum_{\rho}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2}),
        \]
        if $\chi$ is even where $b(\chi)$ is the constant term in the Laurent series of $\frac{L'}{L}(s,\chi)$. In both expressions, $\rho$ runs over the nontrivial zeros of $L(s,\chi)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{theorem}

      As for $\psi(x)$, a few comments are in order. Unlike the explicit formula for $\psi(x)$, there is no main term $x$ in the explicit formula for $\psi(x,\chi)$. This is because $L(s,\chi)$ does not have a pole at $s = 1$. The constants $\frac{L'}{L}(0,\chi)$ and $b(\chi)$ can be expressed in terms of $B(\chi)$ (see \cite{davenport1980multiplicative} for a proof). Also, in the case $\chi$ is odd the Taylor series of the inverse hyperbolic tangent lets us write
      \[
        \tanh^{-1}(x^{-1}) = \sum_{m \ge 1}\frac{x^{-(2m-1)}}{2m-1} = -\sum_{m \ge 1}\frac{x^{-(2m-1)}}{-(2m-1)} = -\sum_{\w}\frac{x^{\w}}{\w},
      \]
      where $\w$ runs over the trivial zeros of $L(s,\chi)$. In the case $\chi$ is even, $\frac{1}{2}\log(1-x^{-2})$ accounts for the contribution of the trivial zeros just as for $\z(s)$. We will now prove the explicit formula for $\psi(x,\chi)$:

      \begin{proof}[Proof of the explicit formula for $\psi(x,\chi)$]
        Recalling \cref{equ:Drichlet_series_log_derivative_Dirichlet} and that $\psi(x,\chi) = \sum_{n \le x}\chi(n)\L(n)$, truncated Perron's formula applied to $-\frac{L'}{L}(s,\chi)$ gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_1}
          \psi_{0}(x,\chi)-J(x,T,\chi) \ll x^{c}\sum_{\substack{n \ge 1 \\ n \neq x}}\frac{\chi(n)\L(n)}{n^{c}}\min\left(1,\frac{1}{T\left|\log\left(\frac{x}{n}\right)\right|}\right)+\d_{x}\chi(x)\L(x)\frac{c}{T},
        \end{equation}
        where
        \[
          J(x,T,\chi) = \frac{1}{2\pi i}\int_{c-iT}^{c+iT}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \]
        $c > 1$, and it is understood that $\d_{x} = 0$ unless $x$ is a prime power. Take $T > 2$ not coinciding with the ordinate of a nontrivial zero and let $c = 1+\frac{1}{\log(x^{2})}$ so that $x^{c} = \sqrt{e}x$. We will estimate the right-hand side of \cref{equ:explicit_formula_Dirichlet_proof_1}. First, we estimate the terms corresponding to $n$ such that $n$ is boudned away from $x$. So suppose $n \le \frac{3}{4}x$ or $n \ge \frac{5}{4}x$. For these $n$, $\log\left(\frac{x}{n}\right)$ is bounded away from zero so that their contribution is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_2}
          \ll \frac{x^{c}}{T}\sum_{n \ge 1}\frac{\chi(n)\L(n)}{n^{c}} \ll \frac{x^{c}}{T}\left(-\frac{\z'}{\z}(c)\right) \ll \frac{x\log(x)}{T},
        \end{equation}
        where the middle estimate follows from \cref{equ:Drichlet_series_log_derivative_zeta} and the last estimate follows from \cref{equ:classical_zero-free_region_zeta_1} and our choice of $c$. Now we estimate the terms $n$ close to $x$. So consider those $n$ for which $\frac{3}{4}x < n < x$ and let $x_{1}$ be the largest prime power less than $x$. We may also assume $\frac{3}{4}x < x_{1} < x$ since otherwise $\L(n) = 0$ and these terms do not contribute anything. Moreover, $\frac{x^{c}}{n^{c}} \ll 1$. For the term $n = x_{1}$, we have the estimate
        \[
          \log\left(\frac{x}{n}\right) = -\log\left(1-\frac{x-x_{1}}{x}\right) \ge \frac{x-x_{1}}{x},
        \]
        where we have obtained the inequality by using Taylor series of the logarithim truncated after the first term. The contribution of this term is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_3}
          \ll \chi(x_{1})\L(x_{1})\min\left(1,\frac{x}{T(x-x_{1})}\right) \ll \log(x)\min\left(1,\frac{x}{T(x-x_{1})}\right).
        \end{equation}
        For the other $n$, we write $n = x_{1}-v$, where $v$ is an integer satisfying $0 < v < \frac{1}{4}x$, so that
        \[
          \log\left(\frac{x}{n}\right) \ge \log\left(\frac{x_{1}}{n}\right) = -\log\left(1-\frac{v}{x_{1}}\right) \ge \frac{v}{x_{1}},
        \]
        where we have obtained the latter inequality by using Taylor series of the logarithim truncated after the first term. The contribution for these $n$ is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_4}
          \ll \sum_{0 < v < \frac{1}{4}x}\chi(x_{1}-v)\L(x_{1}-v)\frac{x_{1}}{Tv} \ll \frac{x}{T}\sum_{0 < v < \frac{1}{4}x}\frac{\L(x_{1}-v)}{v} \ll \frac{x\log(x)}{T}\sum_{0 < v < \frac{1}{4}x}\frac{1}{v} \ll \frac{x\log^{2}(x)}{T}.
        \end{equation}
        The contribution for those $n$ for which $x < n < \frac{5}{4}x$ is handeled in exactly the same way with $x_{1}$ being the least prime power larger than $x$. Let $\<x\>$ be the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power. Combining \cref{equ:explicit_formula_Dirichlet_proof_3,equ:explicit_formula_Dirichlet_proof_4} with our previous comment, the contribution for those $n$ with $\frac{3}{4}x < n < \frac{5}{4}x$ is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_5}
          \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Putting \cref{equ:explicit_formula_Dirichlet_proof_2,equ:explicit_formula_Dirichlet_proof_5}, the error term in \cref{equ:explicit_formula_Dirichlet_proof_2} is absorbed by the second error term in \cref{equ:explicit_formula_Dirichlet_proof_5} and we obtain
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_6}
          \psi_{0}(x,\chi)-J(x,T,\chi) \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Now we estimate $J(x,T,\chi)$ by using the residue theorem. Let $U \ge 1$ be an integer with $U$ is even if $\chi$ is odd and odd if $\chi$ is even. Let $\W$ be the region enclosed by the contours $\eta_{1},\ldots,\eta_{4}$ in \cref{fig:explict_formula_Dirichlet_contour} and set $\eta = \sum_{1 \le i \le 4}\eta_{i}$ so that $\eta = \del \W$. We may write $J(x,T,\chi)$ as
        \[
          J(x,T,\chi) = \frac{1}{2\pi i}\int_{\eta_{1}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s}.
        \]

        \begin{figure}[ht]
          \centering
          \begin{tikzpicture}[scale=2]
            \def\xmin{-3.5} \def\xmax{1.5}
            \def\ymin{-2} \def\ymax{2}
            \draw[thick] (\xmin,0) -- (\xmax,0);
            \draw[thick] (0,\ymin) -- (0,\ymax);
            \draw[dashed] (0.5,\ymin) -- (0.5,\ymax);

            \draw[->-] (1,-1.5) -- (1,1.5);
            \draw[->-] (1,1.5) -- (-3,1.5);
            \draw[->-] (-3,1.5) -- (-3,-1.5);
            \draw[->-] (-3,-1.5) -- (1,-1.5);

            \node at (1,0) [below right] {\tiny{$\eta_{1}$}};
            \node at (-1,1.5) [above] {\tiny{$\eta_{2}$}};
            \node at (-3,0) [below left] {\tiny{$\eta_{3}$}};
            \node at (-1,-1.5) [below] {\tiny{$\eta_{4}$}};

            \node at (1,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (1,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,-1.5) [circle,fill,inner sep=1.5pt]{};

            \node at (1,-1.5) [below left] {\tiny{$c-iT$}};
            \node at (1,1.5) [above] {\tiny{$c+iT$}};
            \node at (0.5,1.5) [above left] {\tiny{$\frac{1}{2}+iT$}};
            \node at (-3,1.5) [above] {\tiny{$-U+iT$}};
            \node at (-3,-1.5) [below left] {\tiny{$-U-iT$}};
            \node at (0.5,-1.5) [below left] {\tiny{$\frac{1}{2}-iT$}};
          \end{tikzpicture}
          \caption{Contour for the explict formula for $\psi(x)$}
          \label{fig:explict_formula_Dirichlet_contour}
        \end{figure}

        We now seperate the cases that $\chi$ is even or odd. If $\chi$ is odd, then the residue theorem together with the explicit formula for $\frac{L'}{L}(s,\chi)$ and \cref{cor:logarithmic_derivative_of_gamma} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_7}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)-\sum_{0 < 2m+1 < U}\frac{x^{-(2m-1)}}{-(2m-1)}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $L(s,\chi)$. If $\chi$ is even, then there is a minor complication because $L(s,\chi)$ has a simple zero at $s = 0$ and so the integrand has a double pole at $s = 0$. To find the residue, the Laurent series are
        \[
          \frac{L'}{L}(s,\chi) = \frac{1}{s}+b(\chi)+\cdots \quad \text{and} \quad \frac{x^{s}}{s} = \frac{1}{s}+\log(x)+\cdots,
        \]
        and thus the residue of the integrand is $-(\log(x)+b(\chi))$. Now as before, the residue theorem together with the explicit formula for $\frac{L'}{L}(s,\chi)$ and \cref{cor:logarithmic_derivative_of_gamma} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_7'}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\sum_{0 < 2m < U}\frac{x^{-2m}}{-2m}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $L(s,\chi)$. We now estimate the remaining integrals in \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_7'}. For this estimate, the parity of $\chi$ does not matter so we make no such restriction. By \cref{cor:Riemann_von_Mangoldt_Dirichlet_L-functions_corollary} (i) and that $\log(q(T+2)) \sim \log(qT)$, the number of nontrivial zeros satisfying $|\g-T| < 1$ is $O(\log(qT))$. Among the ordinates of these zeros, there must be a gap of size $\gg \frac{1}{\log(qT)}$. Upon varrying $T$ by a bounded amount (we are varrying in the interval $[T-1,T+1]$) so that it belongs to this gap, we can additionally ensure
        \[
          |\g-T| \gg \frac{1}{\log(qT)},
        \]
        for all the nontrivial zeros of $L(s,\chi)$. To estimate part of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$, \cref{equ:Riemann_von_Mangoldt_Dirichlet_L-functions_13} with $s = \s+iT$ for $-1 \le \s \le 2$ gives
        \[
          \frac{L'}{L}(s,\chi) = \sum_{|\g-T| < 1}\frac{1}{s-\rho}+O(\log(qT)).
        \]
        Our choice of $T$ implies $|s-\rho| \ge |\g-T| \gg \frac{1}{\log(qT)}$ so that each term in the sum is $O(\log(qT))$. As there are at most $O(\log(qT))$ such terms by \cref{cor:Riemann_von_Mangoldt_Dirichlet_L-functions_corollary} (i), we have
        \[
          \frac{L'}{L}(s,\chi) = O(\log^{2}(qT)),
        \]
        for $-1 \le \s \le 2$. It follows that the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with  $-1 \le \s \le c$ (as $x \ge 2$ our choice of $c$ ensures $c < 2$) contribute
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_8}
          \ll \frac{\log^{2}(qT)}{T}\int_{-1}^{c}x^{\s}\,d\s \ll \frac{\log^{2}(qT)}{T}\int_{-\infty}^{c}x^{\s}\,d\s \ll \frac{x\log^{2}(qT)}{T\log(x)},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim T$ and in the last estimate we have used the choice of $c$. To estimate the remainder of the horizontal integrals, we require a bound for $\frac{L'}{L}(s,\chi)$ when $\s < -1$ and away from the trivial zeros. To find such a bound, write the functional equation for $L(s,\chi)$ in the form
        \[
          L(s,\chi) = \frac{\e_{\chi}}{i^{\mf{a}}}q^{\frac{1}{2}-s}\pi^{s-1}\frac{\G\left(\frac{(1-s)+\mf{a}}{2}\right)}{\G\left(\frac{s+\mf{a}}{2}\right)}L(1-s,\chi),
        \]
        and take the logarithmic derivative to get
        \[
          \frac{L'}{L}(s,\chi) = -\log(q)+\log(\pi)+\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right)+\frac{L'}{L}(1-s,\chi).
        \]
        Now let $s$ be such that $\s < -1$ and suppose $s$ is distance $\frac{1}{2}$ away from the trivial zeros. We will estimate every term on the right-hand side of the identity above. The second term is contant and the last term is bounded by \cref{equ:Drichlet_series_log_derivative_Dirichlet}. For the digamma terms, $s$ is away from the trivial zeros so \cref{equ:approximtion_for_digamma} implies $\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right) = O(\log|(1-s)+\mf{a}|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right) = O(\log|s+\mf{a}|)$. However, as $\s < -1$ and $s$ is away from the trivial zeros, $s+\mf{a}$ and $(1-s)+\mf{a}$ are bounded away from zero so that $\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right) = O(\log|s|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right) = O(\log|s|)$. Putting these estimates together with the first term yields
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_9}
          \frac{L'}{L}(s,\chi) \ll \log(q|s|),
        \end{equation}
        for $\s < -1$. Using \cref{equ:explicit_formula_Dirichlet_proof_9}, the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with $-U \le \s \le -1$ contribute
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_10}
          \ll \frac{\log(qT)}{T}\int_{-U}^{-1}x^{\s}\,d\s \ll \frac{\log(qT)}{Tx\log(x)},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim T$. Combining \cref{equ:explicit_formula_Dirichlet_proof_8,equ:explicit_formula_Dirichlet_proof_10} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_11}
          \frac{1}{2\pi i}\int_{\eta_{2}+\eta_{4}}-\frac{L'}{L}(s)x^{s}\,\frac{ds}{s} \ll \frac{x\log^{2}(qT)}{T\log(x)}+\frac{\log(qT)}{Tx\log(x)} \ll \frac{x\log^{2}(qT)}{T\log(x)}.
        \end{equation}
        To estimate the vertical integral, we use \cref{equ:explicit_formula_Dirichlet_proof_9} again to conclude that
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_12}
          \frac{1}{2\pi i}\int_{\eta_{3}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s} \ll \frac{\log(qU)}{U}\int_{-T}^{T}x^{-U}\,dt \ll \frac{T\log(qU)}{Ux^{U}},
        \end{equation}
        where in the first estimate we have used the fact that $s \sim U$. Combining \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_11,equ:explicit_formula_Dirichlet_proof_12} and taking the limit as $U \to \infty$, the error term in \cref{equ:explicit_formula_Dirichlet_proof_12} vanishes and the sum over $m$ in \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_7'} evaulates to $-\tanh^{-1}(x^{-1})$ or $\frac{1}{2}\log(1-x^{-2})$ respectively (as we have already mentioned) giving
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_13}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(qT)}{T\log(x)},
        \end{equation}
        if $\chi$ is odd, and
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_13'}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(qT)}{T\log(x)},
        \end{equation}
        if $\chi$ is even.
        Substiuting \cref{equ:explicit_formula_Dirichlet_proof_13,equ:explicit_formula_Dirichlet_proof_13'} into \cref{equ:explicit_formula_Dirichlet_proof_6} in the respective cases, we obtain
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_14}
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        if $\chi$ is odd, and
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_14'}
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        if $\chi$ is even, and where the second to last term on the right-hand side in both equations are obtained by combining error term in \cref{equ:explicit_formula_Dirichlet_proof_11} with the first error term in \cref{equ:explicit_formula_Dirichlet_proof_6}. The theorem follows by taking the limit as $T \to \infty$.
      \end{proof}

      As was the case for $\psi(x)$, the convergence of the right-hand side in the explicit formula for $\psi(x,\chi)$ is uniform in any interval not containing a prime power since $\psi(x,\chi)$ is continuous there. Moreover, there is an approximate formula for $\psi(x,\chi)$ as a corollary:

      \begin{corollary}\label{cor:explicit_formula_Dirichlet_corollary_primitive}
         Let $\chi$ be a primitive Dirichlet character of conductor $q > 1$. Then for $x \ge 2$ and $T > 2$,
        \[
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        if $\chi$ is odd, and
        \[
           \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        if $\chi$ is even, and where in both formulas $\rho$ runs over the nontrivial zeros of $L(s,\chi)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{corollary}
      \begin{proof}
        This is just \cref{equ:explicit_formula_Dirichlet_proof_14,equ:explicit_formula_Dirichlet_proof_14'}.
      \end{proof}

      It turns out that \cref{cor:explicit_formula_Dirichlet_corollary_primitive} holds for all $\chi$, not necessarily primitive, under a very mild restriction:

      \begin{corollary}\label{cor:explicit_formula_Dirichlet_corollary}
         Let $\chi$ be a Dirichlet character modulo $m > 1$. Then for $2 \le T \le x$,
        \[
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{L'}{L}(0,\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(xmT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        if $\chi$ is odd, and
        \[
           \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xmT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        if $\chi$ is even, and where in both formulas $\rho$ runs over the nontrivial zeros of $L(s,\chi)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{corollary}
      \begin{proof}
        Let $\wtilde{\chi}$ be the primitive character inducing $\chi$ and denote its conductor by $q$. We estimate
        \begin{equation}\label{equ:difference_between_Dirichlet-Chebychefs}
          \begin{aligned}
            |\psi(x,\chi)-\psi(x,\wtilde{\chi})| &\le \sum_{\substack{n \le x \\ (n,m) > 1}}\L(n) \\
            &= \sum_{p \mid m}\sum_{\substack{v \ge 1 \\ p^{v} \le x}}\log(p) \\
            &\ll \log(x)\sum_{p \mid m}\log(p) \\
            &\ll \log(x)\log(m) \\
            &\ll \log^{2}(xm),
          \end{aligned}
        \end{equation}
        where the third line holds because $p^{v} \le x$ implies $v \le \frac{\log(x)}{\log(p)}$ so that there are $O(\log(x))$ many terms in the inner sum, the fourth line holds since $\prod_{p \mid m}p \ll m$, and in the last line we have used the simple estimates $\log(x) \ll \log(xm)$ and $\log(m) \ll \log(xm)$. Therefore the difference between $\psi(x,\chi)$ and $\psi(x,\wtilde{\chi})$ is $O(\log^{2}(xm))$. Now for $2 \le T \le x$, $\log^{2}(xm) \ll \frac{x\log^{2}(xmT)}{T}$. As $q \le m$, $\frac{x\log^{2}(xqT)}{T} \sim \frac{x\log^{2}(xmT)}{T}$ so that the difference is absorbed into the first error term. Moreover, $\psi(x,\chi) \sim \psi_{0}(x,\chi)$ for all $\chi$, so upon substituting these estimates into \cref{cor:explicit_formula_Dirichlet_corollary_primitive}, the proof is complete.
      \end{proof}

      There is one final comment we need to make. It appears from the explict formula for $\psi(x,\chi)$ that there is no main term unlike that for $\psi(x)$. This is true if $\chi$ is not quadratic, but the situation is more subtle otherwise. Indeed, if $\chi$ is quadratic then $L(s,\chi)$ may exhibit a Siegel zeros $\b_{1}$. Conjecturally, this zero should not exist and so there should be no main term, but if it does Siegel's theorem implies that $\b_{1}$ is very close to $1$. This means that the term in the explicit formula for $\psi(s,\chi)$ corresponding to the Siegel zeros acts like a main term. It is often useful for applications to make this apparent and write
      \[
        \sum_{\rho}\frac{x^{\rho}}{\rho} = \frac{x^{\b_{1}}}{\b_{1}}+\psum_{\rho}\frac{x^{\rho}}{\rho},
      \]
      where the $'$ indicates that we are excluding the term corresponding to the Siegel zero.
  \section{Prime Number Theorems}
    \subsection*{The Prime Number Theorem}
      The \textbf{prime counting function}\index{prime counting function} $\pi(x)$ is defined by
      \[
        \pi(x) = \sum_{p \le x}1,
      \]
      for real $x > 1$. Equivalently, $\pi(x)$ counts the number of primes that no larger than $x$. Euclid's infitude of the primes is equivalent to $\pi(x) \to \infty$ as $x \to \infty$. A more interesting question is to ask how the primes are distributed among the integers. The \textbf{(classical) prime number theorem}\index{(classical) prime number theorem} answers this question and the precise statement is the following:

      \begin{theorem}[Prime number theorem, classical version]
        For $x \ge 2$,
        \[
          \pi(x) \sim \frac{x}{\log(x)}.
        \]
      \end{theorem}

      We will delay the proof for the moment and give some intuition and historical context to the result. Intuitively, the prime number theorem is a result about how dense the primes are in the integers. To see this, notice that the result is equivalent to the asymptotic
      \[
        \frac{\pi(x)}{x} \sim \frac{1}{\log(x)}.
      \]
      Letting $x \ge 2$, the left-hand side is the probability that a radomly chosen positive integer no larger than $x$ is prime. Thus the asymptotic result says that for large enough $x$, the probability that a randomly chosen integer no larger than $x$ is prime is approximately $\frac{1}{\log(x)}$. We can also interpret this as saying that the average gap between primes no larger than $x$ is approximately $\frac{1}{\log(x)}$. As a consequence, a positive integer with at most $2n$ digits is about half as likely to be prime than a positive integer with at most $n$ digits. Indeed, there are $10^{n}-1$ numbers with at most $n$ digits, $10^{2n}-1$ with at most $2n$ digits, and $\log(10^{2n}-1)$ is approximately $2\log(10^{n})$. Note that the prime number theorem says nothing about the exact error $\pi(x)-\frac{x}{\log(x)}$ as $x \to \infty$. The theorem only says that the relative error tends to zero:
      \[
        \lim_{x \to \infty}\frac{\pi(x)-\frac{x}{\log(x)}}{\frac{x}{\log(x)}} = 0.
      \]
      Now for some hisotrical context. While Gauss was not the first to put forth a conjectural form of the prime number theorem, he was known for compiling extensive tables of primes and he suspected that the density of the primes up to $x$ was roughly $\frac{1}{\log(x)}$. How might one suspect this is the correct density? Well, let $d\d_{p}$ be the weighted point measure that assigns $\frac{1}{p}$ at the prime $p$ and zero everywhere else. Then
      \[
        \sum_{p \le x}\frac{1}{p} = \int_{1}^{x}\,d\d_{p}(u).
      \]
      We can interpret the integral as integrating the density $d\d_{p}$ over the volume $[1,x]$. Let's try and find a more explicit expression for the density $d\d_{p}$. Euler (see \cite{euler1744variae}), argued
      \[
        \sum_{p \le x}\frac{1}{p} \sim \log\log(x).
      \]
      But notice that
      \[
        \log\log(x) = \int_{1}^{\log(x)}\frac{du}{u} = \int_{e}^{x}\frac{1}{u}\,\frac{du}{\log{u}},
      \]
      where in the second equality we have made the change of variables $u \to \log(u)$. So altogether,
      \[
        \sum_{p \le x}\frac{1}{p} \sim \int_{e}^{x}\frac{1}{u}\,\frac{du}{\log{u}}.
      \]
      This is an asymptotic formula that gives a more explicit representation of the density $d\d_{p}$. Notice that both sides of this asymptotic are weighted the same, the left-hand side by $\frac{1}{p}$, and the right-hand side by $\frac{1}{u}$. If we remove these weight (this is not strictly allowed), then we might hope
      \[
        \pi(x) = \sum_{p \le x}1 \sim \int_{e}^{x}\frac{du}{\log(u)}.
      \]
      Accordingly, we define the \textbf{logarithmic integral}\index{logarithmic integral} $\Li(x)$ by
      \[
        \Li(x) = \int_{2}^{x}\frac{dt}{\log(t)},
      \]
      for $x \ge 2$. Notice that $\Li(x) \sim \frac{x}{\log{x}}$ because
      \[
        \lim_{x \to \infty}\left|\frac{\Li(x)}{\frac{x}{\log{x}}}\right| = \lim_{x \to \infty}\left|\frac{\int_{2}^{x}\frac{dt}{\log(t)}}{\frac{x}{\log{x}}}\right| = \lim_{x \to \infty}\left|\frac{\frac{1}{\log(x)}}{\frac{\log(x)-1}{\log^{2}(x)}}\right| = \lim_{x \to \infty}\left|\frac{\log(x)}{\log(x)-1}\right| = 1.
      \]
      where in the second equality we have used  l'H\^opital's rule. So an equivalent version of the prime number theorem is the following:
      \begin{theorem}[Prime number theorem, logarithmic integral version]
        For $x \ge 2$,
        \[
          \pi(x) \sim \Li(x).
        \]
      \end{theorem}
      Interpreting the logarithmic integral as an integral of density over volume, then for large $x$ the density of primes up to $x$ is approximately $\frac{1}{\log(x)}$ which is what both versions of the prime number theorem claim. Legendre was the first to put forth a conjectural form of the prime number theorem. In 1798 (see \cite{legendre1798essai}) he claimed that $\pi(x)$ was of the form
      \[
        \frac{x}{A\log(x)+B},
      \]
      for some constants $A$ and $B$. In 1808 (see \cite{legendre1808essai}) he refined his conjecture by claiming
      \[
        \frac{x}{\log(x)+A(x)},
      \]
      where $\lim_{x \to \infty}A(x) \approx 1.08366$. Riemann's 1859 manuscript (see \cite{riemann1859ueber}) contains an outline for how to prove the prime number theorem, but it was not until 1896 that the prime number theorem was proved independently by Hadamard and de la Vall\'ee Poussin (see \cite{hadamard1896distribution} and \cite{poussin1897recherches}). Their proofs, as well as every proof thereon out until 1949, used complex analytic methods in an essential way (there are now elementary proofs due to Erd\"os and Selberg). We are now ready to prove the prime number theorem. Strictly speaking, we will prove a slightly stronger version due to de la Vall\'ee Poussin that bounds the absolute error between $\pi(x)$ and $\Li(x)$:

      \begin{theorem}[Prime number theorem, absolute error version]
        For $x \ge 2$, there exists a positive constant $c$ such that
        \[
          \pi(x) = \Li(x)+O\left(xe^{-c\sqrt{\log(x)}}\right).
        \]
      \end{theorem}
      \begin{proof}
        We will first prove
        \begin{equation}\label{equ:prime_number_theorem_zeta_1}
          \psi(x) = x+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        To achieve this, we estimate the sum over the nontrivial zeros of $\z(s)$ in \cref{cor:explicit_formula_zeta_corollary}. So let $T > 2$ not coinciding with the ordinate of a nontrivial zero, and suppose $\rho = \b+i\g$ is a nontrivial zero with $|\g| < T$. By the classical version of the zero-free region for $\z(s)$, we know $\b < 1-\frac{c}{\log(T)}$ for some constant $c > 0$ (this $c$ is not necessarily the same $c$ in the classical zero-free region for $\z(s)$ because we have replaced $\log(T+2)$ with $\log(T)$). It follows that
        \begin{equation}\label{equ:prime_number_theorem_zeta_2}
          |x^{\rho}| = x^{\b} < x^{1-\frac{c}{\log(T)}} = xe^{-c\frac{\log(x)}{\log(T)}}.
        \end{equation}
        As $|\rho| > |\g|$, letting $\g_{1} > 0$ be the ordinate of the first nontrivial zero, applying integration by parts gives
        \begin{equation}\label{equ:prime_number_theorem_zeta_3}
          \sum_{|\g| < T}\frac{1}{\rho} \ll \sum_{\g_{1} \le \g < T}\frac{1}{\g} \ll \int_{\g_{1}}^{T}\frac{dN(t)}{t} = \frac{N(T)}{T}+\int_{\g_{1}}^{T}\frac{N(t)}{t^{2}}\,dt \ll \log^{2}(T).
        \end{equation}
        where in the last estimate we have used that $N(t) \ll t\log(t)$ which is implied by the Riemann-von Mangoldt formula for $\z(s)$. Putting \cref{equ:prime_number_theorem_zeta_2,equ:prime_number_theorem_zeta_3} together gives
        \begin{equation}\label{equ:prime_number_theorem_zeta_4}
          \sum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll x\log^{2}(T)e^{-c\frac{\log(x)}{\log(T)}}.
        \end{equation}
        As $\psi(x) \sim \psi_{0}(x)$ and $\log(1-x^{-2}) \ll 1$ for $x \ge 2$, \cref{equ:prime_number_theorem_zeta_4} together with \cref{cor:explicit_formula_zeta_corollary} imply
        \begin{equation}\label{equ:prime_number_theorem_zeta_5}
          \psi(x)-x \ll \frac{x\log^{2}(xT)}{T}+x\log^{2}(T)e^{-c\frac{\log(x)}{\log(T)}},
        \end{equation}
        where the last term in \cref{cor:explicit_formula_zeta_corollary} does not appear becase $\<x\> \ge 1$ so that it is absorbed by the first error term in this estimate. We will now let $T$ be determined by
        \[
          \log^{2}(T) = \log(x),
        \]
        or equivalently,
        \[
          T = e^{\sqrt{\log(x)}}.
        \]
        With this choice of $T$ (note that if $x \ge 2$ then $T > 2$), \cref{equ:prime_number_theorem_zeta_5} becomes
        \begin{align*}
          \psi(x)-x &\ll x\left(\log^{2}(x)+\log(x)\right)e^{-\sqrt{\log(x)}}+x\log(x)e^{-c\sqrt{\log(x)}} \\
          &\ll x\log^{2}(x)e^{-\sqrt{\log(x)}}+x\log(x)e^{-c\sqrt{\log(x)}} \\
          &\ll x\log^{2}(x)e^{-\min(1,c)\sqrt{\log(x)}}.
        \end{align*}
        As $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$ for any $\e > 0$, we conclude that
        \[
          \psi(x)-x \ll xe^{-c\sqrt{\log(x)}},
        \]
        for some smaller $c$ with $c < 1$. This is equivalent to \cref{equ:prime_number_theorem_zeta_1}. Now let
        \[
          \pi_{1}(x) = \sum_{n \le x}\frac{\L(n)}{\log(n)}.
        \]
        We can write $\pi_{1}(x)$ in terms of $\psi(x)$ as follows:
        \begin{align*}
          \pi_{1}(x) &= \sum_{n \le x}\frac{\L(n)}{\log(n)} \\
          &= \sum_{n \le x}\L(n)\int_{n}^{x}\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{n \le x}\L(n) \\
          &= \int_{2}^{x}\sum_{n \le t}\L(n)\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{n \le x}\L(n) \\
          &= \int_{2}^{x}\frac{\psi(t)}{t\log^{2}(t)}\,dt+\frac{\psi(x)}{\log(x)}.
        \end{align*}
        Applying \cref{equ:prime_number_theorem_zeta_1} to the last expression yields
        \begin{equation}\label{equ:prime_number_theorem_zeta_6}
          \pi_{1}(x) = \int_{2}^{x}\frac{t}{t\log^{2}(t)}\,dt+\frac{x}{\log(x)}+O\left(\int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)}\right).
        \end{equation}
        Upon applying integrating by parts to the main term in \cref{equ:prime_number_theorem_zeta_6}, we obtain
        \begin{equation}\label{equ:prime_number_theorem_zeta_7}
          \int_{2}^{x}\frac{t}{t\log^{2}(t)}\,dt+\frac{x}{\log(x)} = \int_{2}^{x}\frac{dt}{\log(t)}+\frac{2}{\log(2)} = \Li(x)+\frac{2}{\log(2)}.
        \end{equation}
        As for the error term in \cref{equ:prime_number_theorem_zeta_6}, $\log^{2}(t)$ and $\log(x)$ are both bounded away from zero so that
        \[
          \int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)} \ll \int_{2}^{x}e^{-c\sqrt{\log(t)}}\,dt+xe^{-c\sqrt{\log(x)}}.
        \]
        For $t \le x^{\frac{1}{4}}$, we use the bound $e^{-c\sqrt{\log(t)}} < 1$ so that
        \[
          \int_{2}^{x^{\frac{1}{4}}}e^{-c\sqrt{\log(t)}}\,dt < \int_{2}^{x^{\frac{1}{4}}}\,dt \ll x^{\frac{1}{4}}.
        \]
        For $t > x^{\frac{1}{4}}$, $\sqrt{\log(t)} > \frac{1}{2}\sqrt{\log(x)}$ and thus
        \[
          \int_{2}^{x^{\frac{1}{4}}}e^{-c\sqrt{\log(t)}}\,dt \le e^{-c\frac{1}{2}\sqrt{\log(x)}}\int_{2}^{x^{\frac{1}{4}}}\,dt \ll x^{\frac{1}{4}}e^{-c\frac{1}{2}\sqrt{\log(x)}}. 
        \]
        All of these estimates together imply
        \begin{equation}\label{equ:prime_number_theorem_zeta_8}
          \int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)} \ll xe^{-c\sqrt{\log(x)}},
        \end{equation}
        for some smaller $c$ (actually the new $c$ is $\frac{1}{2}$ of the old one). Combining \cref{equ:prime_number_theorem_zeta_6,equ:prime_number_theorem_zeta_7,equ:prime_number_theorem_zeta_8} yields
        \begin{equation}\label{equ:prime_number_theorem_zeta_9}
          \pi_{1}(x) = \Li(x)+O(xe^{-c\sqrt{\log(x)}}),
        \end{equation}
        where the constant in \cref{equ:prime_number_theorem_zeta_7} has been absorbed into the error term. We now pass from $\pi_{1}(x)$ to $\pi(x)$. If $p$ is a prime such that $p^{m} < x$ for some $m \ge 1$, then $p < x^{\frac{1}{2}} < x^{\frac{1}{3}} < \cdots < x^{\frac{1}{m}}$. Therefore
        \begin{equation}\label{equ:prime_number_theorem_zeta_10}
          \pi_{1}(x) = \sum_{n \le x}\frac{\L(n)}{\log(n)} = \sum_{p^{m} \le x}\frac{\log(p)}{m\log(p)} = \pi(x)+\frac{1}{2}\pi(x^{\frac{1}{2}})+\frac{1}{3}\pi(x^{\frac{1}{3}})+\cdots.
        \end{equation}
        Moreover, as $\pi(x^{\frac{1}{n}}) < x^{\frac{1}{n}}$ for any $n \ge 1$, we see that $\pi(x)-\pi_{1}(x) = O(x^{\frac{1}{2}})$. This estimate together with \cref{equ:prime_number_theorem_zeta_9,equ:prime_number_theorem_zeta_10} gives
        \[
          \pi(x) = \Li(x)+O(xe^{-c\sqrt{\log(x)}}),
        \]
        because $x^{\frac{1}{2}} \ll xe^{-c\sqrt{\log(x)}}$. This completes the proof.
      \end{proof}

      The proof of the logarithmic integral and classical versions of the prime number theorem are immediate:

      \begin{proof}[Proof of prime number theorem, logarithmic integral and classical versions]
        By the absolute error version of the prime number theorem,
        \[
          \pi(x) = \Li(x)\left(1+O\left(\frac{xe^{-c\sqrt{\log(x)}}}{\Li(x)}\right)\right).
        \]
        But we have shown $\Li(x) \sim \frac{x}{\log(x)}$ so that
        \[
          \frac{xe^{-c\sqrt{\log(x)}}}{\Li(x)} \sim \log(x)e^{-c\sqrt{\log(x)}} = o(1),
        \]
        where the equality holds since $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$ for any $\e > 0$. The logarithim integral version follows. The classical version also holds using the asymptotic $\Li(x) \sim \frac{x}{\log(x)}$.
      \end{proof}
      
      In the proof of the logarithmic integral and classical versions of the prime number theorem, we saw that $xe^{-c\sqrt{\log(x)}} < \frac{x}{\log(x)}$ for sufficiently large $x$. Therefore the extact error $\pi(x)-\Li(x)$ grows slower than $\pi(x)-\frac{x}{\log{x}}$ for sufficiently large $x$. This means that $\Li(x)$ is a better numerical approximation to $\pi(x)$ than $\frac{x}{\log(x)}$. There is also the following result due to Hardy and Littlewood (see \cite{hardy1916contributions}) which gives us more information:

      \begin{proposition}\label{thm:Littlewood_Li_approximation_theorem}
        $\pi(x)-\Li(x)$ changes sign infinitely often as $x \to \infty$.
      \end{proposition}

      So in addition, \cref{thm:Littlewood_Li_approximation_theorem} implies that $\Li(x)$ never underestimates or overestimates $\pi(x)$ continuously. On the other hand, the exact error $\pi(x)-\frac{x}{\log(x)}$ is positive provided $x \ge 17$ (see \cite{rosser1962approximate}). It is also worthwile to note that in 1901 Koch showed that the Riemann hypothesis improves the error term in the absolute error version of the prime number theorem (see \cite{von1901distribution}):

      \begin{proposition}
        For $x \ge 2$, under the Riemann hypothesis
        \[
          \pi(x) = \Li(x)+O(\sqrt{x}\log(x)).
        \]
      \end{proposition}
      \begin{proof}
        If $\rho$ is a nontrivial zero of $\z(s)$, the Riemann hypothesis implies $|x^{\rho}| = \sqrt{x}$. Therefore as in the proof of the absolute error version of the prime number theorem,
        \[
          \sum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll \sqrt{x}\log^{2}(T),
        \]
        for $T > 2$ not coinciding with the ordinate of a nontrivial zero. Repeating the same argument with $T$ determined by
        \[
          T^{2} = x,
        \]
        gives
        \[
          \psi(x) = x+O(\sqrt{x}\log^{2}(x)),
        \]
        and then trasnfering to $\pi_{1}(x)$ and finally $\pi(x)$ gives
        \[
          \pi(x) = x+O(\sqrt{x}\log(x)).
        \]
      \end{proof}
    \subsection*{The Siegel–Walfisz Theorem}
      Let $m$ and $a$ be positive integers with $(a,m) = 1$. The \textbf{prime counting function}\index{prime counting function} $\pi(x:a,m)$ is defined by
      \[
        \pi(x;a,m) = \sum_{\substack{p \le x \\ p \equiv a \tmod{m}}}1,
      \]
      for real $x > 1$. Equivalently, $\pi(x;a,m)$ counts the number of primes that no larger than $x$ and are equivalent to $a$ modulo $m$. This is the analog of $\pi(x)$ that is naturally associated to Dirichlet characters modulo $m$. Accordingly, there is a version of the prime number theorem for $\pi(x;a,m)$. To prove it, we will require an auxiliary function. The \textbf{Chebychef function} $\psi(x;a,m)$, for $x \ge 1$, is defined by
      \[
        \psi(x;a,m) = \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n).
      \]
      This is just $\psi(x)$ restricted to only those terms equivalent to $a$ modulo $m$. The prime number theorem for $\pi(x;a,m)$ is known as the \textbf{Siegel–Walfisz theorem}\index{Siegel–Walfisz theorem}:

      \begin{theorem}[Siegel–Walfisz theorem]
        Let $m$ and $a$ be positive integers with $(a,m) = 1$ and let $N \ge 1$. For $x \ge 2$, there exists a positive constant $c$ such that
        \[
          \pi(x;a,m) = \frac{\Li(x)}{\phi(m)}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \]
        provided $m \le \log^{N}(x)$.
      \end{theorem}
      \begin{proof}
        We being with the identity
        \begin{equation}\label{equ:Siegel-Walfisz_1}
          \psi(x;a,m) = \frac{1}{\phi(m)}\sum_{\chi \tmod{m}}\cchi(a)\psi(x,\chi),
        \end{equation}
        which holds by the orthogonality relations (\cref{prop:Dirichlet_orthogonality_relations} (ii)). Let $\wtilde{\chi}$ be the primitive character inducing $\chi$. Then \cref{equ:difference_between_Dirichlet-Chebychefs} implies
        \begin{equation}\label{equ:Siegel-Walfisz_2}
          \psi(x,\chi) = \psi(x,\wtilde{\chi})+O(\log^{2}(xm)).
        \end{equation}
        When $\chi = \chi_{m,0}$ we have $\psi(x,\wtilde{\chi}) = \psi(x)$, and as $\psi(x,\chi) \sim \psi_{0}(x,\chi)$ for all $\chi$, substiuting \cref{equ:prime_number_theorem_zeta_1} into \cref{equ:Siegel-Walfisz_2} gives
        \begin{equation}\label{equ:Siegel-Walfisz_3}
          \psi(x,\chi_{m,0}) = \psi(x)+O\left(xe^{-c\sqrt{\log(x)}}+\log^{2}(xm)\right),
        \end{equation}
        for some positive constant $c$. Upon combining \cref{equ:Siegel-Walfisz_1,equ:Siegel-Walfisz_3}, we obtain
        \begin{equation}\label{equ:Siegel-Walfisz_4}
          \psi(x;a,m) = \frac{x}{\phi(m)}+\frac{1}{\phi(m)}\sum_{\substack{\chi \tmod{m} \\ \chi \neq \chi_{m,0}}}\cchi(a)\psi(x,\chi)+O\left(\frac{1}{\phi(m)}\left(xe^{-c\sqrt{\log(x)}}+\log^{2}(xm)\right)\right).
        \end{equation}
        Now let $2 \le T \le x$...

      \end{proof}