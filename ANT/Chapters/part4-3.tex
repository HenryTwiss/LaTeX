\chapter{Explicit Formulas \& Prime Number Theorems}
  Our main aim is to prove the prime number theorem and its variant for primes restricted to a certain residue class, the Siegel–Walfisz theorem, in the classical manner. These results will follow from explicit formulas for Chebyshev functions. After deriving these results, we prove the prime number theorem and the Siegel–Walfisz theorem.
  \section{Explicit Formulas for Chebyshev Functions}
    \subsection*{The Explicit Formula for \texorpdfstring{$\psi(x)$}{$\psi(x)$}}
      The \textbf{Chebyshev function}\index{Chebyshev function} $\psi(x)$, for $x > 0$, is defined by
      \[
        \psi(x) = \sum_{n \le x}\L(n).
      \]
      The explicit formula for $\psi(x)$ will be obtained by applying truncated Perron's formula to the logarithmic derivative of $\z(s)$. Since $\psi(x)$ is discontinuous when $x$ is a prime power, we need to work with a slightly modified function to apply the Mellin inversion formula. Define $\psi_{0}(x)$ by
      \[
        \psi_{0}(x) = \begin{cases} \psi(x) & \text{if $x$ is not a prime power}, \\ \psi(x)-\frac{1}{2}\L(x) & \text{if $x$ is a prime power}. \end{cases}
      \]
      Equivalently, $\psi_{0}(x)$ is $\psi(x)$ except that its value is halfway between the limit values when $x$ is a prime power. Stated another way, if $x$ is a prime power the last term in the sum for $\psi_{0}(x)$ is multiplied by $\frac{1}{2}$. The \textbf{explicit formula}\index{explicit formula} for $\psi(x)$ is the following:

      \begin{theorem}[Explicit formula for $\psi(x)$]
        For $x \ge 2$,
        \[
          \psi_{0}(x) = x-\sum_{\rho}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2}),
        \]
        where $\rho$ runs over the nontrivial zeros of $\z(s)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{theorem}

      A few comments are in order before we prove the explicit formula for $\psi(x)$. First, since $\rho$ is conjectured to be of the form $\rho = \frac{1}{2}+i\g$ under the Riemann hypothesis, $x$ is conjectured to be the main term in the explicit formula. The constant $\frac{\z'}{\z}(0)$ can be shown to be $\log(2\pi)$ (see \cite{davenport1980multiplicative} for a proof). Also, using the Taylor series of the logarithm, the last term can be expressed as
      \[
        \frac{1}{2}\log(1-x^{-2}) = \frac{1}{2}\sum_{m \ge 1}(-1)^{m-1}\frac{(-x^{-2})^{m}}{m} = \sum_{m \ge 1}(-1)^{2m-1}\frac{x^{-2m}}{2m} = \sum_{m \ge 1}\frac{x^{-2m}}{-2m} = \sum_{\w}\frac{x^{\w}}{\w},
      \]
      where $\w$ runs over the trivial zeros of $\z(s)$. We will now prove the explicit formula for $\psi(x)$:

      \begin{proof}[Proof of the explicit formula for $\psi(x)$]
        Recalling \cref{equ:Drichlet_series_log_derivative_zeta} and that $\psi(x) = \sum_{n \le x}\L(n)$, applying truncated Perron's formula to $-\frac{\z'}{\z}(s)$ gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_1}
          \psi_{0}(x)-J(x,T) \ll x^{c}\sum_{\substack{n \ge 1 \\ n \neq x}}\frac{\L(n)}{n^{c}}\min\left(1,\frac{1}{T\left|\log\left(\frac{x}{n}\right)\right|}\right)+\d_{x}\L(x)\frac{c}{T},
        \end{equation}
        where
        \[
          J(x,T) = \frac{1}{2\pi i}\int_{c-iT}^{c+iT}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s},
        \]
        $c > 1$, and it is understood that $\d_{x} = 0$ unless $x$ is a prime power. Take $T > 2$ not coinciding with the ordinate of a nontrivial zero and let $c = 1+\frac{1}{\log(x^{2})}$ so that $x^{c} = \sqrt{e}x$. The first step is to estimate the right-hand side of \cref{equ:explicit_formula_zeta_proof_1}. We deal with the terms corresponding to $n$ such that $n$ is bounded away from $x$ before anything else. So suppose $n \le \frac{3}{4}x$ or $n \ge \frac{5}{4}x$. For these $n$, $\log\left(\frac{x}{n}\right)$ is bounded away from zero so that their contribution is
        \begin{equation}\label{equ:explicit_formula_zeta_proof_2}
          \ll \frac{x^{c}}{T}\sum_{n \ge 1}\frac{\L(n)}{n^{c}} \ll \frac{x^{c}}{T}\left(-\frac{\z'}{\z}(c)\right) \ll \frac{x\log(x)}{T},
        \end{equation}
        where the last estimate follows from \cref{equ:classical_zero-free_region_zeta_1} and our choice of $c$. Now we deal with the terms $n$ close to $x$. Consider those $n$ for which $\frac{3}{4}x < n < x$. Let $x_{1}$ be the largest prime power less than $x$. We may also suppose $\frac{3}{4}x < x_{1} < x$ since otherwise $\L(n) = 0$ and these terms do not contribute anything. Moreover, $\frac{x^{c}}{n^{c}} \ll 1$. For the term $n = x_{1}$, we have
        \[
          \log\left(\frac{x}{n}\right) = -\log\left(1-\frac{x-x_{1}}{x}\right) \ge \frac{x-x_{1}}{x},
        \]
        where we have obtained the inequality by using Taylor series of the logarithm truncated after the first term. The contribution of this term is then
        \begin{equation}\label{equ:explicit_formula_zeta_proof_3}
          \ll \L(x_{1})\min\left(1,\frac{x}{T(x-x_{1})}\right) \ll \log(x)\min\left(1,\frac{x}{T(x-x_{1})}\right).
        \end{equation}
        For the other such $n$, we can write $n = x_{1}-v$, where $v$ is an integer satisfying $0 < v < \frac{1}{4}x$, so that
        \[
          \log\left(\frac{x}{n}\right) \ge \log\left(\frac{x_{1}}{n}\right) = -\log\left(1-\frac{v}{x_{1}}\right) \ge \frac{v}{x_{1}},
        \]
        where we have obtained the latter inequality by using Taylor series of the logarithm truncated after the first term. The contribution for these $n$ is then
        \begin{equation}\label{equ:explicit_formula_zeta_proof_4}
          \ll \sum_{0 < v < \frac{1}{4}x}\L(x_{1}-v)\frac{x_{1}}{Tv} \ll \frac{x}{T}\sum_{0 < v < \frac{1}{4}x}\frac{\L(x_{1}-v)}{v} \ll \frac{x\log(x)}{T}\sum_{0 < v < \frac{1}{4}x}\frac{1}{v} \ll \frac{x\log^{2}(x)}{T}.
        \end{equation}
        The contribution for those $n$ for which $x < n < \frac{5}{4}x$ is handled in exactly the same way with $x_{1}$ being the least prime power larger than $x$. Let $\<x\>$ be the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power. Combining \cref{equ:explicit_formula_zeta_proof_3,equ:explicit_formula_zeta_proof_4} with our previous comment, the contribution for those $n$ with $\frac{3}{4}x < n < \frac{5}{4}x$ is
        \begin{equation}\label{equ:explicit_formula_zeta_proof_5}
          \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Putting \cref{equ:explicit_formula_zeta_proof_2,equ:explicit_formula_zeta_proof_5} together and noticing that the error term in \cref{equ:explicit_formula_zeta_proof_2} is absorbed by the second error term in \cref{equ:explicit_formula_zeta_proof_5}, we obtain
        \begin{equation}\label{equ:explicit_formula_zeta_proof_6}
          \psi_{0}(x)-J(x,T) \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        This is the first part of the proof. Now we estimate $J(x,T)$ by appealing to the residue theorem. Let $U \ge 1$ be an odd integer. Let $\W$ be the region enclosed by the contours $\eta_{1},\ldots,\eta_{4}$ in \cref{fig:explict_formula_zeta_contour} and set $\eta = \sum_{1 \le i \le 4}\eta_{i}$ so that $\eta = \del \W$.

        \begin{figure}[ht]
          \centering
          \begin{tikzpicture}[scale=2]
            \def\xmin{-3.5} \def\xmax{1.5}
            \def\ymin{-2} \def\ymax{2}
            \draw[thick] (\xmin,0) -- (\xmax,0);
            \draw[thick] (0,\ymin) -- (0,\ymax);
            \draw[dashed] (0.5,\ymin) -- (0.5,\ymax);

            \draw[->-] (1,-1.5) -- (1,1.5);
            \draw[->-] (1,1.5) -- (-3,1.5);
            \draw[->-] (-3,1.5) -- (-3,-1.5);
            \draw[->-] (-3,-1.5) -- (1,-1.5);

            \node at (1,0) [below right] {\tiny{$\eta_{1}$}};
            \node at (-1,1.5) [above] {\tiny{$\eta_{2}$}};
            \node at (-3,0) [below left] {\tiny{$\eta_{3}$}};
            \node at (-1,-1.5) [below] {\tiny{$\eta_{4}$}};

            \node at (1,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (1,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,-1.5) [circle,fill,inner sep=1.5pt]{};

            \node at (1,-1.5) [below left] {\tiny{$c-iT$}};
            \node at (1,1.5) [above] {\tiny{$c+iT$}};
            \node at (0.5,1.5) [above left] {\tiny{$\frac{1}{2}+iT$}};
            \node at (-3,1.5) [above] {\tiny{$-U+iT$}};
            \node at (-3,-1.5) [below left] {\tiny{$-U-iT$}};
            \node at (0.5,-1.5) [below left] {\tiny{$\frac{1}{2}-iT$}};
          \end{tikzpicture}
          \caption{Contour for the explicit formula for $\psi(x)$}
          \label{fig:explict_formula_zeta_contour}
        \end{figure}

        We may express $J(x,T)$ as
        \[
          J(x,T) = \frac{1}{2\pi i}\int_{\eta_{1}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s}.
        \]
        The residue theorem together with the explicit formula for $\frac{\z'}{\z}(s)$ and \cref{cor:logarithmic_derivative_of_gamma} imply
        \begin{equation}\label{equ:explicit_formula_zeta_proof_7}
          J(x,T) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\sum_{0 < 2m < U}\frac{x^{-2m}}{-2m}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $\z$. We will estimate $J(x,T)$ by estimating the remaining integral. By \cref{cor:Riemann_von_Mangoldt_corollary} (i), the number of nontrivial zeros satisfying $|\g-T| < 1$ is $O(\log(T))$. Among the ordinates of these zeros, there must be a gap of size $\gg \frac{1}{\log(T)}$. Upon varying $T$ by a bounded amount (we are varying in the interval $[T-1,T+1]$) so that it belongs to this gap, we can additionally ensure
        \[
          \g-T \gg \frac{1}{\log(T)},
        \]
        for all the nontrivial zeros of $\z(s)$. To estimate part of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$, \cref{equ:Riemann_von_Mangoldt_14} gives
        \[
          \frac{\z'}{\z}(s) = \sum_{|\g-T| < 1}\frac{1}{s-\rho}+O(\log(T)),
        \]
        on the parts of these segments with $-1 \le \s \le 2$. By our choice of $T$, $|s-\rho| \ge |\g-T| \gg \frac{1}{\log(T)}$ so that each term in the sum is $O(\log(T))$. There are at most $O(\log(T))$ such terms by \cref{cor:Riemann_von_Mangoldt_corollary} (i), so we find that
        \[
          \frac{\z'}{\z}(s) = O(\log^{2}(T)),
        \]
        for $-1 \le \s \le 2$. It follows that the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with  $-1 \le \s \le c$ (as $x \ge 2$ our choice of $c$ ensures $c < 2$) contribute
        \begin{equation}\label{equ:explicit_formula_zeta_proof_8}
          \ll \frac{\log^{2}(T)}{T}\int_{-1}^{c}x^{\s}\,d\s \ll \frac{\log^{2}(T)}{T}\int_{-\infty}^{c}x^{\s}\,d\s \ll \frac{x\log^{2}(T)}{T\log(x)},
        \end{equation}
        where in the last estimate we have used the choice of $c$. To estimate the remainder of the horizontal integrals, we need a bound for $\frac{\z'}{\z}(s)$ when $\s < -1$ and away from the trivial zeros. To this end, write the functional equation for $\z(s)$ in the form
        \[
          \z(s) = \pi^{s-1}\frac{\G\left(\frac{1-s}{2}\right)}{\G\left(\frac{s}{2}\right)}\z(1-s),
        \]
        and take the logarithmic derivative to get
        \[
          \frac{\z'}{\z}(s) = \log(\pi)+\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{s}{2}\right)+\frac{\z'}{\z}(1-s).
        \]
        Let $s$ be such that $\s < -1$ and suppose $s$ is distance $\frac{1}{2}$ away from the trivial zeros. We will estimate every term on the right-hand side of the previous identity. The first term is constant and the last term is bounded by \cref{equ:Drichlet_series_log_derivative_zeta}. As for the digamma terms, since $s$ is away from the trivial zeros, \cref{equ:approximtion_for_digamma} implies $\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right) = O(\log|1-s|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s}{2}\right) = O(\log|s|)$. However, as $\s < -1$ and $s$ is away from the trivial zeros, $s$ and $1-s$ are bounded away from zero so that $\frac{1}{2}\frac{\G'}{\G}\left(\frac{1-s}{2}\right) = O(\log|s|)$. Putting these estimates together gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_9}
          \frac{\z'}{\z}(s) \ll \log(|s|),
        \end{equation}
        for $\s < -1$. Using \cref{equ:explicit_formula_zeta_proof_9}, the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with $-U \le \s \le -1$ contribute
        \begin{equation}\label{equ:explicit_formula_zeta_proof_10}
          \ll \frac{\log(T)}{T}\int_{-U}^{-1}x^{\s}\,d\s \ll \frac{\log(T)}{Tx\log(x)}.
        \end{equation}
        Combining \cref{equ:explicit_formula_zeta_proof_8,equ:explicit_formula_zeta_proof_10} gives
        \begin{equation}\label{equ:explicit_formula_zeta_proof_11}
          \frac{1}{2\pi i}\int_{\eta_{2}+\eta_{4}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s} \ll \frac{x\log^{2}(T)}{T\log(x)}+\frac{\log(T)}{Tx\log(x)} \ll \frac{x\log^{2}(T)}{T\log(x)}.
        \end{equation}
        To estimate the vertical integral, we use \cref{equ:explicit_formula_zeta_proof_9} again to conclude that
        \begin{equation}\label{equ:explicit_formula_zeta_proof_12}
          \frac{1}{2\pi i}\int_{\eta_{3}}-\frac{\z'}{\z}(s)x^{s}\,\frac{ds}{s} \ll \frac{\log(U)}{U}\int_{-T}^{T}x^{-U}\,dt \ll \frac{T\log(U)}{Ux^{U}}.
        \end{equation}
        Combining \cref{equ:explicit_formula_zeta_proof_7,equ:explicit_formula_zeta_proof_11,equ:explicit_formula_zeta_proof_12} and taking the limit as $U \to \infty$, the error term in \cref{equ:explicit_formula_zeta_proof_12} vanishes and the sum over $m$ in \cref{equ:explicit_formula_zeta_proof_7} evaluates to $\frac{1}{2}\log(1-x^{-2})$ (as we have already mentioned) giving
        \begin{equation}\label{equ:explicit_formula_zeta_proof_13}
          J(x,T) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(T)}{T\log(x)}.
        \end{equation}
        Substituting \cref{equ:explicit_formula_zeta_proof_13} into \cref{equ:explicit_formula_zeta_proof_6}, we at last obtain
        \begin{equation}\label{equ:explicit_formula_zeta_proof_14}
          \psi_{0}(x) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\frac{\z'}{\z}(0)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        where the second to last term on the right-hand side is obtained by combining the error term in \cref{equ:explicit_formula_zeta_proof_11} with the first error term in \cref{equ:explicit_formula_zeta_proof_6}. The theorem follows by taking the limit as $T \to \infty$.
      \end{proof}

      Note that the convergence of the right-hand side in the explicit formula for $\psi(x)$ is uniform in any interval not containing a prime power since $\psi(x)$ is continuous there. Moreover, we have an approximate formula for $\psi(x)$ as a corollary:

      \begin{corollary}\label{cor:explicit_formula_zeta_corollary}
         For $x \ge 2$ and $T > 2$,
        \[
           \psi_{0}(x) = x-\sum_{|\g| < T}\frac{x^{\rho}}{\rho}+R(x,T),
        \]
        where $\rho$ runs over the nontrivial zeros of $\z(s)$ counted with multiplicity and ordered with respect to the size of the ordinate, and
        \[
          R(x,T) \ll \frac{x\log^{2}(xT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        where $\<x\>$ is the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power. Moreover, if $x$ is an integer, we have the simplified estimate
        \[
          R(x,T) \ll \frac{x\log^{2}(xT)}{T}.
        \]
      \end{corollary}
      \begin{proof}
        This follows from \cref{equ:explicit_formula_zeta_proof_14} since $\frac{\z'}{\z}(0)$ is constant and $\frac{1}{2}\log(1-x^{2})$ is bounded for $x \ge 2$. If $x$ is an integer, then $\<x\> \ge 1$ so that $\log(x)\min\left(1,\frac{x}{T\<x\>}\right) \le \frac{x\log(x)}{T}$ and this term can be absorbed by $\frac{x\log^{2}(xT)}{T}$.
      \end{proof}
    \subsection*{The Explicit Formula for \texorpdfstring{$\psi(x,\chi)$}{$\psi(x,\chi)$}}
      Let $\chi$ be a Dirichlet character modulo $m > 1$. The \textbf{Dirichlet-Chebyshev function} $\psi(x,\chi)$, for $x > 0$, is defined by
      \[
        \psi(x,\chi) = \sum_{n \le x}\chi(n)\L(n).
      \]
      This object plays the analogous role of $\psi(x)$ but for Dirichlet $L$-functions. Accordingly, we will derive an explicit formula for $\psi(x,\chi)$ in a similar manner to that of $\psi(x)$. Because $\psi(x,\chi)$ is discontinuous when $x$ is a prime power, we also introduce a slightly modified function. Define $\psi_{0}(x,\chi)$ by
      \[
        \psi_{0}(x,\chi) = \begin{cases} \psi(x,\chi) & \text{if $x$ is not a prime power}, \\ \psi(x,\chi)-\frac{1}{2}\chi(x)\L(x) & \text{if $x$ is a prime power}. \end{cases}
      \]
      Thus $\psi_{0}(x,\chi)$ is $\psi(x,\chi)$ except that its value is halfway between the limit values when $x$ is a prime power. We will also need to define a particular constant that will come up. For a character $\chi$, define $b(\chi)$ to be $\frac{L'}{L}(0,\chi)$ if $\chi$ is odd and to be the constant term in the Laurent series of $\frac{L'}{L}(s,\chi)$ if $\chi$ is even (as in the even case $\frac{L'}{L}(s,\chi)$ has a pole at $s = 0$). The \textbf{explicit formula}\index{explicit formula} for $\psi(x,\chi)$ is the following:

      \begin{theorem}[Explicit formula for $\psi(x,\chi)$]
        Let $\chi$ be a primitive Dirichlet character of conductor $q > 1$. Then for $x \ge 2$,
        \[
          \psi_{0}(x,\chi) = -\sum_{\rho}\frac{x^{\rho}}{\rho}-b(\chi)+\tanh^{-1}(x^{-1}),
        \]
        if $\chi$ is odd, and
        \[
          \psi_{0}(x,\chi) = -\sum_{\rho}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2}),
        \]
        if $\chi$ is even, and where in both expressions, $\rho$ runs over the nontrivial zeros of $L(s,\chi)$ counted with multiplicity and ordered with respect to the size of the ordinate.
      \end{theorem}

      As for $\psi(x)$, a few comments are in order. Unlike the explicit formula for $\psi(x)$, there is no main term $x$ in the explicit formula for $\psi(x,\chi)$. This is because $L(s,\chi)$ does not have a pole at $s = 1$. The constant $b(\chi)$ can be expressed in terms of $B(\chi)$ (see \cite{davenport1980multiplicative} for a proof). Also, in the case $\chi$ is odd the Taylor series of the inverse hyperbolic tangent lets us write
      \[
        \tanh^{-1}(x^{-1}) = \sum_{m \ge 1}\frac{x^{-(2m-1)}}{2m-1} = -\sum_{m \ge 1}\frac{x^{-(2m-1)}}{-(2m-1)} = -\sum_{\w}\frac{x^{\w}}{\w},
      \]
      where $\w$ runs over the trivial zeros of $L(s,\chi)$. In the case $\chi$ is even, $\frac{1}{2}\log(1-x^{-2})$ accounts for the contribution of the trivial zeros just as for $\z(s)$. We will now prove the explicit formula for $\psi(x,\chi)$:

      \begin{proof}[Proof of the explicit formula for $\psi(x,\chi)$]
        Recalling \cref{equ:Drichlet_series_log_derivative_Dirichlet} and that $\psi(x,\chi) = \sum_{n \le x}\chi(n)\L(n)$, truncated Perron's formula applied to $-\frac{L'}{L}(s,\chi)$ gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_1}
          \psi_{0}(x,\chi)-J(x,T,\chi) \ll x^{c}\sum_{\substack{n \ge 1 \\ n \neq x}}\frac{\chi(n)\L(n)}{n^{c}}\min\left(1,\frac{1}{T\left|\log\left(\frac{x}{n}\right)\right|}\right)+\d_{x}\chi(x)\L(x)\frac{c}{T},
        \end{equation}
        where
        \[
          J(x,T,\chi) = \frac{1}{2\pi i}\int_{c-iT}^{c+iT}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \]
        $c > 1$, and it is understood that $\d_{x} = 0$ unless $x$ is a prime power. Take $T > 2$ not coinciding with the ordinate of a nontrivial zero and let $c = 1+\frac{1}{\log(x^{2})}$ so that $x^{c} = \sqrt{e}x$. We will estimate the right-hand side of \cref{equ:explicit_formula_Dirichlet_proof_1}. First, we estimate the terms corresponding to $n$ such that $n$ is bounded away from $x$. So suppose $n \le \frac{3}{4}x$ or $n \ge \frac{5}{4}x$. For these $n$, $\log\left(\frac{x}{n}\right)$ is bounded away from zero so that their contribution is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_2}
          \ll \frac{x^{c}}{T}\sum_{n \ge 1}\frac{\chi(n)\L(n)}{n^{c}} \ll \frac{x^{c}}{T}\left(-\frac{\z'}{\z}(c)\right) \ll \frac{x\log(x)}{T},
        \end{equation}
        where the middle estimate follows from \cref{equ:Drichlet_series_log_derivative_zeta} and the last estimate follows from \cref{equ:classical_zero-free_region_zeta_1} and our choice of $c$. Now we estimate the terms $n$ close to $x$. So consider those $n$ for which $\frac{3}{4}x < n < x$ and let $x_{1}$ be the largest prime power less than $x$. We may also assume $\frac{3}{4}x < x_{1} < x$ since otherwise $\L(n) = 0$ and these terms do not contribute anything. Moreover, $\frac{x^{c}}{n^{c}} \ll 1$. For the term $n = x_{1}$, we have the estimate
        \[
          \log\left(\frac{x}{n}\right) = -\log\left(1-\frac{x-x_{1}}{x}\right) \ge \frac{x-x_{1}}{x},
        \]
        where we have obtained the inequality by using Taylor series of the logarithm truncated after the first term. The contribution of this term is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_3}
          \ll \chi(x_{1})\L(x_{1})\min\left(1,\frac{x}{T(x-x_{1})}\right) \ll \log(x)\min\left(1,\frac{x}{T(x-x_{1})}\right).
        \end{equation}
        For the other $n$, we write $n = x_{1}-v$, where $v$ is an integer satisfying $0 < v < \frac{1}{4}x$, so that
        \[
          \log\left(\frac{x}{n}\right) \ge \log\left(\frac{x_{1}}{n}\right) = -\log\left(1-\frac{v}{x_{1}}\right) \ge \frac{v}{x_{1}},
        \]
        where we have obtained the latter inequality by using Taylor series of the logarithm truncated after the first term. The contribution for these $n$ is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_4}
          \ll \sum_{0 < v < \frac{1}{4}x}\chi(x_{1}-v)\L(x_{1}-v)\frac{x_{1}}{Tv} \ll \frac{x}{T}\sum_{0 < v < \frac{1}{4}x}\frac{\L(x_{1}-v)}{v} \ll \frac{x\log(x)}{T}\sum_{0 < v < \frac{1}{4}x}\frac{1}{v} \ll \frac{x\log^{2}(x)}{T}.
        \end{equation}
        The contribution for those $n$ for which $x < n < \frac{5}{4}x$ is handled in exactly the same way with $x_{1}$ being the least prime power larger than $x$. Let $\<x\>$ be the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power. Combining \cref{equ:explicit_formula_Dirichlet_proof_3,equ:explicit_formula_Dirichlet_proof_4} with our previous comment, the contribution for those $n$ with $\frac{3}{4}x < n < \frac{5}{4}x$ is
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_5}
          \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Putting \cref{equ:explicit_formula_Dirichlet_proof_2,equ:explicit_formula_Dirichlet_proof_5}, the error term in \cref{equ:explicit_formula_Dirichlet_proof_2} is absorbed by the second error term in \cref{equ:explicit_formula_Dirichlet_proof_5} and we obtain
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_6}
          \psi_{0}(x,\chi)-J(x,T,\chi) \ll \frac{x\log^{2}(x)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right).
        \end{equation}
        Now we estimate $J(x,T,\chi)$ by using the residue theorem. Let $U \ge 1$ be an integer with $U$ is even if $\chi$ is odd and odd if $\chi$ is even. Let $\W$ be the region enclosed by the contours $\eta_{1},\ldots,\eta_{4}$ in \cref{fig:explict_formula_Dirichlet_contour} and set $\eta = \sum_{1 \le i \le 4}\eta_{i}$ so that $\eta = \del \W$. We may write $J(x,T,\chi)$ as
        \[
          J(x,T,\chi) = \frac{1}{2\pi i}\int_{\eta_{1}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s}.
        \]

        \begin{figure}[ht]
          \centering
          \begin{tikzpicture}[scale=2]
            \def\xmin{-3.5} \def\xmax{1.5}
            \def\ymin{-2} \def\ymax{2}
            \draw[thick] (\xmin,0) -- (\xmax,0);
            \draw[thick] (0,\ymin) -- (0,\ymax);
            \draw[dashed] (0.5,\ymin) -- (0.5,\ymax);

            \draw[->-] (1,-1.5) -- (1,1.5);
            \draw[->-] (1,1.5) -- (-3,1.5);
            \draw[->-] (-3,1.5) -- (-3,-1.5);
            \draw[->-] (-3,-1.5) -- (1,-1.5);

            \node at (1,0) [below right] {\tiny{$\eta_{1}$}};
            \node at (-1,1.5) [above] {\tiny{$\eta_{2}$}};
            \node at (-3,0) [below left] {\tiny{$\eta_{3}$}};
            \node at (-1,-1.5) [below] {\tiny{$\eta_{4}$}};

            \node at (1,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (1,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (-3,-1.5) [circle,fill,inner sep=1.5pt]{};
            \node at (0.5,-1.5) [circle,fill,inner sep=1.5pt]{};

            \node at (1,-1.5) [below left] {\tiny{$c-iT$}};
            \node at (1,1.5) [above] {\tiny{$c+iT$}};
            \node at (0.5,1.5) [above left] {\tiny{$\frac{1}{2}+iT$}};
            \node at (-3,1.5) [above] {\tiny{$-U+iT$}};
            \node at (-3,-1.5) [below left] {\tiny{$-U-iT$}};
            \node at (0.5,-1.5) [below left] {\tiny{$\frac{1}{2}-iT$}};
          \end{tikzpicture}
          \caption{Contour for the explicit formula for $\psi(x)$}
          \label{fig:explict_formula_Dirichlet_contour}
        \end{figure}

        We now separate the cases that $\chi$ is even or odd. If $\chi$ is odd, then the residue theorem together with the explicit formula for $\frac{L'}{L}(s,\chi)$ and \cref{cor:logarithmic_derivative_of_gamma} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_7}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-b(\chi)-\sum_{0 < 2m+1 < U}\frac{x^{-(2m-1)}}{-(2m-1)}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $L(s,\chi)$. If $\chi$ is even, then there is a minor complication because $L(s,\chi)$ has a simple zero at $s = 0$ and so the integrand has a double pole at $s = 0$. To find the residue, the Laurent series are
        \[
          \frac{L'}{L}(s,\chi) = \frac{1}{s}+b(\chi)+\cdots \quad \text{and} \quad \frac{x^{s}}{s} = \frac{1}{s}+\log(x)+\cdots,
        \]
        and thus the residue of the integrand is $-(\log(x)+b(\chi))$. Now as before, the residue theorem together with the explicit formula for $\frac{L'}{L}(s,\chi)$ and \cref{cor:logarithmic_derivative_of_gamma} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_7'}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\sum_{0 < 2m < U}\frac{x^{-2m}}{-2m}+\frac{1}{2\pi i}\int_{\eta_{2}+\eta_{3}+\eta_{4}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s},
        \end{equation}
        where $\rho = \b+i\g$ is a nontrivial zero of $L(s,\chi)$. We now estimate the remaining integrals in \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_7'}. For this estimate, the parity of $\chi$ does not matter so we make no such restriction. By \cref{cor:Riemann_von_Mangoldt_Dirichlet_L-functions_corollary} (i), the number of nontrivial zeros satisfying $|\g-T| < 1$ is $O(\log(qT))$. Among the ordinates of these zeros, there must be a gap of size $\gg \frac{1}{\log(qT)}$. Upon varying $T$ by a bounded amount (we are varying in the interval $[T-1,T+1]$) so that it belongs to this gap, we can additionally ensure
        \[
          \g-T \gg \frac{1}{\log(qT)},
        \]
        for all the nontrivial zeros of $L(s,\chi)$. To estimate part of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$, \cref{equ:Riemann_von_Mangoldt_Dirichlet_L-functions_13} gives
        \[
          \frac{L'}{L}(s,\chi) = \sum_{|\g-T| < 1}\frac{1}{s-\rho}+O(\log(qT)),
        \]
        on the parts of these segments with $-1 \le \s \le 2$. Our choice of $T$ implies $|s-\rho| \ge |\g-T| \gg \frac{1}{\log(qT)}$ so that each term in the sum is $O(\log(qT))$. As there are at most $O(\log(qT))$ such terms by \cref{cor:Riemann_von_Mangoldt_Dirichlet_L-functions_corollary} (i), we have
        \[
          \frac{L'}{L}(s,\chi) = O(\log^{2}(qT)),
        \]
        for $-1 \le \s \le 2$. It follows that the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with  $-1 \le \s \le c$ (as $x \ge 2$ our choice of $c$ ensures $c < 2$) contribute
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_8}
          \ll \frac{\log^{2}(qT)}{T}\int_{-1}^{c}x^{\s}\,d\s \ll \frac{\log^{2}(qT)}{T}\int_{-\infty}^{c}x^{\s}\,d\s \ll \frac{x\log^{2}(qT)}{T\log(x)}.
        \end{equation}
        where in the last estimate we have used the choice of $c$. To estimate the remainder of the horizontal integrals, we require a bound for $\frac{L'}{L}(s,\chi)$ when $\s < -1$ and away from the trivial zeros. To find such a bound, write the functional equation for $L(s,\chi)$ in the form
        \[
          L(s,\chi) = \frac{\e_{\chi}}{i^{\mf{a}}}q^{\frac{1}{2}-s}\pi^{s-1}\frac{\G\left(\frac{(1-s)+\mf{a}}{2}\right)}{\G\left(\frac{s+\mf{a}}{2}\right)}L(1-s,\chi),
        \]
        and take the logarithmic derivative to get
        \[
          \frac{L'}{L}(s,\chi) = -\log(q)+\log(\pi)+\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right)+\frac{L'}{L}(1-s,\chi).
        \]
        Now let $s$ be such that $\s < -1$ and suppose $s$ is distance $\frac{1}{2}$ away from the trivial zeros. We will estimate every term on the right-hand side of the identity above. The second term is constant and the last term is bounded by \cref{equ:Drichlet_series_log_derivative_Dirichlet}. For the digamma terms, $s$ is away from the trivial zeros so \cref{equ:approximtion_for_digamma} implies $\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right) = O(\log|(1-s)+\mf{a}|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right) = O(\log|s+\mf{a}|)$. However, as $\s < -1$ and $s$ is away from the trivial zeros, $s+\mf{a}$ and $(1-s)+\mf{a}$ are bounded away from zero so that $\frac{1}{2}\frac{\G'}{\G}\left(\frac{(1-s)+\mf{a}}{2}\right) = O(\log|s|)$ and $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right) = O(\log|s|)$. Putting these estimates together with the first term yields
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_9}
          \frac{L'}{L}(s,\chi) \ll \log(q|s|),
        \end{equation}
        for $\s < -1$. Using \cref{equ:explicit_formula_Dirichlet_proof_9}, the parts of the horizontal integrals over $\eta_{2}$ and $\eta_{4}$ with $-U \le \s \le -1$ contribute
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_10}
          \ll \frac{\log(qT)}{T}\int_{-U}^{-1}x^{\s}\,d\s \ll \frac{\log(qT)}{Tx\log(x)}.
        \end{equation}
        Combining \cref{equ:explicit_formula_Dirichlet_proof_8,equ:explicit_formula_Dirichlet_proof_10} gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_11}
          \frac{1}{2\pi i}\int_{\eta_{2}+\eta_{4}}-\frac{L'}{L}(s)x^{s}\,\frac{ds}{s} \ll \frac{x\log^{2}(qT)}{T\log(x)}+\frac{\log(qT)}{Tx\log(x)} \ll \frac{x\log^{2}(qT)}{T\log(x)}.
        \end{equation}
        To estimate the vertical integral, we use \cref{equ:explicit_formula_Dirichlet_proof_9} again to conclude that
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_12}
          \frac{1}{2\pi i}\int_{\eta_{3}}-\frac{L'}{L}(s,\chi)x^{s}\,\frac{ds}{s} \ll \frac{\log(qU)}{U}\int_{-T}^{T}x^{-U}\,dt \ll \frac{T\log(qU)}{Ux^{U}}.
        \end{equation}
        Combining \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_11,equ:explicit_formula_Dirichlet_proof_12} and taking the limit as $U \to \infty$, the error term in \cref{equ:explicit_formula_Dirichlet_proof_12} vanishes and the sum over $m$ in \cref{equ:explicit_formula_Dirichlet_proof_7,equ:explicit_formula_Dirichlet_proof_7'} evaluates to $-\tanh^{-1}(x^{-1})$ or $\frac{1}{2}\log(1-x^{-2})$ respectively (as we have already mentioned) giving
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_13}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-b(\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(qT)}{T\log(x)},
        \end{equation}
        if $\chi$ is odd, and
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_13'}
          J(x,T,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(qT)}{T\log(x)},
        \end{equation}
        if $\chi$ is even.
        Substituting \cref{equ:explicit_formula_Dirichlet_proof_13,equ:explicit_formula_Dirichlet_proof_13'} into \cref{equ:explicit_formula_Dirichlet_proof_6} in the respective cases, we obtain
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_14}
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-b(\chi)+\tanh^{-1}(x^{-1})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        if $\chi$ is odd, and
        \begin{equation}\label{equ:explicit_formula_Dirichlet_proof_14'}
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}-\log(x)-b(\chi)-\frac{1}{2}\log(1-x^{-2})+\frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \end{equation}
        if $\chi$ is even, and where the second to last term on the right-hand side in both equations are obtained by combining the error term in \cref{equ:explicit_formula_Dirichlet_proof_11} with the first error term in \cref{equ:explicit_formula_Dirichlet_proof_6}. The theorem follows by taking the limit as $T \to \infty$.
      \end{proof}

      As was the case for $\psi(x)$, the convergence of the right-hand side in the explicit formula for $\psi(x,\chi)$ is uniform in any interval not containing a prime power since $\psi(x,\chi)$ is continuous there. Moreover, there is an approximate formula for $\psi(x,\chi)$ as a corollary which holds for all Dirichlet characters:


      \begin{corollary}\label{cor:explicit_formula_Dirichlet_corollary}
         Let $\chi$ be a Dirichlet character modulo $m > 1$. Then for $2 \le T \le x$,
        \[
          \psi_{0}(x,\chi) = -\frac{x^{\b_{1}}}{\b_{1}}-\psum_{|\g| < T}\frac{x^{\rho}}{\rho}+R(x,T,\chi),
        \]
        where $\rho$ runs over the nontrivial zeros of $L(s,\chi)$ counted with multiplicity and ordered with respect to the size of the ordinate, the $'$ in the sum indicates that we are excluding the terms corresponding to real zeros, the term corresponding to a Siegel zero $\b_{1}$ is present only if $L(s,\chi)$ admits a Siegel zero, and
        \[
          R(x,T,\chi) \ll \frac{x\log^{2}(xmT)}{T}+x^{1-\b_{1}}\log(x)+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        where $\<x\>$ is the distance between $x$ and the nearest prime power other than $x$ if $x$ itself is a prime power and again the term corresponding to a Siegel zero $\b_{1}$ is present only if $L(s,\chi)$ admits a Siegel zero. Moreover, if $x$ is an integer, we have the simplified estimate
        \[
          R(x,T,\chi) \ll \frac{x\log^{2}(xmT)}{T}+x^{1-\b_{1}}\log(x).
        \]
      \end{corollary}
      \begin{proof}
        We first reduced to the case that $\chi$ is primitive. Let $\wtilde{\chi}$ be the primitive character inducing $\chi$ and denote its conductor by $q$. We estimate
        \begin{equation}\label{equ:difference_between_Dirichlet-Chebyshevs}
          \begin{aligned}
            |\psi_{0}(x,\chi)-\psi_{0}(x,\wtilde{\chi})| &\le \sum_{\substack{n \le x \\ (n,m) > 1}}\L(n) \\
            &= \sum_{p \mid m}\sum_{\substack{v \ge 1 \\ p^{v} \le x}}\log(p) \\
            &\ll \log(x)\sum_{p \mid m}\log(p) \\
            &\ll \log(x)\log(m) \\
            &\ll \log^{2}(xm),
          \end{aligned}
        \end{equation}
        where the third line holds because $p^{v} \le x$ implies $v \le \frac{\log(x)}{\log(p)}$ so that there are $O(\log(x))$ many terms in the inner sum and in the last line we have used the simple estimates $\log(x) \ll \log(xm)$ and $\log(m) \ll \log(xm)$. Therefore the difference between $\psi_{0}(x,\chi)$ and $\psi_{0}(x,\wtilde{\chi})$ is $O(\log^{2}(xm))$. Now for $2 \le T \le x$, we have $\log^{2}(xm) \ll \frac{x\log^{2}(xmT)}{T}$, which implies that the difference is absorbed by $\frac{x\log^{2}(xmT)}{T}$ which is the first term in the error for $R(x,T,\chi)$. As $R(x,T,\wtilde{\chi}) \ll R(x,T,\chi)$ because $q \le m$, and there are finitely many nontrivial zeros of $L(s,\chi)$ that are not nontrivial zeros of $L(s,\wtilde{\chi})$ (all occurring on the line $\s = 0$), it suffices to assume that $\chi$ is primitive. The claim will follow from estimating terms in \cref{equ:explicit_formula_Dirichlet_proof_14,equ:explicit_formula_Dirichlet_proof_14'}. We will estimate the constant $b(\chi)$ first. The explicit formula for $\frac{L'}{L}(s,\chi)$ at $s = 2$ implies
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_1}
          0 = -\frac{L'}{L}(2,\chi)+B(\chi)-\frac{1}{2}\log\left(\frac{q}{\pi}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{2+\mf{a}}{2}\right)+\sum_{\rho}\left(\frac{1}{2-\rho}+\frac{1}{\rho}\right).
        \end{equation}
        Subtracting \cref{equ:explicit_formula_Dirichlet_corollary_1} from the explicit formula for $\frac{L'}{L}(s,\chi)$ gives
        \[
          \frac{L'}{L}(s,\chi) = \frac{L'}{L}(2,\chi)+\frac{1}{2}\frac{\G'}{\G}\left(\frac{2+\mf{a}}{2}\right)-\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right)+\sum_{\rho}\left(\frac{1}{s-\rho}-\frac{1}{2-\rho}\right).
        \]
        As the first two terms are constant, we obtain a weaker estimate
        \[
          \frac{L'}{L}(s,\chi) = -\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right)+\sum_{\rho}\left(\frac{1}{s-\rho}-\frac{1}{2-\rho}\right)+O(1).
        \]
        If $\chi$ is odd, we set $s = 0$ since $\frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right)$ does not have a pole there. If $\chi$ is even, we compare constant terms in the Laurent series using the Laurent series
        \[
          \frac{L'}{L}(s,\chi) = \frac{1}{s}+b(\chi)+\cdots \quad \text{and} \quad \frac{1}{2}\frac{\G'}{\G}\left(\frac{s+\mf{a}}{2}\right) = \frac{1}{s}+b+\cdots,
        \]
        for some constant $b$. In either case, we arrive at
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_2}
          b(\chi) = -\sum_{\rho}\left(\frac{1}{\rho}+\frac{1}{2-\rho}\right)+O(1).
        \end{equation}
        Let $\rho = \b+i\g$. For all the terms with $|\g| > 1$, we estimate
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_3}
          \sum_{|\g| > 1}\left(\frac{1}{\rho}+\frac{1}{2-\rho}\right) \le \sum_{|\g| > 1}\left|\frac{1}{\rho}+\frac{1}{2-\rho}\right| = \sum_{|\g| > 1}\frac{2}{|\rho(2-\rho)|} \ll \sum_{|\g| > 1}\frac{1}{|2-\rho|^{2}} \ll \log(q),
        \end{equation}
        where the second to last estimate holds because $|\rho| \gg |2-\rho|$ as $\b$ is bounded and the last estimate holds by \cref{lem:Riemann_von_Mangoldt_Dirichlet_L-functions_lemma} (ii) since $|2-\rho| \ge |\g|$. For the terms corresponding to $2-\rho$ with $|\g| \le 1$, we have
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_4}
          \sum_{|\g| \le 1}\frac{1}{2-\rho} \le \sum_{|\g| \le 1}\frac{1}{|2-\rho|} \ll \sum_{|\g| \le 1}\frac{1}{|2-\rho|^{2}} \ll \log(q),
        \end{equation}
        where the second to last estimate holds because $|2-\rho| \gg |2-\rho|^{2}$ as $\rho$ is bounded (because both $\b$ and $\g$ are) and the last estimate holds by \cref{lem:Riemann_von_Mangoldt_Dirichlet_L-functions_lemma} (i). Combining \cref{equ:explicit_formula_Dirichlet_corollary_2,equ:explicit_formula_Dirichlet_corollary_3,equ:explicit_formula_Dirichlet_corollary_4} yields
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_5}
          b(\chi) = -\sum_{|\g| \le 1}\frac{1}{\rho}+O(\log(q)).
        \end{equation}
        Inserting \cref{equ:explicit_formula_Dirichlet_corollary_5} into \cref{equ:explicit_formula_Dirichlet_proof_14,equ:explicit_formula_Dirichlet_proof_14'} and noting that $\tanh^{-1}(x^{-1})$ and $\frac{1}{2}\log(1-x^{-2})$ are both bounded for $x \ge 2$ gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_6}
          \psi_{0}(x,\chi) = -\sum_{|\g| < T}\frac{x^{\rho}}{\rho}+\sum_{|\g| \le 1}\frac{1}{\rho}+R'(x,T,\chi),
        \end{equation}
        where
        \[
          R'(x,T,\chi) \ll \frac{x\log^{2}(xqT)}{T}+\log(x)\min\left(1,\frac{x}{T\<x\>}\right),
        \]
        and we have absorbed the error in \cref{equ:explicit_formula_Dirichlet_corollary_5} into $\frac{x\log^{2}(xqT)}{T}$ because $2 \le T \le x$. By the classical zero-free region for $L(s,\wtilde{\chi})$, all of the zeros $\rho$ with $|\g| < T$ (we have assume $T \ge 2$ so that this includes the zeros with $|\g| \le 1$) satisfy $\b \ll 1-\frac{1}{\log(qT)}$ except for possibly a single real Siegel zero $\b_{1}$ if $\chi$ is quadratic. Since $\conj{\rho}$ is a zero if $\rho$ is, there will be another real zero $1-\b_{1}$. Extracting the terms corresponding to these two zeros in \cref{equ:explicit_formula_Dirichlet_corollary_6}, gives
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_7}
          \psi_{0}(x,\chi) = -\psum_{|\g| < T}\frac{x^{\rho}}{\rho}+\psum_{|\g| \le 1}\frac{1}{\rho}-\frac{x^{\b_{1}}-1}{\b_{1}}-\frac{x^{1-\b_{1}}-1}{1-\b_{1}}+R(x,T,\chi),
        \end{equation}
        where the $'$ on the sums indicates that we are excluding the terms corresponding to real zeros and the terms corresponding to $\b_{1}$ and $1-\b_{1}$ are present if and only if $L(s,\chi)$ admits a Siegel zero. We now estimate some of the terms in \cref{equ:explicit_formula_Dirichlet_corollary_7}. For the second sum, we have $\rho \gg \frac{1}{\log(q)}$ since $\g$ is bounded and these zeros satisfy $\b \ll 1-\frac{1}{\log(q)}$. Thus
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_8}
          \psum_{|\g| \le 1}\frac{1}{\rho} \ll \psum_{|\g| \le 1}\log(q) \ll \log^{2}(q),
        \end{equation}
        where the last estimate holds by \cref{lem:Riemann_von_Mangoldt_Dirichlet_L-functions_lemma} (i). Similarly,
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_9}
          \frac{x^{1-\b_{1}}-1}{1-\b_{1}} \ll x^{1-\b_{1}}\log(x),
        \end{equation}
        because $1-\b_{1} \gg \frac{1}{\log(q)} \gg \frac{1}{\log(x)}$. Substituting \cref{equ:explicit_formula_Dirichlet_corollary_8,equ:explicit_formula_Dirichlet_corollary_9} into \cref{equ:explicit_formula_Dirichlet_corollary_7} and noting that $\b_{1}$ is bounded, yields
        \begin{equation}\label{equ:explicit_formula_Dirichlet_corollary_10}
          \psi_{0}(x,\chi) = -\frac{x^{\b_{1}}}{\b_{1}}-\psum_{|\g| < T}\frac{x^{\rho}}{\rho}+R(x,T,\chi),
        \end{equation}
        where
        \[
          R(x,T,\chi) \ll \frac{x\log^{2}(xqT)}{T}+x^{1-\b_{1}}\log(x)+\log(x)\min\left(1,\frac{x}{T\<x\>}\right)
        \]
        and we have absorbed the error in \cref{equ:explicit_formula_Dirichlet_corollary_8} into $\frac{x\log^{2}(xqT)}{T}$ because because $2 \le T \le x$. If $x$ is an integer, then $\<x\> \ge 1$ so that $\log(x)\min\left(1,\frac{x}{T\<x\>}\right) \le \frac{x\log(x)}{T}$ and this term can be absorbed by $\frac{x\log^{2}(xqT)}{T}$.
      \end{proof}
  \section{Prime Number Theorems}
    \subsection*{The Prime Number Theorem}
      The \textbf{prime counting function}\index{prime counting function} $\pi(x)$ is defined by
      \[
        \pi(x) = \sum_{p \le x}1,
      \]
      for $x > 0$. Equivalently, $\pi(x)$ counts the number of primes that no larger than $x$. Euclid's infinitude of the primes is equivalent to $\pi(x) \to \infty$ as $x \to \infty$. A more interesting question is to ask how the primes are distributed among the integers. The classical \textbf{prime number theorem}\index{prime number theorem} answers this question and the precise statement is the following:

      \begin{theorem}[Prime number theorem, classical version]
        For $x \ge 2$,
        \[
          \pi(x) \sim \frac{x}{\log(x)}.
        \]
      \end{theorem}

      We will delay the proof for the moment and give some intuition and historical context to the result. Intuitively, the prime number theorem is a result about how dense the primes are in the integers. To see this, notice that the result is equivalent to the asymptotic
      \[
        \frac{\pi(x)}{x} \sim \frac{1}{\log(x)}.
      \]
      Letting $x \ge 2$, the left-hand side is the probability that a randomly chosen positive integer no larger than $x$ is prime. Thus the asymptotic result says that for large enough $x$, the probability that a randomly chosen integer no larger than $x$ is prime is approximately $\frac{1}{\log(x)}$. We can also interpret this as saying that the average gap between primes no larger than $x$ is approximately $\frac{1}{\log(x)}$. As a consequence, a positive integer with at most $2n$ digits is about half as likely to be prime than a positive integer with at most $n$ digits. Indeed, there are $10^{n}-1$ numbers with at most $n$ digits, $10^{2n}-1$ with at most $2n$ digits, and $\log(10^{2n}-1)$ is approximately $2\log(10^{n})$. Note that the prime number theorem says nothing about the exact error $\pi(x)-\frac{x}{\log(x)}$ as $x \to \infty$. The theorem only says that the relative error tends to zero:
      \[
        \lim_{x \to \infty}\frac{\pi(x)-\frac{x}{\log(x)}}{\frac{x}{\log(x)}} = 0.
      \]
      Now for some historical context. While Gauss was not the first to put forth a conjectural form of the prime number theorem, he was known for compiling extensive tables of primes and he suspected that the density of the primes up to $x$ was roughly $\frac{1}{\log(x)}$. How might one suspect this is the correct density? Well, let $d\d_{p}$ be the weighted point measure that assigns $\frac{1}{p}$ at the prime $p$ and zero everywhere else. Then
      \[
        \sum_{p \le x}\frac{1}{p} = \int_{1}^{x}\,d\d_{p}(u).
      \]
      We can interpret the integral as integrating the density $d\d_{p}$ over the volume $[1,x]$. Let's try and find a more explicit expression for the density $d\d_{p}$. Euler (see \cite{euler1744variae}), argued
      \[
        \sum_{p \le x}\frac{1}{p} \sim \log\log(x).
      \]
      But notice that
      \[
        \log\log(x) = \int_{1}^{\log(x)}\frac{du}{u} = \int_{e}^{x}\frac{1}{u}\,\frac{du}{\log{u}},
      \]
      where in the second equality we have made the change of variables $u \to \log(u)$. So altogether,
      \[
        \sum_{p \le x}\frac{1}{p} \sim \int_{e}^{x}\frac{1}{u}\,\frac{du}{\log{u}}.
      \]
      This is an asymptotic formula that gives a more explicit representation of the density $d\d_{p}$. Notice that both sides of this asymptotic are weighted the same, the left-hand side by $\frac{1}{p}$, and the right-hand side by $\frac{1}{u}$. If we remove these weight (this is not strictly allowed), then we might hope
      \[
        \pi(x) = \sum_{p \le x}1 \sim \int_{e}^{x}\frac{du}{\log(u)}.
      \]
      Accordingly, we define the \textbf{logarithmic integral}\index{logarithmic integral} $\Li(x)$ by
      \[
        \Li(x) = \int_{2}^{x}\frac{dt}{\log(t)},
      \]
      for $x \ge 2$. Notice that $\Li(x) \sim \frac{x}{\log{x}}$ because
      \[
        \lim_{x \to \infty}\left|\frac{\Li(x)}{\frac{x}{\log{x}}}\right| = \lim_{x \to \infty}\left|\frac{\int_{2}^{x}\frac{dt}{\log(t)}}{\frac{x}{\log{x}}}\right| = \lim_{x \to \infty}\left|\frac{\frac{1}{\log(x)}}{\frac{\log(x)-1}{\log^{2}(x)}}\right| = \lim_{x \to \infty}\left|\frac{\log(x)}{\log(x)-1}\right| = 1.
      \]
      where in the second equality we have used  L'H\^opital's rule. So an equivalent statement is the logarithmic integral version of the \textbf{prime number theorem}\index{prime number theorem}:

      \begin{theorem}[Prime number theorem, logarithmic integral version]
        For $x \ge 2$,
        \[
          \pi(x) \sim \Li(x).
        \]
      \end{theorem}

      Interpreting the logarithmic integral as an integral of density over volume, then for large $x$ the density of primes up to $x$ is approximately $\frac{1}{\log(x)}$ which is what both versions of the prime number theorem claim. Legendre was the first to put forth a conjectural form of the prime number theorem. In 1798 (see \cite{legendre1798essai}) he claimed that $\pi(x)$ was of the form
      \[
        \frac{x}{A\log(x)+B},
      \]
      for some constants $A$ and $B$. In 1808 (see \cite{legendre1808essai}) he refined his conjecture by claiming
      \[
        \frac{x}{\log(x)+A(x)},
      \]
      where $\lim_{x \to \infty}A(x) \approx 1.08366$. Riemann's 1859 manuscript (see \cite{riemann1859ueber}) contains an outline for how to prove the prime number theorem, but it was not until 1896 that the prime number theorem was proved independently by Hadamard and de la Vall\'ee Poussin (see \cite{hadamard1896distribution} and \cite{poussin1897recherches}). Their proofs, as well as every proof thereon out until 1949, used complex analytic methods in an essential way (there are now elementary proofs due to Erd\"os and Selberg). We are now ready to prove the prime number theorem. Strictly speaking, we will prove the absolute error version of the \textbf{prime number theorem}\index{prime number theorem}, due to de la Vall\'ee Poussin, which bounds the absolute error between $\pi(x)$ and $\Li(x)$:

      \begin{theorem}[Prime number theorem, absolute error version]
        For $x \ge 2$, there exists a positive constant $c$ such that
        \[
          \pi(x) = \Li(x)+O\left(xe^{-c\sqrt{\log(x)}}\right).
        \]
      \end{theorem}
      \begin{proof}
        It suffices to assume $x$ is an integer, because $\pi(x)$ can only change value at integers and the other functions in the statement are increasing. We will first prove
        \begin{equation}\label{equ:prime_number_theorem_zeta_1}
          \psi(x) = x+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        for some positive constant $c$. To achieve this, we estimate the sum over the nontrivial zeros of $\z(s)$ in \cref{cor:explicit_formula_zeta_corollary}. So let $T > 2$ not coinciding with the ordinate of a nontrivial zero, and suppose $\rho = \b+i\g$ is a nontrivial zero with $|\g| < T$. By the classical version of the zero-free region for $\z(s)$, we know $\b < 1-\frac{c}{\log(T)}$ for some positive constant $c$. It follows that
        \begin{equation}\label{equ:prime_number_theorem_zeta_2}
          |x^{\rho}| = x^{\b} < x^{1-\frac{c}{\log(T)}} = xe^{-c\frac{\log(x)}{\log(T)}}.
        \end{equation}
        As $|\rho| > |\g|$, letting $\g_{1} > 0$ (which is bounded away from zero since the zeros of $\z(s)$ are discrete and we know that there is no real nontrivial zero) be the ordinate of the first nontrivial zero, applying integration by parts gives
        \begin{equation}\label{equ:prime_number_theorem_zeta_3}
          \sum_{|\g| < T}\frac{1}{\rho} \ll \sum_{\g_{1} \le |\g| < T}\frac{1}{\g} \ll \int_{\g_{1}}^{T}\frac{dN(t)}{t} = \frac{N(T)}{T}+\int_{\g_{1}}^{T}\frac{N(t)}{t^{2}}\,dt \ll \log^{2}(T),
        \end{equation}
        where in the last estimate we have used that $N(t) \ll t\log(t)$ which follows from \cref{cor:density_of_nontrivial_zeros_zeta}. Putting \cref{equ:prime_number_theorem_zeta_2,equ:prime_number_theorem_zeta_3} together gives
        \begin{equation}\label{equ:prime_number_theorem_zeta_4}
          \sum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll x\log^{2}(T)e^{-c\frac{\log(x)}{\log(T)}}.
        \end{equation}
        As $\psi(x) \sim \psi_{0}(x)$ and $x$ is an integer, \cref{equ:prime_number_theorem_zeta_4} with \cref{cor:explicit_formula_zeta_corollary} together imply
        \begin{equation}\label{equ:prime_number_theorem_zeta_5}
          \psi(x)-x \ll x\log^{2}(T)e^{-c\frac{\log(x)}{\log(T)}}+\frac{x\log^{2}(xT)}{T}.
        \end{equation}
        We will now let $T$ be determined by
        \[
          \log^{2}(T) = \log(x),
        \]
        or equivalently,
        \[
          T = e^{\sqrt{\log(x)}}.
        \]
        With this choice of $T$ (note that if $x \ge 2$ then $T > 2$), we can estimate \cref{equ:prime_number_theorem_zeta_5} as follows:
        \begin{align*}
          \psi(x)-x &\ll x\log(x)e^{-c\sqrt{\log(x)}}+x\left(\log^{2}(x)+\log(x)\right)e^{-\sqrt{\log(x)}} \\
          &\ll x\log(x)e^{-c\sqrt{\log(x)}}+x\log^{2}(x)e^{-\sqrt{\log(x)}} \\
          &\ll x\log^{2}(x)e^{-\min(1,c)\sqrt{\log(x)}}.
        \end{align*}
        As $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$, we conclude that
        \[
          \psi(x)-x \ll xe^{-c\sqrt{\log(x)}},
        \]
        for some smaller $c$ with $c < 1$. This is equivalent to \cref{equ:prime_number_theorem_zeta_1}. Now let
        \[
          \pi_{1}(x) = \sum_{n \le x}\frac{\L(n)}{\log(n)}.
        \]
        We can write $\pi_{1}(x)$ in terms of $\psi(x)$ as follows:
        \begin{align*}
          \pi_{1}(x) &= \sum_{n \le x}\frac{\L(n)}{\log(n)} \\
          &= \sum_{n \le x}\L(n)\int_{n}^{x}\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{n \le x}\L(n) \\
          &= \int_{2}^{x}\sum_{n \le t}\L(n)\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{n \le x}\L(n) \\
          &= \int_{2}^{x}\frac{\psi(t)}{t\log^{2}(t)}\,dt+\frac{\psi(x)}{\log(x)}.
        \end{align*}
        Applying \cref{equ:prime_number_theorem_zeta_1} to the last expression yields
        \begin{equation}\label{equ:prime_number_theorem_zeta_6}
          \pi_{1}(x) = \int_{2}^{x}\frac{t}{t\log^{2}(t)}\,dt+\frac{x}{\log(x)}+O\left(\int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)}\right).
        \end{equation}
        Upon applying integrating by parts to the main term in \cref{equ:prime_number_theorem_zeta_6}, we obtain
        \begin{equation}\label{equ:prime_number_theorem_zeta_7}
          \int_{2}^{x}\frac{t}{t\log^{2}(t)}\,dt+\frac{x}{\log(x)} = \int_{2}^{x}\frac{dt}{\log(t)}+\frac{2}{\log(2)} = \Li(x)+\frac{2}{\log(2)}.
        \end{equation}
        As for the error term in \cref{equ:prime_number_theorem_zeta_6}, $\log^{2}(t)$ and $\log(x)$ are both bounded away from zero so that
        \[
          \int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)} \ll \int_{2}^{x}e^{-c\sqrt{\log(t)}}\,dt+xe^{-c\sqrt{\log(x)}}.
        \]
        For $t \le x^{\frac{1}{4}}$, we use the bound $e^{-c\sqrt{\log(t)}} < 1$ so that
        \[
          \int_{2}^{x^{\frac{1}{4}}}e^{-c\sqrt{\log(t)}}\,dt < \int_{2}^{x^{\frac{1}{4}}}\,dt \ll x^{\frac{1}{4}}.
        \]
        For $t > x^{\frac{1}{4}}$, $\sqrt{\log(t)} > \frac{1}{2}\sqrt{\log(x)}$ and thus
        \[
          \int_{2}^{x^{\frac{1}{4}}}e^{-c\sqrt{\log(t)}}\,dt \le e^{-c\frac{1}{2}\sqrt{\log(x)}}\int_{2}^{x^{\frac{1}{4}}}\,dt \ll x^{\frac{1}{4}}e^{-c\frac{1}{2}\sqrt{\log(x)}}. 
        \]
        All of these estimates together imply
        \begin{equation}\label{equ:prime_number_theorem_zeta_8}
          \int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)} \ll xe^{-c\sqrt{\log(x)}},
        \end{equation}
        for some smaller $c$. Combining \cref{equ:prime_number_theorem_zeta_6,equ:prime_number_theorem_zeta_7,equ:prime_number_theorem_zeta_8} yields
        \begin{equation}\label{equ:prime_number_theorem_zeta_9}
          \pi_{1}(x) = \Li(x)+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        where the constant in \cref{equ:prime_number_theorem_zeta_7} has been absorbed into the error term. We now pass from $\pi_{1}(x)$ to $\pi(x)$. If $p$ is a prime such that $p^{m} < x$ for some $m \ge 1$, then $p < x^{\frac{1}{2}} < x^{\frac{1}{3}} < \cdots < x^{\frac{1}{m}}$. Therefore
        \begin{equation}\label{equ:prime_number_theorem_zeta_10}
          \pi_{1}(x) = \sum_{n \le x}\frac{\L(n)}{\log(n)} = \sum_{p^{m} \le x}\frac{\log(p)}{m\log(p)} = \pi(x)+\frac{1}{2}\pi(x^{\frac{1}{2}})+\cdots.
        \end{equation}
        Moreover, as $\pi(x^{\frac{1}{n}}) < x^{\frac{1}{n}}$ for any $n \ge 1$, we see that $\pi(x)-\pi_{1}(x) = O(x^{\frac{1}{2}})$. This estimate together with \cref{equ:prime_number_theorem_zeta_9,equ:prime_number_theorem_zeta_10} gives
        \[
          \pi(x) = \Li(x)+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \]
        because $x^{\frac{1}{2}} \ll xe^{-c\sqrt{\log(x)}}$. This completes the proof.
      \end{proof}

      The proof of the logarithmic integral and classical versions of the prime number theorem are immediate:

      \begin{proof}[Proof of prime number theorem, logarithmic integral and classical versions]
        By the absolute error version of the prime number theorem,
        \[
          \pi(x) = \Li(x)\left(1+O\left(\frac{xe^{-c\sqrt{\log(x)}}}{\Li(x)}\right)\right).
        \]
        But we have shown $\Li(x) \sim \frac{x}{\log(x)}$ so that
        \[
          \frac{xe^{-c\sqrt{\log(x)}}}{\Li(x)} \sim \log(x)e^{-c\sqrt{\log(x)}} = o(1),
        \]
        where the equality holds since $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$. The logarithm integral version follows. The classical version also holds using the asymptotic $\Li(x) \sim \frac{x}{\log(x)}$.
      \end{proof}
      
      In the proof of the logarithmic integral and classical versions of the prime number theorem, we saw that $xe^{-c\sqrt{\log(x)}} < \frac{x}{\log(x)}$ for sufficiently large $x$. Therefore the exact error $\pi(x)-\Li(x)$ grows slower than $\pi(x)-\frac{x}{\log{x}}$ for sufficiently large $x$. This means that $\Li(x)$ is a better numerical approximation to $\pi(x)$ than $\frac{x}{\log(x)}$. There is also the following result due to Hardy and Littlewood (see \cite{hardy1916contributions}) which gives us more information:

      \begin{proposition}\label{thm:Littlewood_Li_approximation_theorem}
        $\pi(x)-\Li(x)$ changes sign infinitely often as $x \to \infty$.
      \end{proposition}

      So in addition, \cref{thm:Littlewood_Li_approximation_theorem} implies that $\Li(x)$ never underestimates or overestimates $\pi(x)$ continuously. On the other hand, the exact error $\pi(x)-\frac{x}{\log(x)}$ is positive provided $x \ge 17$ (see \cite{rosser1962approximate}). It is also worthwhile to note that in 1901 Koch showed that the Riemann hypothesis improves the error term in the absolute error version of the prime number theorem (see \cite{von1901distribution}):

      \begin{proposition}
        For $x \ge 2$, under the Riemann hypothesis
        \[
          \pi(x) = \Li(x)+O(\sqrt{x}\log(x)).
        \]
      \end{proposition}
      \begin{proof}
        If $\rho$ is a nontrivial zero of $\z(s)$, the Riemann hypothesis implies $|x^{\rho}| = \sqrt{x}$. Therefore as in the proof of the absolute error version of the prime number theorem,
        \[
          \sum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll \sqrt{x}\log^{2}(T),
        \]
        for $T > 2$ not coinciding with the ordinate of a nontrivial zero. Repeating the same argument with $T$ determined by
        \[
          T^{2} = x,
        \]
        gives
        \[
          \psi(x) = x+O(\sqrt{x}\log^{2}(x)),
        \]
        and then transferring to $\pi_{1}(x)$ and finally $\pi(x)$ gives
        \[
          \pi(x) = x+O(\sqrt{x}\log(x)).
        \]
      \end{proof}
    \subsection*{The Siegel–Walfisz Theorem}
      Let $a$ and $m$ be positive integers with $m > 1$ and $(a,m) = 1$. The \textbf{prime counting function}\index{prime counting function} $\pi(x:a,m)$ is defined by
      \[
        \pi(x;a,m) = \sum_{\substack{p \le x \\ p \equiv a \tmod{m}}}1,
      \]
      for $x > 0$. Equivalently, $\pi(x;a,m)$ counts the number of primes that no larger than $x$ and are equivalent to $a$ modulo $m$. This is the analog of $\pi(x)$ that is naturally associated to Dirichlet characters modulo $m$. Accordingly, there are asymptotics for $\pi(x;a,m)$ analogous to those for $\pi(x)$. To prove them, we will require an auxiliary function. The \textbf{Chebyshev function} $\psi(x;a,m)$, for $x \ge 1$, is defined by
      \[
        \psi(x;a,m) = \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n).
      \]
      This is just $\psi(x)$ restricted to only those terms equivalent to $a$ modulo $m$. As for the asymptotics, the classical \textbf{Siegel–Walfisz theorem}\index{Siegel–Walfisz theorem} is the first of them and the precise statement is the following:

      \begin{theorem}[Siegel–Walfisz theorem, classical version]
        Let $a$ and $m$ be positive integers with $m > 1$, $(a,m) = 1$, and let $N \ge 1$. For $x \ge 2$,
        \[
          \pi(x;a,m) \sim \frac{x}{\vphi(m)\log(x)},
        \]
        provided $m \le \log^{N}(x)$.
      \end{theorem}
      
      The logarithmic integral version of the \textbf{Siegel–Walfisz theorem}\index{Siegel–Walfisz theorem} is equivalent and sometimes more useful:

      \begin{theorem}[Siegel–Walfisz theorem, logarithmic integral version]
        Let $a$ and $m$ be positive integers with $m > 1$, $(a,m) = 1$, and let $N \ge 1$. For $x \ge 2$,
        \[
          \pi(x;a,m) \sim \frac{\Li(x)}{\vphi(m)},
        \]
        provided $m \le \log^{N}(x)$.
      \end{theorem}
      
      We will prove the absolute error version of the \textbf{Siegel–Walfisz theorem}\index{Siegel–Walfisz theorem} which is slightly stronger as it bounds the absolute error between $\pi(x;a,m)$ and $\frac{\Li(x)}{\vphi(m)}$:

      \begin{theorem}[Siegel–Walfisz theorem, absolute error version]
        Let $a$ and $m$ be positive integers with $m > 1$, $(a,m) = 1$, and let $N \ge 1$. For $x \ge 2$, there exists a positive constant $c$ such that
        \[
          \pi(x;a,m) = \frac{\Li(x)}{\vphi(m)}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \]
        provided $m \le \log^{N}(x)$.
      \end{theorem}
      \begin{proof}
        It suffices to assume $x$ is an integer, because $\pi(x;a,m)$ can only change value at integers and the other functions in the statement are increasing. We being with the identity
        \begin{equation}\label{equ:Siegel-Walfisz_1}
          \psi(x;a,m) = \frac{1}{\vphi(m)}\sum_{\chi \tmod{m}}\cchi(a)\psi(x,\chi),
        \end{equation}
        which holds by the orthogonality relations (\cref{prop:Dirichlet_orthogonality_relations} (ii)). Let $\wtilde{\chi}$ be the primitive character inducing $\chi$. Then \cref{equ:difference_between_Dirichlet-Chebyshevs} implies
        \begin{equation}\label{equ:Siegel-Walfisz_2}
          \psi(x,\chi) = \psi(x,\wtilde{\chi})+O(\log^{2}(xm)).
        \end{equation}
        When $\chi = \chi_{m,0}$ we have $\psi(x,\wtilde{\chi}) = \psi(x)$, and as $\psi(x,\chi) \sim \psi_{0}(x,\chi)$, substituting \cref{equ:prime_number_theorem_zeta_1} into \cref{equ:Siegel-Walfisz_2} gives
        \begin{equation}\label{equ:Siegel-Walfisz_3}
          \psi(x,\chi_{m,0}) = \psi(x)+O\left(xe^{-c\sqrt{\log(x)}}+\log^{2}(xm)\right),
        \end{equation}
        for some positive constant $c$. Upon combining \cref{equ:Siegel-Walfisz_1,equ:Siegel-Walfisz_3}, we obtain
        \begin{equation}\label{equ:Siegel-Walfisz_4}
          \psi(x;a,m) = \frac{x}{\vphi(m)}+\frac{1}{\vphi(m)}\sum_{\substack{\chi \tmod{m} \\ \chi \neq \chi_{m,0}}}\cchi(a)\psi(x,\chi)+O\left(\frac{1}{\vphi(m)}\left(xe^{-c\sqrt{\log(x)}}+\log^{2}(xm)\right)\right).
        \end{equation}
        We now prove
        \begin{equation}\label{equ:Siegel-Walfisz_5}
          \psi(x,\chi) = -\frac{x^{\b_{1}}}{\b_{1}}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        for some potentially different constant $c$, where $\chi \neq \chi_{m,0}$, and the term corresponding to $\b_{1}$ appears if and only if $L(s,\chi)$ admits a Siegel zero. To accomplish this, we estimate the sum over the nontrivial zeros of $L(s,\chi)$ in \cref{cor:explicit_formula_Dirichlet_corollary}. So fix a non-principal $\chi$ modulo $m$ and let $\wtilde{\chi}$ be the primitive character inducing $\chi$. Let $2 \le T \le x$ not coinciding with the ordinate of a nontrivial zero and let $\rho = \b+i\g$ be a nontrivial zero of $L(s,\chi)$ with $|\g| < T$ and not a real zero. By the classical zero-free region for $L(s,\wtilde{\chi})$, all of the zeros $\rho$ satisfy $\b < 1-\frac{c}{\log(mT)}$ for some possibly different constant $c$ (recall that the zeros of $L(s,\wtilde{\chi})$ and $L(s,\chi)$ are the same). It follows that
        \begin{equation}\label{equ:Siegel-Walfisz_6}
          |x^{\rho}| = x^{\b} < x^{1-\frac{c}{\log(mT)}} = xe^{-c\frac{\log(x)}{\log(mT)}}.
        \end{equation}
        As $|\rho| > |\g|$, for those terms with $|\g| > 1$ (unlike the Riemann zeta function we do not have a positive lower bound for the first ordinate $\g_{1}$ of a nontrivial zero that is not real since Siegel zeros may exist), applying integration by parts gives
        \begin{equation}\label{equ:Siegel-Walfisz_7}
          \sum_{1 < |\g| < T}\frac{1}{\rho} \ll \sum_{1 < |\g| < T}\frac{1}{\g} \ll \int_{1}^{T}\frac{dN(t,\wtilde{\chi})}{t} = \frac{N(T,\wtilde{\chi})}{T}+\int_{1}^{T}\frac{N(t,\wtilde{\chi})}{t^{2}}\,dt \ll \log^{2}(mT) \ll \log^{2}(xm),
        \end{equation}
        where in the second to last estimate we have used that $N(t,\wtilde{\chi}) \ll t\log(qt) \ll t\log(mt)$ which follows from \cref{cor:density_of_nontrivial_zeros_Dirichlet} and that $q \le m$ and in the last estimate we have used that $T \le x$. For the remaining terms with $|\g| \le 1$ (that are not real), \cref{equ:explicit_formula_Dirichlet_corollary_8} along with $q \le m$ gives
        \begin{equation}\label{equ:Siegel-Walfisz_8}
          \sum_{|\g| \le 1}\frac{1}{\rho} \ll \log^{2}(m).
        \end{equation}
        Combining \cref{equ:Siegel-Walfisz_5,equ:Siegel-Walfisz_6,equ:Siegel-Walfisz_7,equ:Siegel-Walfisz_8} yields
        \begin{equation}\label{equ:Siegel-Walfisz_9}
          \psum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll x\log^{2}(xm)e^{-c\frac{\log(x)}{\log(mT)}},
        \end{equation}
        where the $'$ in the sum indicates that we are excluding the terms corresponding to real zeros and the error in \cref{equ:Siegel-Walfisz_8} has been absorbed by that in \cref{equ:Siegel-Walfisz_7}. As $\psi(x,\chi) \sim \psi_{0}(x,\chi)$ and $x$ is an integer, inserting \cref{equ:Siegel-Walfisz_9} into \cref{cor:explicit_formula_Dirichlet_corollary} results in
        \begin{equation}\label{equ:Siegel-Walfisz_10}
          \psi(x,\chi)+\frac{x^{\b_{1}}}{\b_{1}} \ll x\log^{2}(xm)e^{-c\frac{\log(x)}{\log(mT)}}+\frac{x\log^{2}(xmT)}{T}+x^{1-\b_{1}}\log(x),
        \end{equation}
        where the terms corresponding to real zeros are present if and only if $L(s,\chi)$ admits a Siegel zero. We now let $T$ be determined by $T = x$ for $2 \le x < 3$ and
        \[
          \log^{2}(T) = \log(x),
        \]
        or equivalently,
        \[
          T = e^{\sqrt{\log(x)}},
        \]
        for $x \ge 3$. With this choice of $T$ (note that if $x \ge 2$ then $2 \le T \le x$) and that $m \ll \log^{N}(x)$, we can estimate \cref{equ:Siegel-Walfisz_10} as follows:
        \begin{align*}
          \psi(x)+\frac{x^{\b_{1}}}{x} &\ll x(\log^{2}(x)+\log^{2}(m))e^{-c\frac{\log(x)}{\log(m)+\sqrt{\log(x)}}}+x(\log^{2}(x)+\log^{2}(m)+\log(x))e^{-\sqrt{\log(x)}}+x^{1-\b_{1}}\log(x) \\
          &\ll x(\log^{2}(x)+\log^{2}(m))e^{-c\frac{\log(x)}{\log(m)+\sqrt{\log(x)}}}+x(\log^{2}(x)+\log^{2}(m)+\log(x))e^{-\sqrt{\log(x)}}+x^{1-\b_{1}}\log(x) \\
          &\ll x(\log^{2}(x)+\log^{2}(m))e^{-c\sqrt{\log(x)}}+x(\log^{2}(x)+\log^{2}(m))e^{-\sqrt{\log(x)}}+x^{1-\b_{1}}\log(x) \\
          &\ll x\log^{2}(x)e^{-c\sqrt{\log(x)}}+x\log^{2}(x)e^{-\sqrt{\log(x)}}+x^{1-\b_{1}}\log(x) \\
          &\ll x\log^{2}(x)e^{-\min(1,c)\frac{\sqrt{\log(x)}}{\log(m)}},
        \end{align*}
        where in the last estimate we have used that $x^{1-\b_{1}} \le x^{\frac{1}{2}}$ because $\b_{1} \ge \frac{1}{2}$. As $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$, we conclude that
        \[
          \psi(x)+\frac{x^{\b_{1}}}{x} \ll xe^{-c\sqrt{\log(x)}},
        \]
        for some smaller $c$ with $c < 1$. This is equivalent to \cref{equ:Siegel-Walfisz_5}. Substituting \cref{equ:Siegel-Walfisz_5} into \cref{equ:Siegel-Walfisz_4} and noting that there is at most one Siegel zero for characters modulo $m$ by \cref{prop:at_most_one_Siegel_zero_per_modulus}, we arrive at
        \begin{equation}\label{equ:Siegel-Walfisz_11}
          \psi(x;a,m) = \frac{x}{\vphi(m)}-\frac{\cchi_{1}(a)x^{\b_{1}}}{\vphi(m)\b_{1}}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        where $\chi_{1}$ is the single quadratic character modulo $m$ such that $L(s,\chi_{1})$ admits a Siegel zero if it exists and we have absorbed the second term in the error in \cref{equ:Siegel-Walfisz_4} into the first since $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$ and $m \ll \log^{N}(x)$. Taking $\e = \frac{1}{2N}$ in the zero-free region version of Siegel's theorem, $m^\frac{1}{2N} \ll \sqrt{\log(x)}$ so that $\b_{1} < 1-\frac{c}{\sqrt{\log(x)}}$ for some potentially smaller constant $c$. It follows that $m^{2N}$ Therefore
        \begin{equation}\label{equ:Siegel-Walfisz_12}
          x^{\b_{1}} < x^{1-\frac{c}{\sqrt{\log(x)}}} = xe^{-c\log(x)}.
        \end{equation}
        Combining \cref{equ:Siegel-Walfisz_11,equ:Siegel-Walfisz_12} gives the simplified estimate
        \begin{equation}\label{equ:Siegel-Walfisz_13}
          \psi(x;a,m) = \frac{x}{\vphi(m)}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        for some potentially smaller constant $c$. Now let
        \[
          \pi_{1}(x;a,m) = \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\frac{\L(n)}{\log(n)}.
        \]
        We can write $\pi_{1}(x;a,m)$ in terms of $\psi(x;a,m)$ as follows:
        \begin{align*}
          \pi_{1}(x;a,m) &= \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\frac{\L(n)}{\log(n)} \\
          &= \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n)\int_{n}^{x}\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n) \\
          &= \int_{2}^{x}\sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n)\frac{dt}{t\log^{2}(t)}+\frac{1}{\log(x)}\sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\L(n) \\
          &= \int_{2}^{x}\frac{\psi(t;a,m)}{t\log^{2}(t)}\,dt+\frac{\psi(x;a,m)}{\log(x)}.
        \end{align*}
        Applying \cref{equ:Siegel-Walfisz_13} to the last expression yields
        \begin{equation}\label{equ:Siegel-Walfisz_14}
          \pi_{1}(x;a,m) = \int_{2}^{x}\frac{t}{\vphi(m)t\log^{2}(t)}\,dt+\frac{x}{\vphi(m)\log(x)}+O\left(\int_{2}^{x}\frac{e^{-c\sqrt{\log(t)}}}{\log^{2}(t)}\,dt+\frac{xe^{-c\sqrt{\log(x)}}}{\log(x)}\right),
        \end{equation}
        Applying integrating by parts to the main term in \cref{equ:Siegel-Walfisz_14}, we obtain
        \begin{equation}\label{equ:Siegel-Walfisz_15}
          \int_{2}^{x}\frac{t}{\vphi(m)t\log^{2}(t)}\,dt+\frac{x}{\vphi(m)\log(x)} = \int_{2}^{x}\frac{dt}{\vphi(m)\log(t)}+\frac{2}{\vphi(m)\log(2)} = \frac{\Li(x)}{\vphi(m)}+\frac{2}{\vphi(m)\log(2)}.
        \end{equation}
        As for the error term in \cref{equ:Siegel-Walfisz_14}, we use \cref{equ:prime_number_theorem_zeta_8}. Combining \cref{equ:prime_number_theorem_zeta_8,equ:Siegel-Walfisz_14,equ:Siegel-Walfisz_15} yields
        \begin{equation}\label{equ:Siegel-Walfisz_16}
          \pi_{1}(x;a,m) = \frac{\Li(x)}{\vphi(m)}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \end{equation}
        for some smaller $c$ and where the constant in \cref{equ:Siegel-Walfisz_15} has been absorbed into the error term. As last we pass from $\pi_{1}(x;a,m)$ to $\pi(x;a,m)$. If $p$ is a prime such that $p^{m} < x$ for some $m \ge 1$, then $p < x^{\frac{1}{2}} < x^{\frac{1}{3}} < \cdots < x^{\frac{1}{m}}$. Therefore
        \begin{equation}\label{equ:Siegel-Walfisz_17}
          \pi_{1}(x;a,m) = \sum_{\substack{n \le x \\ n \equiv a \tmod{m}}}\frac{\L(n)}{\log(n)} = \sum_{\substack{p^{m} \le x \\ p^{m} \equiv a \tmod{m}}}\frac{\log(p)}{m\log(p)} = \pi(x;a,m)+\frac{1}{2}\pi(x^{\frac{1}{2}};a,m)+\cdots.
        \end{equation}
        Moreover, as $\pi(x^{\frac{1}{n}};a,m) < x^{\frac{1}{n}}$ for any $n \ge 1$, we see that $\pi(x;a,m)-\pi_{1}(x;a,m) = O(x^{\frac{1}{2}})$. This estimate together with \cref{equ:Siegel-Walfisz_16,equ:Siegel-Walfisz_17} gives
        \[
          \pi(x) = \frac{\Li(x)}{\vphi(m)}+O\left(xe^{-c\sqrt{\log(x)}}\right),
        \]
        because $x^{\frac{1}{2}} \ll xe^{-c\sqrt{\log(x)}}$. This completes the proof.
      \end{proof}

      It is interesting to note that the constant $c$ in the Siegel-Walfisz theorem is ineffective because of the use of Siegel's theorem (it also depends upon $N$). This is unlike the prime number theorem, where the constant $c$ is effective. The proof of the logarithmic integral and classical versions of the Siegel-Walfisz theorem are immediate:

      \begin{proof}[Proof of Siegel-Walfisz theorem, logarithmic integral and classical versions]
        By the absolute error version of the Siegel-Walfisz theorem,
        \[
          \pi(x;a,m) = \frac{\Li(x)}{\vphi(m)}\left(1+O\left(\frac{\vphi(m)xe^{-c\sqrt{\log(x)}}}{\Li(x)}\right)\right).
        \]
        As $\Li(x) \sim \frac{x}{\log(x)}$, we have
        \[
          \frac{\vphi(m)xe^{-c\sqrt{\log(x)}}}{\Li(x)} \sim \vphi(m)\log(x)e^{-c\sqrt{\log(x)}} = o(1),
        \]
        where the equality holds since $m \ll \log^{N}(x)$ and $\log(x) \ll_{\e} e^{-\e\sqrt{\log(x)}}$. The logarithm integral version follows. The classical version also holds using the asymptotic $\Li(x) \sim \frac{x}{\log(x)}$.
      \end{proof}
      
      
      
       Also, we have an optimal error term, in a much wider range of $m$, assuming the Riemann hypothesis for Dirichlet $L$-functions:
      
      \begin{proposition}
        Let $a$ and $m$ be positive integers with $m > 1$, $(a,m) = 1$, and let $N \ge 1$. For $x \ge 2$, under the Riemann hypothesis for Dirichlet $L$-functions
        \[
          \pi(x;a,m) = \frac{\Li(x)}{\vphi(m)}+O(\sqrt{x}\log(x)).
        \]
        provided $m \le x$.
      \end{proposition}
      \begin{proof}
        Let $\chi$ be a Dirichlet character modulo $m$. If $\rho$ is a nontrivial zero of $L(s,\chi)$, the Riemann hypothesis for Dirichlet $L$-functions implies $|x^{\rho}| = \sqrt{x}$ and that Siegel zeros do not exist so we may merely assume $m \le x$. Therefore as in the proof of the absolute error version of the Siegel-Walfisz theorem,
        \[
          \sum_{|\g| < T}\frac{x^{\rho}}{\rho} \ll \sqrt{x}\log^{2}(x),
        \]
        for $2 \le T \le x$ not coinciding with the ordinate of a nontrivial zero. Repeating the same argument with $T$ determined by $T = x$ for $2 \le x < 3$ and 
        \[
          T^{2} = x,
        \]
        for $x \ge 3$ gives
        \[
          \psi(x;a,m) = \frac{x}{\vphi(m)}+O(\sqrt{x}\log^{2}(x)),
        \]
        and then transferring to $\pi_{1}(x)$ and finally $\pi(x)$ gives
        \[
          \pi(x;a,m) = \frac{x}{\vphi(m)}+O(\sqrt{x}\log(x)).
        \]
      \end{proof}