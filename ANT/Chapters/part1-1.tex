  \chapter{Preliminaries}\label{ch:Preliminaries}
    There is quite a bit of knowledge that most authors assume one is fluent in when writing any text on analytic number theory that is not necessarily standard material every reader knowns. A good selection is the following:
    \begin{itemize}
      \item Asymptotic Notation,
      \item Dirichlet Characters,
      \item Special Sums,
      \item Integral Methods \& Transforms,
      \item The Gamma Function.
    \end{itemize}
    This is not an extensive list (depending on whom is writing), but it is a decent one for sure. In the interest of keeping this text mostly self-contained, this chapter is dedicated to the basics of these topics as they are the gadgets that will take center stage in our later investigations. A well-versed reader is encouraged to skim these sections for completeness. On the other hand, readers who are not completely comfortable these topics are encouraged to read this chapter in full and accept the material mentioned without proof as black box. The mathematics presented in this chapter belongs to an analytic number theorist's tool box rather than being pure analytic number theory. In order to improve the readability of the remainder of the text we will use the results presented here without reference unless it is a matter of clarity. As for standard knowledge, we assume familiarity with basic number theory, complex analysis, real analysis, functional analysis, topology, and algebra. We have also outsourced specific subtopics to the appendix and we will reference them when necessary.
    \section{Notational Conventions}
      Here we make some notational conventions throughout the rest of the text unless specified otherwise:
      \begin{itemize}
        \item The symbol $\e$ denotes a small positive constant ($\e > 0$) that is not necessarily the same from line to line.
        \item If $a \in (\Z/m\Z)^{\ast}$, we will always let $\conj{a}$ denote the multiplicative inverse. That is, $a\conj{a} \equiv 1 \tmod{m}$.  
        \item For the complex variables $z$, $s$, and $u$, we write
        \[
          z = x+iy, \quad s = \s+it, \quad \text{and} \quad u = \tau+ir,
        \]
        for the real and imaginary parts of these variables respectively. In some cases we make exceptions and this will always be clear from context. Moreover, in certain expressions we often write $\Im(z)$ for clarity.
        \item If $r \in \Z$ denotes the order of a possible pole of a complex function, $r \ge 0$ if it is a pole and $r \le 0$ if it is a zero.
        \item The nontrivial zeros of an $L$-function will be denoted by $\rho = \b+i\g$ unless specified otherwise.
        \item By $\log$ we will always mean the principal branch of the logarithm.
        \item For a sum $\sum$ over integers satisfying a congruence condition, $\sum^{'}$ will denote the sum restricted to relatively prime integers satisfying the same congruence.
        \item We will write $\int_{(a)}$ for the complex integral over the line whose real part is $a$ and with positive orientation.
        \item $\d_{a,b}$ will denote the indicator function for $a = b$. That is, $\d_{a,b} = 1,0$ according to if $a = b$ or not.
      \end{itemize}
    \section{Asymptotic Notation}
      Much of the language of analytic number theory is given in asymptotic notation as it allows us to discuss approximate growth and dispense with superfluous constants. For this reason, asymptotic notation is the first material that we will present. The asymptotic notations that we will cover are listed in the following table:
      \begin{center}
        \begin{stabular}[1.5]{|c|c|c|}
          \hline
          Estimate & Notation \\
          \hline
          Big O & $f(z) = O(g(z))$ \\
          \hline
          Vinogradov's symbol & $f(z) \ll g(z)$ \\
          \hline
          Order of magnitude symbol & $f(z) \asymp g(z)$ \\
          \hline
          Little o & $f(z) = o(g(z))$ \\
          \hline
          Asymptotic equivalence & $f(z) \sim g(z)$ \\
          \hline
          Omega symbol & $f(z) = \W(g(z))$ \\
          \hline
        \end{stabular}
      \end{center}
      Implicit in all of these estimates is some limiting process $z \to z_{0}$ where $z_{0}$ is some complex number or $\infty$ (and $\pm \infty$ for the real case respectively). If $z_{0}$ is finite, then it is understood that the estimate is assumed to hold for all $z$ such that $|z-z_{0}| < \d$ for some real $\d > 0$. If $z_{0}$ is infinite, then the estimate is assumed to hold for all sufficiently large values of $z$. That is, $|z| > z_{0}$ for some $z_{0}$ (and $z > z_{0}$ or $z < z_{0}$ in the real case for $\pm \infty$ respectively). If the limiting process is not explicitly mentioned, it is assumed to be as $z \to \infty$ (or as $+\infty$ or $-\infty$ for the real case depending upon the context and even then we may exclude the sign for brevity).

      \begin{remark}
        Suppose $f,g:\Z_{\ge 0} \to \C$. Extending $f(x)$ and $g(x)$ by making them piecewise linear so that they are piecewise continuous, we can consider estimates with $n$ in place of $z$. All of the following theory still holds. Moreover, if we further take $f(x)$ or $g(x)$ to be a constant function, the following theory will still hold.
      \end{remark}
      \subsection*{\texorpdfstring{$O$}{O}-estimates \& Symbols}
        We say $f(z)$ \textbf{is of order}\index{is of order} $g(z)$ or $f(z)$ is $O(g(z))$ as $z \to z_{0}$ and write $f(z) = O(g(z))$
        if there is some positive constant $c$ such that
        \[
          |f(z)| \le c|g(z)|,
        \]
        holds as $z \to z_{0}$. We call this a \textbf{$O$-estimate}\index{$O$-estimate}.
        
        \begin{remark}
          Many authors assume that $g(z)$ is a nonnegative function so that the absolute values on $g(z)$ can be dropped. As we require other forms of asymptotic notation that will be used more generally, we do not make this assumption since one could very well replace $O(g(z))$ with $O(|g(z)|)$. In practice this deviation causes no issue.
        \end{remark}
        
        As a symbol, let $O(g(z))$ stand for a function $f(z)$ that is $O(g(z))$. Then we may use the $O$-estimates in algebraic equations. Note that this extends the definition of the symbol because $f(z) = O(g(z))$ means $f(z)$ is $O(g(z))$. The $O$-estimate says that for $z$ close to $z_{0}$, the size of $f(z)$ grows like $g(z)$. The constant $c$ is not unique as any $c' > c$ also works. Any such constant is called the \textbf{implicit constant}\index{implicit constant} of the $O$-estimate. The implicit constant may depend on one or more parameters, $\e$, $\s$, etc. If we wish to make these dependences known, we use subscripts $O_{\e}$, $O_{\s}$, $O_{\e,\s}$, etc. If it is possible to choose the implicit constant independent of a certain parameter then we say that the estimate is \textbf{uniform}\index{uniform} with respect to that parameter. Moreover, we say that an implicit constant is \textbf{effective}\index{effective} if the constant is numerically computable and \textbf{ineffective}\index{ineffective} otherwise. Moreover, if we are interested in the dependence of the estimate on a certain parameter, say $p$, we will refer to the \textbf{$p$-aspect}\index{$p$-aspect} to mean the part of the estimate that is dependent upon $p$. Lastly, in algebraic equations involving $O$-estimates, it is often customary to refer to such an $O$-estimate as an \textbf{error term}\index{error term}. The symbol $\ll$ is known as \textbf{Vinogradov's symbol}\index{Vinogradov's symbol} and it is an alternative way to express $O$-estimates. We write $f(z) \ll g(z)$ as $z \to z_{0}$ if $f(z) = O(g(z))$ as $z \to z_{0}$. We also write $f(z) \gg g(z)$ as $z \to z_{0}$ to mean $g(z) \ll f(z)$ as $z \to z_{0}$. If there is a dependence of the implicit constant on parameters, we use subscripts to denote dependence on these parameters. If both $f(z) \ll g(z)$ and $g(z) \ll f(z)$ as $z \to z_{0}$, then we say $f(z)$ and $g(z)$ have the \textbf{same order of magnitude}\index{same order of magnitude} and write $f(z) \asymp g(z)$ as $z \to z_{0}$. This is different from the $O$-estimate in the respect that for $z$ close to $z_{0}$, $f(z)$ grows like $g(z)$ and conversely $g(z)$ grows like $f(z)$. In other words, $f(z)$ and $g(z)$ grow the same. If there is a dependence of the implicit constant on parameters, we use subscripts to denote dependence on these parameters. From the definition of the $O$-estimate, this is equivalent to the existence of positive constants $c_{1}$ and $c_{2}$ such that
        \[
          c_{1}|g(z)| \le |f(z)| \le c_{2}|g(z)|.
        \]
        Equivalently, we can interchange $f(z)$ and $g(z)$ in the above equation.
      \subsection*{\texorpdfstring{$o$}{o}-estimates \& Symbols}
        We say $f(z)$ \textbf{is of smaller order than}\index{is of smaller order than} $g(z)$ or $f(z)$ is $o(g(z))$ as $z \to z_{0}$ and write $f(z) = o(g(z))$ if
        \[
          \lim_{z \to z_{0}}\left|\frac{f(z)}{g(z)}\right| = 0,
        \]
        provided $g(z) \neq 0$ for all $z$ sufficiently close to $z_{0}$. We call this a \textbf{$o$-estimate}\index{$o$-estimate}. The $o$-estimate says that for $z$ close to $z_{0}$, $g(z)$ dominates $f(z)$. If $f(z) = o(g(z))$ as $z \to z_{0}$, then $f(z) = O(g(z))$ as $z \to z_{0}$ where the implicit constant can be taken arbitrarily small by definition of the $o$-estimate. Therefore, $o$-estimates are stronger than $O$-estimates. As a symbol, let $o(g(z))$ stand for a function $f(z)$ that is $o(g(z))$. Then we may use the $o$-estimates in algebraic equations. Note that this extends the definition of the symbol because $f(z) = o(g(z))$ means $f(z)$ is $o(g(z))$.

        We say $f(z)$ \textbf{is asymptotic to}\index{is asymptotic to} $g(z)$ or $f(z)$ and $g(z)$ are \textbf{asymptotically equivalent}\index{asymptotically equivalent} as $z \to z_{0}$ and write $f(z) \sim g(z)$ if
        \[
          \lim_{z \to z_{0}}\left|\frac{f(z)}{g(z)}\right| = 1,
        \]
        provided $g(z) \neq 0$ for all $z$ sufficiently close to $z_{0}$. It is useful to think of asymptotic equivalence as $f(z)$ and $g(z)$ being the same size in the limit as $z \to z_{0}$. Immediately from the definition, we see that this is an equivalence relation on functions. In particular, if $f(z) \sim g(z)$ and $g(z) \sim h(z)$ then $f(z) \sim h(z)$. Also, if $f(z) \sim g(z)$ as $z \to z_{0}$, then $f(z) \asymp g(z)$ as $z \to z_{0}$ with $c_{1} \le 1 \le c_{2}$. So asymptotic equivalence is stronger than being of the same order of magnitude. Also note that $f(x) \sim g(x)$ is equivalent to $f(x) = g(x)(1+o(1))$ and hence implies $f(x) = g(x)(1+O(1))$. We write $f(z) = \W(g(z))$ as $z \to z_{0}$ if
        \[
          \limsup_{z \to z_{0}}\left|\frac{f(z)}{g(z)}\right| > 0.
        \]
        This is precisely the negation of $f(z) = o(g(z))$, so that $f(z) = \W(g(z))$ means $f(z) = o(g(z))$ is false. In other words, for $z$ near $z_{0}$ the growth of $g(z)$ does not dominate the growth of $f(z)$. This is weaker than $f(z) \gg g(z)$ because $f(z) = \W(g(z))$ means $|f(z)| \ge c|g(z)|$ for values of $z$ arbitrarily close to $z_{0}$ whereas $f(z) \gg g(z)$ means $|f(z)| \ge c|g(z)|$ for all values of $z$ sufficiently close to $z_{0}$.
      \subsection*{Algebraic Manipulation for \texorpdfstring{$O$}{O}-estimates and \texorpdfstring{$o$}{o}-estimates}
        Asymptotic estimates become increasingly more useful when we can use them in equations to represent approximations. We catalogue some of the most useful algebraic manipulations for $O$-estimates and $o$-estimates. Most importantly, if an algebraic equation involves a $O$-estimate or $o$-estimate then it is understood that the equation is not symmetric and is interpreted to be read from left to right. That is, any function of the form satisfying the estimate on the left-hand side also satisfies the estimate on the right-hand side too. We begin with $O$-estimates. The trivial algebraic manipulations are collected in the proposition below:

        \begin{proposition}\label{prop:Big_Oh_manipulations}
            The following $O$-estimates hold as $z \to z_{0}$:
            \begin{enumerate}[label=(\roman*)]
              \item If $f(z) = O(g(z))$ and $g(z) = O(h(z))$, then $f(z) = O(h(z))$. Equivalently, $O(O(h(z))) = O(h(z))$.
              \item If $f_{i}(z) = O(g_{i}(z))$ for $i = 1,2$, then $f_{1}(z)f_{2}(z) = O(g_{1}(z)g_{2}(z))$.
              \item If $f(z) = O(g(z)h(z))$, then $f(z) = g(z)O(h(z))$.
              \item If $f_{i}(z) = O(g_{i}(z))$ for $i = 1,2,\ldots,n$, then $\sum_{1 \le i \le n}f_{i}(z) = O\left(\sum_{1 \le i \le n}|g_{i}(z)|\right)$.
              \item If $f_{n}(z) = O(g_{n}(z))$ for $n \ge 1$, then $\sum_{n \ge 1}f_{n}(z) = O\left(\sum_{n \ge 1}|g_{n}(z)|\right)$ provided both $\sum_{n \ge 1}f_{n}(z)$ and $\sum_{n \ge 1}|g_{n}(z)|$ converge.
              \item If $f(z) = O(g(z))$ as $z \to z_{0}$ and $h(z)$ is such that $h(z) \to z_{0}$ as $z \to z_{0}$, then $(f \circ h)(z) = O((g \circ h)(z))$.
              \item If $f(z) = O(g(z))$, then $\Re(f(z)) = O(g(z))$ and $\Im(f(z)) = O(g(z))$.
            \end{enumerate}
        \end{proposition}
        \begin{proof}
          Statements (i)-(iii) and (vi) follow immediately from the definition of the $O$-estimate. Statement (iv) follows from the definition and the triangle inequality. Statement (v) follows in the same way as (iv) given that both sums converge. Statement (vii) follows from the definition and the bounds $|x| \le |z|$ and $|\Im(z)| \le |z|$.
        \end{proof}

        We will also often use \cref{prop:Big_Oh_manipulations} (vi) in the case of the input for a function. The most common instances will be when $z \asymp w$ or $z \sim w$ (the latter case implying the former) where $w$ is a function of $z$ (usually one that is more simple than $z$ itself). Taking $h(z) = w$, \cref{prop:Big_Oh_manipulations} (vi) says that if $f(z) = O(g(z))$ then $f(w) = O(g(w))$. In terms of Vinogradov's symbol, $f(z) \ll g(z)$ implies $f(w) \ll g(w)$. $O$-estimates also behave well with respect to integrals provided the functions involved are of a real variable:

        \begin{proposition}
          Suppose $f(z)$ and $g(z)$ are functions of a real variable, $f(z) = O(g(z))$ as $z \to \infty$, $f(z)$ and $g(z)$ are integrable on the region where this estimate holds, and let $[z_{1},z_{2}]$ belong to this region. Then
          \[
            \int_{z_{1}}^{z_{2}}f(z)\,dz = O\left(\int_{z_{1}}^{z_{2}}|g(z)|\,dz\right).
          \]
        \end{proposition}
        \begin{proof}
          This follows immediately from the definition of the $O$-estimate.
        \end{proof}

        The next proposition is a collection of some useful expressions for simplifying equations involving $O$-estimates:

        \begin{proposition}
          Let $f(z)$ be a function such that $f(z) \to 0$ as $z \to 0$. The following $O$-estimates hold as $z \to 0$:
          \begin{enumerate}[label=(\roman*)]
            \item $\frac{1}{1+O(f(z))} = 1+O(f(z))$.
            \item $(1+O(f(z)))^{p} = 1+O(f(z))$ for any complex number $p$.
            \item $\log(1+O(f(z))) = O(f(z))$.
            \item $e^{1+O(f(z))} = 1+O(f(z))$.
          \end{enumerate}
        \end{proposition}
        \begin{proof}
          Taking the Taylor series truncated after the first term and applying Taylor's theorem, we have the $O$-estimates
          \begin{enumerate}[label=(\roman*)]
            \item $\frac{1}{1+z} = 1+O(z)$.
            \item $(1+z)^{p} = 1+O(z)$.
            \item $\log(1+z) = O(z)$.
            \item $e^{z} = 1+O(z)$.
          \end{enumerate}
          Now apply \cref{prop:Big_Oh_manipulations} (v) with $h(z) = O(f(z))$ to each of these estimates, and use \cref{prop:Big_Oh_manipulations} (i).
        \end{proof}

        For $o$-estimates, the following properties are useful:

        \begin{proposition}\label{prop:Little_Oh_manipulations}
            The following $o$-estimates hold as $z \to z_{0}$:
            \begin{enumerate}[label=(\roman*)]
              \item If $f(z) = o(g(z))$ and $g(z) = o(h(z))$, then $f(z) = o(h(z))$. Equivalently, $o(o(h(z))) = o(h(z))$.
              \item If $f_{i}(z) = o(g_{i}(z))$ for $i = 1,2$, then $f_{1}(z)f_{2}(z) = o(g_{1}(z)g_{2}(z))$.
              \item If $f(z) = o(g(z)h(z))$, then $f(z) = g(z)o(h(z))$.
              \item If $f_{i}(z) = o(g_{i}(z))$ for $i = 1,2,\ldots,n$, then $\sum_{1 \le i \le n}f_{i}(z) = o\left(\sum_{1 \le i \le n}|g_{i}(z)|\right)$.
              \item If $f(z) = o(g(z))$ as $z \to z_{0}$ and $h(z)$ is such that $h(z) \to z_{0}$ as $z \to z_{0}$, then $(f \circ h)(z) = o((g \circ h)(z))$.
            \end{enumerate}
        \end{proposition}
        \begin{proof}
          Statements (i)-(iii) and (v) follow immediately from the definition of the $o$-estimate and basic properties of limits. Statement (iv) follows from the definition and that $\sum_{1 \le i \le n}|g_{i}(z)| \ge |g_{i}(z)|$ for any $1 \le i \le n$.
        \end{proof}
      \subsection*{Growth of Functions}
        We will also be interested in the growth rate of functions. We can compactly express these types of growth using asymptotic notation. There are many types of growth rates, but we will only recall the ones that will be of use to us. Let $f(z)$ be a complex function and let $z \to z_{0}$. If $f(z) = O(\log^{n}(z))$, for some $n \ge 1$, we say that $f(z)$ is of \textbf{logarithmic growth}\index{logarithmic growth}. If $f(z) = O(z^{c})$, for some $c \in \R$, we say that $f(z)$ is of \textbf{polynomial growth}\index{polynomial growth}. If $f(z) = o(e^{z})$, we say that $f(z)$ is of \textbf{moderate growth}\index{moderate growth}. If $f(z) = O(e^{z})$, we say that $f(z)$ is of \textbf{exponential growth}\index{exponential growth}. Now suppose $z \to \infty$. If $f(z) = o(\log^{-n}(z))$, for some $n \ge 1$, we say that $f(z)$ is of \textbf{logarithmic decay}\index{logarithmic decay}. If $f(z) = o(x^{-c})$ for some $c \ge 1$, we say that $f(z)$ has \textbf{polynomial decay}\index{polynomial decay}. If $f(z) = o(x^{-c})$ for all $c \ge 1$, we say that $f(z)$ has \textbf{moderate decay}\index{moderate decay}. If $f(z) = o(e^{-z})$, we say that $f(z)$ has \textbf{exponential decay}\index{exponential decay}.
    \section{Dirichlet Characters}
      The most important multiplicative periodic functions for an analytic number theorist are the Dirichlet characters. A \textbf{Dirichlet character}\index{Dirichlet character} $\chi$ modulo $m \ge 1$ (or of modulus $m \ge 1$) is an $m$-periodic completely multiplicative function $\chi:\Z \to \C$ such that $\chi(a) = 0$ if and only if $(a,m) > 1$. Sometimes we will also write $\chi_{m}$ to denote a Dirichlet character modulo $m$ if we need to express the dependence upon the modulus. For any $m$, there is always the \textbf{principal Dirichlet character}\index{principal Dirichlet character} modulo $m$ which we denote by $\chi_{m,0}$ (sometimes also seen as $\chi_{0,m}$ or the ever more confusing $\chi_{0}$) and is defined by
      \[
        \chi_{m,0}(a) = \begin{cases} 1 & (a,m) = 1, \\ 0 & (a,m) > 1. \end{cases}
      \]
      When $m = 1$, the principal Dirichlet character is identically $1$ and we call this the \textbf{trivial Dirichlet character}\index{trivial Dirichlet character}. This is also the only Dirichlet character modulo $1$, so $\chi_{1} = \chi_{1,0}$. In general, we say a Dirichlet character $\chi$ is \textbf{principal}\index{principal} if it only takes values $0$ or $1$. We now discuss some basic facts of Dirichlet characters. Since $a^{\vphi(m)} \equiv 1 \tmod{m}$ by Euler's little theorem, where $\vphi$ is Euler's totient function, the multiplicativity of $\chi$ implies $\chi(a)^{\vphi(m)} = 1$. Therefore the nonzero values of $\chi_{m}$ are $\vphi(m)$-th roots of unity. In particular, there are only finitely many Dirichlet characters of any fixed modulus $m$. Given two Dirichlet character $\chi$ and $\psi$ modulo $m$, we define $\chi\psi$ by $\chi\psi(a) = \chi(a)\psi(a)$. This is also a Dirichlet character modulo $m$, so the Dirichlet characters modulo $m$ form an abelian group denoted by $X_{m}$. If we have a Dirichlet character $\chi$ modulo $m$, then $\cchi$ defined by $\cchi(a) = \conj{\chi(a)}$ is also a Dirichlet character modulo $m$ and is called the \textbf{conjugate Dirichlet character}\index{conjugate Dirichlet character} of $\chi$. Since the nonzero values of $\chi$ are roots of unity, if $(a,m) = 1$ then $\cchi(a) = \chi(a)^{-1}$. So $\cchi$ is the inverse of $\chi$. This is all strikingly similar to characters on $(\Z/m\Z)^{\ast}$ (see \cref{append:Character_Groups}), and there is a connection. To see it, by the periodicity of $\chi$, it's nonzero values are uniquely determined by $(\Z/m\Z)^{\ast}$. Then since $\chi$ is multiplicative, it descends to a character $\chi$ of $(\Z/m\Z)^{\ast}$ (we abuse notation here). Conversely, if we are given a character $\chi$ of $(\Z/m\Z)^{\ast}$ we can extend it to a Dirichlet character by defining it to be $m$-periodic and declaring $\chi(a) = 0$ if $(a,m) > 1$. We call this extension the \textbf{zero extension}\index{zero extension}. So in other words, Dirichlet characters modulo $m$ are the zero extensions of group characters on $(\Z/m\Z)^{\ast}$. Clearly zero-extension respects multiplication of characters. As groups are isomorphic to their character groups (see \cref{prop:character_group_isomorphim}), we deduce that the group of Dirichlet characters modulo $m$ is isomorphic to $(\Z/m\Z)^{\ast}$. That is, $X_{m} \cong \what{(\Z/m\Z)^{\ast}} \cong (\Z/m\Z)^{\ast}$. In particular, there are $\vphi(m)$ Dirichlet characters modulo $m$. From now on we identify Dirichlet characters modulo $m$ with their corresponding group characters of $(\Z/m\Z)^{\ast}$. We now state two very useful relations called \textbf{orthogonality relations}\index{orthogonality relations} for Dirichlet characters (this follows from the more general orthogonality relations in \cref{append:Character_Groups} but we wish to give a direct proof):

      \begin{proposition}\label{prop:Dirichlet_orthogonality_relations}
      \phantom{ }
        \begin{enumerate}[label=(\roman*)]
          \item For any two Dirichlet characters $\chi$ and $\psi$ modulo $m$,
          \[
            \frac{1}{\vphi(m)}\psum_{a \tmod{m}}\chi(a)\conj{\psi}(a) = \d_{\chi,\psi}.
          \]
          \item For any $a,b \in (\Z/m\Z)^{\ast}$,
          \[
            \frac{1}{\vphi(m)}\sum_{\chi \tmod{m}}\chi(a)\cchi(b) = \d_{a,b}.
          \]
        \end{enumerate}
      \end{proposition}
      \begin{proof}
        We will prove the statements separately.
        \begin{enumerate}[label=(\roman*)]
          \item Denote the left-hand side by $S$ and let $b$ be such that $(b,m) = 1$. Then $a \to ab^{-1}$ is a bijection on $(\Z/m\Z)^{\ast}$ so that
          \[
            \frac{\chi(b)\conj{\psi}(b)}{\vphi(m)}\psum_{a \tmod{m}}\chi(a)\conj{\psi}(a) = \frac{1}{\vphi(m)}\psum_{a \tmod{m}}\chi(ab)\conj{\psi}(ab) = \frac{1}{\vphi(m)}\psum_{a \tmod{m}}\chi(a)\conj{\psi}(a).
          \]
          Consequently $\chi(b)\conj{\psi}(b)S = S$ so that $S = 0$ unless $\chi(b)\conj{\psi}(b) = 1$ for all $b$ such that $(b,m) = 1$. This happens if and only if $\psi = \chi$ in which case $S = 1$. This proves (i).
          \item Denote the left-hand side by $S$. Let $\psi$ be any Dirichlet character modulo $m$. As $\chi \to \chi\conj{\psi}$ is a bijection on $X_{m}$, we have
          \[
            \frac{\psi(a)\conj{\psi}(b)}{\vphi(m)}\sum_{\chi \tmod{m}}\chi(a)\cchi(b) = \frac{1}{\vphi(m)}\sum_{\chi \tmod{m}}\psi\chi(a)\conj{\psi\chi}(b) = \frac{1}{\vphi(m)}\sum_{\chi \tmod{m}}\chi(a)\cchi(b).
          \]
          Therefore $\psi(a)\conj{\psi}(b)S = S$ so that $S = 0$ unless $\psi(a)\conj{\psi}(b) = \psi(a\conj{b}) = 1$ for all Dirichlet characters $\psi$ modulo $m$. If this happens, then $a\conj{b} = 1 \tmod{m}$, or equivalently, $a \equiv b \tmod{m}$. Indeed, let $m = p_{1}^{r_{1}}p_{2}^{r_{2}} \cdots p_{k}^{r_{k}}$ be the prime factorization of $m$. By the classification theorem for finite abelian groups,
          \[
            (\Z/m\Z)^{\ast} \cong (\Z/p_{1}^{r_{1}}\Z)^{\ast} \x (\Z/p_{2}^{r_{2}}\Z)^{\ast} \x \cdots \x (\Z/p_{k}^{r_{k}}\Z)^{\ast}.
          \]
          Now let $n_{i}$ be a generator for the cyclic group $(\Z/p_{i}^{r_{i}}\Z)^{\ast}$ and let $\w_{i}$ be a primitive $p_{i}^{k_{i}}$-th root of unity for $1 \le i \le k$. Writing $a\conj{b} = n_{1}^{f_{1}}n_{2}^{f_{2}} \cdots n_{k}^{f_{k}}$, consider the Dirichlet character $\psi$ modulo $m$ defined by
          \[
            \psi(n_{1}^{e_{1}}n_{2}^{e_{2}} \cdots n_{k}^{e_{k}}) = \w_{1}^{e_{1}f_{1}}\w_{2}^{e_{2}f_{2}} \cdots \w_{r}^{e_{r}f_{r}}.
          \]
          We have
          \[
            \psi(1) = \w_{1}^{f_{1}}\w_{2}^{f_{2}} \cdots \w_{r}^{f_{r}}.
          \]
          As $w_{i}$ has order $p_{i}^{k_{i}}$ and $0 \le f_{i} < p_{i}^{k_{i}}-1$ for all $i$, the only way $\psi(1) = 1$ is if $f_{i} = 0$ for all $i$. Therefore $a\conj{b} = 1 \tmod{m}$. In this case $S = 1$. This proves (ii).
        \end{enumerate}
      \end{proof}

      In many practical settings, the orthogonality relations are often used in the following form:

      \begin{corollary}\label{cor:Dirichlet_orthogonality_relations}
      \phantom{ }
        \begin{enumerate}[label=(\roman*)]
          \item For any Dirichlet character $\chi$ modulo $m$,
          \[
            \frac{1}{\vphi(m)}\psum_{a \tmod{m}}\chi(a) = \d_{\chi,\chi_{m,0}}.
          \]
          \item For any $a \in (\Z/m\Z)^{\ast}$,
          \[
            \frac{1}{\vphi(m)}\sum_{\chi \tmod{m}}\chi(a) = \d_{a,1}.
          \]
        \end{enumerate}
      \end{corollary}
      \begin{proof}
        For (i), take $\psi = \chi_{m,0}$ in \cref{prop:Dirichlet_orthogonality_relations} (i). For (ii), take $b \equiv 1 \tmod{m}$ in \cref{prop:Dirichlet_orthogonality_relations} (ii).
      \end{proof}

      Now that we understand the basics of Dirichlet characters, we might be interested in computing them. This is not hard to do by hand for small $m$. For example, the table below gives the Dirichlet characters modulo $5$ where $i$ in $\chi_{5,i}$ is an indexing variable:

      \begin{center}
        \begin{stabular}[1.5]{|c|c|c|c|c|c|}
          \hline
          & $0$ & $1$ & $2$ & $3$ & $4$ \\
          \hline
          $\chi_{5,0}$ & $0$ & $1$ & $1$ & $1$ & $1$ \\
          \hline
          $\chi_{5,1}$ & $0$ & $1$ & $i$ & $-i$ & $-1$ \\
          \hline
          $\chi_{5,2}$ & $0$ & $1$ & $-i$ & $i$ & $-1$ \\
          \hline
          $\chi_{5,3}$ & $0$ & $1$ & $-1$ & $-1$ & $1$ \\
          \hline
        \end{stabular}
      \end{center}

      If the modulus is large this is of course more difficult. However, there is a way to build Dirichlet characters modulo $m_{2}$ from those modulo $m_{1}$. Let $\chi_{m_{1}}$ be a Dirichlet character modulo $m_{1}$. If $m_{1} \mid m_{2}$ then $(a,m_{2}) = 1$ implies $(a,m_{1}) = 1$. Therefore we can define a Dirichlet character $\chi_{m_{2}}$ by
      \[
        \chi_{m_{2}}(a) = \begin{cases} \chi_{m_{1}}(a) & \text{if $(a,m_{2}) = 1$}, \\ 0 & \text{if $(a,m_{2}) > 1$}. \end{cases}
      \]
      In this case, we say $\chi_{m_{2}}$ is \textbf{induced}\index{induced} from $\chi_{m_{1}}$ or that $\chi_{m_{1}}$ \textbf{lifts} to $\chi_{m_{2}}$. All that is happening is $\chi_{m_{2}}$ is a Dirichlet character modulo $m_{2}$ whose values are given by those that $\chi_{m_{1}}$ takes. Clearly every Dirichlet character is induced from itself. On the other hand, provided there is a prime $p$ dividing $m_{2}$ and not $m_{1}$ (so $m_{2}$ is a larger modulus), $\chi_{m_{2}}$ will be different from $\chi_{m_{1}}$. For instance, $\chi_{m_{2}}(p) = 0$ but $\chi_{m_{1}}(p) \neq 0$. In general, we say a Dirichlet character is \textbf{primitive}\index{primitive} if it is not induced by any character other than itself. Notice that the principal Dirichlet characters are precisely those Dirichlet characters induced from the trivial Dirichlet character, and the only primitive one is the trivial Dirichlet character. In any case, we can determine when Dirichlet characters are induced:

      \begin{proposition}\label{prop:Dirichlet_character_induction_classification}
        A Dirichlet character $\chi_{m_{2}}$ is induced from a Dirichlet character $\chi_{m_{1}}$ if and only if $\chi_{m_{2}}$ is constant on the residue classes in $(\Z/m_{2}\Z)^{\ast}$ that are congruent modulo $m_{1}$. When this happens, $\chi_{m_{1}}$ is uniquely determined.
      \end{proposition}
      \begin{proof}
        For the forward implication, if $\chi_{m_{2}}$ is induced from $\chi_{m_{1}}$, then $\chi_{m_{2}}$ is constant on the residue classes in $(\Z/m_{2}\Z)^{\ast}$ that are congruent modulo $m_{1}$ because $\chi_{m_{1}}$ is. For the reverse implication, we first show that the reduction modulo $m_{1}$ map $\Z/m_{2}\Z \to \Z/m_{1}\Z$ induces a surjective homomorphism $\Phi:(\Z/m_{2}\Z)^{\ast} \to (\Z/m_{1}\Z)^{\ast}$. For $u_{1} \in (\Z/m_{1}\Z)^{\ast}$, let $a$ be the product of all primes dividing $\frac{m_{2}}{m_{1}}$ but not $u_{1}$. Then $u_{2} = u_{1}+m_{1}a$ is not divisible by any prime $p$ dividing $m_{1}$ or $\frac{m_{2}}{m_{1}}$. Hence $(u_{2},m_{2}) = 1$ so that $u_{2} \in (\Z/m_{2}\Z)^{\ast}$. Note that $a$ is uniquely determined by $u_{1}$ so that $u_{2}$ is uniquely determined and hence $\Phi$ is unique. It's also a homomorphism because reduction modulo $m_{1}$ is. Now suppose $\chi_{m_{2}}$ is constant on the residue classes in $(\Z/m_{2}\Z)^{\ast}$ that are congruent modulo $m_{1}$. Surjectivity of $\Phi$ implies $\chi_{m_{2}}$ induces a unique group character on $(\Z/m_{1}\Z)^{\ast}$ and hence a unique Dirichlet character modulo $m_{1}$. By construction $\chi_{m_{2}}$ is induced from $\chi_{m_{1}}$.
      \end{proof}

      Why might we be interested in primitive Dirichlet characters? The reason is that the primitive Dirichlet character are the building blocks for all Dirichlet characters:

      \begin{theorem}\label{thm:Dirichlet_character_conductor_existance}
        Every Dirichlet character $\chi$ is induced from a primitive Dirichlet character $\wtilde{\chi}$ that is uniquely determined by $\chi$.
      \end{theorem}
      \begin{proof}
        Let the modulus of $\chi$ be $m$. Define a partial ordering on the set of Dirichlet characters where $\psi \le \chi$ if $\chi$ is induced from $\psi$. This ordering is clearly reflexive, and it is transitive by \cref{prop:Dirichlet_character_induction_classification}. Set $X = \{\psi:\psi \le \chi\}$. This set is nonempty, and is finite by \cref{prop:Dirichlet_character_induction_classification}. Now suppose $\chi_{m_{1}},\chi_{m_{2}} \in X$. Setting $m_{3} = (m_{1},m_{2})$, and we have a commuting square
        \begin{center}
          \begin{tikzcd}
            \arrow{d}[swap]{\Phi} (\Z/m\Z)^{\ast} \arrow{r}{\Phi} & (\Z/m_{1}\Z)^{\ast} \arrow{d} \\
            (\Z/m_{2}\Z)^{\ast} \arrow{r} & (\Z/m_{3}\Z)^{\ast}
          \end{tikzcd}
        \end{center}
        where $\Phi$ is as in \cref{prop:Dirichlet_character_induction_classification}. Also from \cref{prop:Dirichlet_character_induction_classification}, $\chi$ is constant on the residue classes of $(\Z/m\Z)^{\ast}$ that are congruent modulo $m_{1}$ or $m_{2}$ and hence also $m_{3}$. Therefore \cref{prop:Dirichlet_character_induction_classification} implies there is a unique Dirichlet character $\chi_{m_{3}}$ modulo $m_{3}$ that lifts to $\chi_{m_{1}}$ and $\chi_{m_{2}}$. We have now shown that every pair $\chi_{m_{1}},\chi_{m_{2}} \in X$ has a lower bound $\chi_{m_{3}}$. Hence $X$ contains a primitive Dirichlet character $\wtilde{\chi}$ that is minimal with respect to this partial ordering. There is only one such element. Indeed, since $m_{3} \le m_{1},m_{2}$ the partial ordering is compatible with the total ordering by period. Thus $\wtilde{\chi}$ is unique.
      \end{proof}

      In light of \cref{thm:Dirichlet_character_conductor_existance}, we define \textbf{conductor}\index{conductor} $q$ of a Dirichlet character $\chi$ modulo $m$ to be the period of the unique primitive character $\wtilde{\chi}$ that induces $\chi$. This is the most important data of a Dirichlet character since it tells us how $\chi$ is built. Note that $\chi$ is primitive if and only if its conductor and modulus are equal. Also observe that if $\chi$ has conductor $q$, then $\chi$ is $q$-periodic (necessarily $q \mid m$), and the nonzero values of $\chi$ are all $q$-th roots of unity because those are the nonzero values of $\wtilde{\chi}$. Moreover, $\chi = \wtilde{\chi}\chi_{\frac{m}{q},0}$ by the definition of induced Dirichlet characters. We would also like to distinguish Dirichlet characters whose nonzero values are real or imaginary. We say $\chi$ is \textbf{real}\index{real} if it is real-valued. Hence the nonzero values of $\chi$ are $1$ or $-1$ since they must be roots of unity. We say $\chi$ is an \textbf{complex}\index{complex} if it is not real. More commonly, we distinguish Dirichlet characters modulo $m$ by their order as an element of $(\Z/m\Z)^{\ast}$. If $\chi$ is of order $2$, $3$, etc in $(\Z/m\Z)^{\ast}$ then we say it is \textbf{quadratic}\index{quadratic}, \textbf{cubic}\index{cubic}, etc. In particular, a Dirichlet character is quadratic if and only if it is real. For example, if $m$ is odd then the Jacobi symbol $\tlegendre{\cdot}{m}$ is a quadratic Dirichlet character. We will often let $\chi_{m}$ denote this quadratic Dirichlet character but we will always mention this explicitly when we do so. For any Dirichlet character $\chi$, $\chi(-1) = \pm 1$ because $\chi(-1)^{2} = 1$. We would like to distinguish this parity. Accordingly, we say $\chi$ is \textbf{even}\index{even} if $\chi(-1) = 1$ and \textbf{odd}\index{odd} if $\chi(-1) = -1$. Clearly even Dirichlet characters are even functions and odd Dirichlet characters are odd functions. Moreover, $\chi$ and $\cchi$ have the same parity and any lift of $\chi$ has the same parity as $\chi$.
    \section{Special Sums}
      Analytic number theory does not come without its class of special sums that appear naturally. They play the role of discrete counterparts to continuous objects (there is a rich underpinning here). Without a sufficient understanding of these sums, they would cause a discrete obstruction to an analytic problem that we wish to solve.
      \subsection*{Ramanujan Sums}
        Let's begin with the Ramanujan sum. For a positive integer $m$ and any integer $b$, the \textbf{Ramanujan sum}\index{Ramanujan sum} $r(b;m)$ is defined by
        \[
          r(b;m) = \psum_{a \tmod{m}}e^{\frac{2\pi iab}{m}}.
        \]
        Note that the Ramanujan sum is a finite sum of $m$-th roots of unity on the unit circle. Clearly $r(0;m) = \vphi(m)$. Ramanujan sums can be computed explicitly by means of the M\"obius function (see \cref{append:Arithmetic_Functions}):

        \begin{proposition}\label{prop:Ramanujan_sum_evaluation}
          For any positive integer $m$ and any nonzero $b \in \Z$,
          \[
            r(b;m) = \sum_{\ell \mid (b,m)}\ell\mu\left(\frac{m}{\ell}\right).
          \]
        \end{proposition}
        \begin{proof}
          This is a computation:
          \begin{align*}
            r(b;m) &= \psum_{a \tmod{m}}e^{\frac{2\pi iab}{m}} \\
            &= \sum_{a \tmod{m}}e^{\frac{2\pi iab}{m}}\sum_{d \mid (a,m)}\mu(d) && \text{\cref{prop:Mobius_dirac_delta}} \\
            &= \sum_{d \mid m}\mu(d)\sum_{\substack{a \tmod{m} \\ d \mid a}}e^{\frac{2\pi iab}{m}} \\
            &= \sum_{d \mid m}\mu(d)\sum_{kd \tmod{m}}e^{\frac{2\pi ikdb}{m}} && \text{$a \to kd$.} \\
            &= \sum_{d \mid m}\mu(d)\sum_{k \tmod{\frac{m}{d}}}e^{\frac{2\pi ik b}{\frac{m}{d}}}.
          \end{align*}
          Now if $\frac{m}{d} \mid b$ the inner sum is $\frac{m}{d}$, and otherwise it is zero because $k \to k\conj{b}$ is a bijection on $\Z/\frac{m}{d}\Z$ and thus we are summing over all $\left(\frac{m}{d}\right)$-th roots of unity. So the double sum above reduces to
          \[
            \sum_{\substack{\frac{m}{d} \mid b \\ d \mid m}}\frac{m}{d}\mu(d) = \sum_{\ell \mid (b,m)}\ell\mu\left(\frac{m}{\ell}\right),
          \]
          upon performing the change of variables $\frac{m}{d} \to \ell$.
        \end{proof}
      \subsection*{Gauss Sums}
        When we take a Ramanujan sum and introduce a Dirichlet character we get a Gauss sums. Let $\chi$ be a Dirichlet character modulo $m$. For any $b \in \Z$, the \textbf{Gauss sum}\index{Gauss sum} $\tau(b,\chi)$ attached to $\chi$ is given by
        \[
          \tau(b,\chi) = \sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi iab}{m}} = \psum_{a \tmod{m}}\chi(a)e^{\frac{2\pi iab}{m}},
        \]
        where the last equality follows because $\chi(a) = 0$ unless $(a,m) = 1$. If $b = 1$ we will write $\tau(\chi)$ instead. That is, $\tau(\chi) = \tau(1,\chi)$. Gauss sums are interesting because the Dirichlet character is a multiplicative character while the exponential is an additive one. So the Gauss sums is a convolution between a multiplicative and additive character. This is the fundamental reason that makes them difficult to study as one needs to separate the additive and multiplicative structures. Observe that if $m = 1$ then $\chi$ is the trivial character and $\tau(b,\chi) = 1$. So the interesting cases are when $m \ge 2$. There are some basic properties of Gauss sums that are very useful:

        \begin{proposition}\label{prop:Gauss_sum_reduction}
          Let $\chi$ and $\psi$ be nontrivial Dirichlet characters modulo $m$ and $n$ respectively and let $b \in \Z$. Then the following hold:
          \begin{enumerate}[label=(\roman*)]
            \item $\conj{\tau(b,\cchi)} = \chi(-1)\tau(b,\chi)$.
            \item If $(b,m) = 1$, then $\tau(b,\chi) = \cchi(b)\tau(\chi)$.
            \item If $(b,m) > 1$ and $\chi$ is primitive, then $\tau(b,\chi) = 0$.
            \item If $(m,n) = 1$, then $\tau(b,\chi\psi) = \chi(n)\psi(m)\tau(b,\chi)\tau(b,\psi)$.
            \item Let $q$ be the conductor of $\chi$ and let $\wtilde{\chi}$ be the primitive Dirichlet character that lifts to $\chi$. Then
            \[
              \tau(\chi) = \mu\left(\frac{m}{q}\right)\wtilde{\chi}\left(\frac{m}{q}\right)\tau(\wtilde{\chi}).
            \]
          \end{enumerate}
        \end{proposition}
        \begin{proof}
          We will prove the statements separately.
          \begin{enumerate}[label=(\roman*)]
            \item Observe that $a \to -a$ is an isomorphism of $\Z/m\Z$. Thus
            \begin{align*}
              \conj{\tau(b,\cchi)} &= \conj{\sum_{a \tmod{m}}\cchi(a)e^{\frac{2\pi iab}{m}}} \\
              &= \sum_{a \tmod{m}}\chi(a)e^{-\frac{2\pi iab}{m}} \\
              &= \sum_{a \tmod{m}}\chi(-a)e^{\frac{2\pi iab}{m}} \\
              &= \chi(-1)\sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi iab}{m}} \\
              &= \chi(-1)\tau(b,\chi),
            \end{align*}
            and (i) follows.
            \item The map $a \to a\conj{b}$ is an isomorphism of $\Z/m\Z$ since $(b,m) = 1$. Therefore
            \[
              \tau(b,\chi) = \sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi iab}{m}} = \sum_{a \tmod{m}}\chi(a\conj{b})e^{\frac{2\pi ia}{m}} = \cchi(b)\sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi ia}{m}} = \cchi(b)\tau(\chi),
            \]
            and (ii) is proven.
            \item Now fix a divisor $d < m$ of $m$ and choose an integer $c$ such that $c \equiv 1 \tmod{m}$. Then necessarily $(c,m) = 1$. As $d \mid m$, $c \equiv 1 \tmod{d}$ and $(c,d) = 1$. Moreover, there is such a $c$ with the additional property that $\chi(c) \neq 1$. For if not, $\chi$ is induced from $\chi_{d,0}$ which contradicts $\chi$ being primitive. Now set $d = \frac{m}{(b,m)} < m$ and choose $c$ as above. Since $(c,m) = 1$, $a \to a\conj{c}$ is a bijection on $\Z/m\Z$, so that
            \[
              \chi(c)\tau(b,\chi) = \sum_{a \tmod{m}}\chi(ac)e^{\frac{2\pi iab}{m}} = \sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi iab\conj{c}}{m}}.
            \]
            As $e^{\frac{2\pi ib}{m}}$ is a $d$-th root of unity, and $\conj{c} \equiv 1 \tmod{d}$ (because $c$ is and $d \mid m$) we have $e^{\frac{2\pi iab\conj{c}}{m}} = e^{\frac{2\pi iab}{m}}$. Thus the last sum above is $\tau(b,\chi)$. So altogether $\chi(c)\tau(b,\chi) = \tau(b,\chi)$. Since $\chi(c) \neq 1$, we conclude $\tau(b,\chi) = 0$ proving (iii).

            There exists some integer $c$ with $(c,m) = 1$ such that $\chi(c) \neq 1$, for if not $\chi$ would be principal modulo $m \ge 2$ and therefore not primitive.

            \item Since $(m,n) = 1$, the Chinese remainder theorem implies that $(\Z/m\Z) \x (\Z/n\Z) \cong (\Z/mn\Z)$ via the isomorphism $(a,b) \to an+a'm$ with $a$ taken modulo $m$ and $a'$ taken modulo $n$. Therefore
            \begin{align*}
              \tau(b,\chi\psi) &= \sum_{an+a'm \tmod{mn}}\chi\psi(an+a'm)e^{\frac{2\pi i(an+a'm)b}{mn}} \\
              &= \sum_{a\tmod{m}}\sum_{a'\tmod{n}}\chi\psi(an+a'm)e^{\frac{2\pi i(an+a'm)b}{mn}} \\
              &= \sum_{a\tmod{m}}\sum_{a'\tmod{n}}\chi(an+a'm)\psi(an+a'm)e^{\frac{2\pi i(an+a'm)b}{mn}} \\
              &= \sum_{a\tmod{m}}\sum_{a'\tmod{n}}\chi(an)\psi(a'm)e^{\frac{2\pi i(an+a'm)b}{mn}} \\
              &= \chi(n)\psi(m)\sum_{a\tmod{m}}\sum_{a'\tmod{n}}\chi(a)\psi(a')e^{\frac{2\pi iab}{m}}e^{\frac{2\pi ia'b}{n}} \\
              &= \chi(n)\psi(m)\sum_{a\tmod{m}}\chi(a)e^{\frac{2\pi iab}{m}}\sum_{a'\tmod{n}}\psi(a')e^{\frac{2\pi ia'b}{n}} \\
              &= \chi(n)\psi(m)\tau(b,\chi)\tau(b,\psi).
            \end{align*}
            This proves (iv).
            \item If $\left(\frac{m}{q},q\right) > 1$, then $\wtilde{\chi}\left(\frac{m}{q}\right) = 0$ so we need to show $\tau(\chi) = 0$. As $\left(\frac{m}{q},q\right) > 1$, there exists a prime $p$ such that $p \mid \frac{m}{q}$ and $p \mid q$. By Euclidean division we may write any $a$ modulo $m$ in the form $a = a'\frac{m}{p}+a''$ with $a'$ taken modulo $p$ and $a''$ taken modulo $\frac{m}{p}$. Then
            \begin{equation}\label{equ:Gauss_sum_reduction_1}
              \tau(\chi) = \sum_{a \tmod{m}}\chi(a)e^{\frac{2\pi ia}{m}} = \sum_{\substack{a' \tmod{p} \\ a'' \tmod{\frac{m}{p}}}}\chi\left(a'\frac{m}{p}+a''\right)e^{\frac{2\pi i\left(a'\frac{m}{p}+a''\right)}{m}}.
            \end{equation}
            Since $p \mid \left(\frac{m}{q},q\right)$, we have $p^{2} \mid m$. Therefore $\left(a'\frac{m}{p}+a'',m\right) = 1$ if and only if $\left(a'\frac{m}{p}+a'',\frac{m}{p}\right) = 1$ and this latter condition is equivalent to $\left(a'',\frac{m}{p}\right) = 1$. Thus the last sum in \cref{equ:Gauss_sum_reduction_1} is
            \[
              \sum_{\substack{a' \tmod{p} \\ a'' \tmod{\frac{m}{p}} \\ \left(a'',\frac{m}{p}\right) = 1}}\chi\left(a'\frac{m}{p}+a''\right)e^{\frac{2\pi i\left(a'\frac{m}{p}+a''\right)}{m}}.
            \]
            As $p \mid \frac{m}{q}$, we know $q \mid \frac{m}{p}$ so that $a'\frac{m}{p}+a'' \equiv a'' \tmod{q}$. Then \cref{prop:Dirichlet_character_induction_classification} implies $\chi\left(a'\frac{m}{p}+a''\right) = \wtilde{\chi}(a'')$ and this sum is further reduced to
            \begin{equation}\label{equ:Gauss_sum_reduction_2}
              \psum_{a'' \tmod{\frac{m}{p}}}\wtilde{\chi}(a'')e^{\frac{2\pi ia''}{m}}\sum_{a' \tmod{p}}e^{\frac{2\pi ia'}{p}}.
            \end{equation}
          \end{enumerate}
          The inner sum in \cref{equ:Gauss_sum_reduction_2} vanishes since it is the sum over all $p$-th roots of unity and thus $\tau(\chi) = 0$. Now suppose $\left(\frac{m}{q},q\right) = 1$. Then (iv) implies
          \[
            \tau(\chi) = \tau(\wtilde{\chi}\chi_{\frac{m}{q},0}) = \wtilde{\chi}\left(\frac{m}{q}\right)\chi_{\frac{m}{q},0}(q)\tau(\wtilde{\chi})\tau(\chi_{\frac{m}{q},0}) = \tau(\chi_{\frac{m}{q},0})\wtilde{\chi}\left(\frac{m}{q}\right)\tau(\wtilde{\chi}).
          \]
          Now observe that $\tau(\chi_{\frac{m}{q},0}) = r\left(1;\frac{m}{q}\right)$. By \cref{prop:Ramanujan_sum_evaluation} we see that $r\left(1;\frac{m}{q}\right) = \mu\left(\frac{m}{q}\right)$ and (v) follows.
        \end{proof}

        Notice that \cref{prop:Gauss_sum_reduction} reduces the evaluation of the Gauss sum $\tau(b,\chi)$ to that of $\tau(\chi)$ at least when $\chi$ is primitive. When $\chi$ is not primitive and $(b,m) > 1$ we need to appeal to evaluating $\tau(b,\chi)$ by more direct means. Evaluating $\tau(\chi)$ for general characters $\chi$ turns out to be a very difficult problem and is still open. However, it is not difficult to determine the modulus of $\tau(\chi)$ when $\chi$ is primitive:

        \begin{theorem}\label{thm:Gauss_sum_modulus}
          Let $\chi$ be a primitive Dirichlet character of conductor $q$. Then
          \[
            |\tau(\chi)| = \sqrt{q}.
          \]
        \end{theorem}
        \begin{proof}
          If $\chi$ is the trivial character this is obvious since $\tau(\chi) = 1$. So we may assume $\chi$ is nontrivial. Now this is just a computation:
          \begin{align*}
            |\tau(\chi)|^{2} &= \tau(\chi)\conj{\tau(\chi)} \\
            &= \sum_{a \tmod{q}}\tau(\chi)\cchi(a)e^{-\frac{2\pi ia}{q}} \\
            &=  \sum_{a \tmod{q}}\tau(a,\chi)e^{-\frac{2\pi ia}{q}} & \text{\cref{prop:Gauss_sum_reduction} (i) and (ii)} \\
            &= \sum_{a \tmod{q}}\left(\sum_{a' \tmod{q}}\chi(a')e^{\frac{2\pi iaa'}{q}}\right)e^{-\frac{2\pi ia}{q}} \\
            &= \sum_{a,a' \tmod{q}}\chi(a')e^{\frac{2\pi ia(a'-1)}{q}} \\
            &= \sum_{a' \tmod{q}}\chi(a')\left(\sum_{a \tmod{q}}e^{\frac{2\pi ia(a'-1)}{q}}\right).
          \end{align*}
          Let $S(a')$ denote the inner sum. For the $a'$ such that $a'-1 \equiv 0 \tmod{q}$, $S(a') = q$. Otherwise $a \to a\conj{(a'-1)}$ is a bijection on $\Z/q\Z$ ($q \neq 1$ because $\chi$ is nontrivial) so that $S(a') = 0$ because it is the sum of all $q$-th roots of unity. It follows that the double sum is $\chi(1)q = q$. So altogether $|\tau(\chi)|^{2} = q$ and hence $|\tau(\chi)| = \sqrt{q}$.
        \end{proof}

        As an almost immediate corollary to \cref{thm:Gauss_sum_modulus}, we deduce a useful expression for primitive Dirichlet characters of conductor $q$ in terms of additive characters on $(\Z/q\Z)$:

        \begin{corollary}\label{cor:gauss_sum_primitive_formula}
          Let $\chi$ be a primitive Dirichlet character of conductor $q$. Then
          \[
            \tau(n,\chi) = \cchi(n)\tau(\chi),
          \]
          for all $n \in \Z$. In particular,
          \[
            \chi(n) = \frac{1}{\tau(\cchi)}\sum_{a \tmod{q}}\cchi(a)e^{\frac{2\pi ian}{q}},
          \]
          for all $n \in \Z$.
        \end{corollary}
        \begin{proof}
          If $\chi$ is the trivial character this is obvious since $\tau(n,\chi) = 1$. So assume $\chi$ is nontrivial. If $(n,q) = 1$, then the first identity is \cref{prop:Gauss_sum_reduction} (ii). If $(n,q) > 1$, then the first identity follows from \cref{prop:Gauss_sum_reduction} (iii) and that $\cchi(n) = 0$. This proves the first identity in full. For the second identity, first note that $\tau(\chi) \neq 0$ by \cref{thm:Gauss_sum_modulus}. Replacing $\chi$ with $\cchi$, dividing the first identity by $\tau(\chi)$, and expanding the Gauss sum, gives the second identity.
        \end{proof}

        In light of \cref{thm:Gauss_sum_modulus} we define the \textbf{epsilon factor}\index{epsilon factor} $\e_{\chi}$ for a Dirichlet character $\chi$ modulo $m$ by
        \[
          \e_{\chi} = \frac{\tau(\chi)}{\sqrt{m}}.
        \]
        \cref{thm:Gauss_sum_modulus} says that this value lies on the unit circle when $\chi$ is primitive and not the trivial character. In any case, the question of the evaluation of Gauss sums further boils down to determining what value the epsilon factor is. This is the real difficultly as the epsilon factor is very hard to calculate and its value is not known for general Dirichlet characters. When $\chi$ is primitive, there is a simple relationship between $\e_{\chi}$ and $\e_{\cchi}$:

        \begin{proposition}\label{prop:epsilon_factor_relationship}
          Let $\chi$ be a primitive Dirichlet character of conductor $q$. Then
          \[
            \e_{\chi}\e_{\cchi} = \chi(-1).
          \]
        \end{proposition}
        \begin{proof}
          If $\chi$ is trivial this is obvious since $\e_{\chi} = \e_{\cchi} = 1$. So assume $\chi$ is nontrivial. By \cref{prop:Gauss_sum_reduction} (iii) and that $\e_{\chi}$ lies on the unit circle,
          \[
            \e_{\chi} = \frac{\tau(\chi)}{\sqrt{q}} = \chi(-1)\conj{\frac{\tau(\chi)}{\sqrt{q}}} = \chi(-1)\e_{\cchi}^{-1},
          \]
          from whence the statement follows.
        \end{proof}
      \subsection*{Quadratic Gauss Sums}
        Another class of sums is a generalization of the Gauss sum in the case where the Dirichlet character is quadratic and given by the Jacobi symbol. For a positive integer $m$ and any $b \in \Z$, the \textbf{quadratic Gauss sum}\index{quadratic Gauss sum} $g(b,m)$ is defined by
        \[
          g(b,m) = \sum_{a \tmod{m}}e^{\frac{2\pi ia^{2}b}{m}}.
        \]
        If $b = 1$ we write $g(m)$ instead. That is, $g(m) = g(1,m)$. Our language is somewhat abusive since if $\chi_{m}$ is the quadratic Dirichlet character given by the Jacobi symbol, then we have the two quadratic Gauss sums $\tau(b,\chi_{m})$ and $g(b,m)$. It turns out that $\tau(b,\chi_{m}) = g(b,m)$ if $m$ is square-free. This will take a little work to prove. We first reduce to the case when $(b,m) = 1$:

        \begin{proposition}\label{prop:quadratic_Gauss_sum_relatively_prime_reduction}
          Let $m$ be a positive odd integer and let $b \in \Z$. Then
          \[
            g(b,m) = (b,m)g\left(\frac{b}{(b,m)},\frac{m}{(b,m)}\right).
          \]
        \end{proposition}
        \begin{proof}
          By Euclidean division write any $a$ modulo $m$ in the form $a = a'\frac{m}{(b,m)}+a''$ with $a'$ take modulo $(b,m)$ and $a''$ take modulo $\frac{m}{(b,m)}$. Then
          \begin{align*}
            g(b,m) &= \sum_{a \tmod{m}}e^{\frac{2\pi ia^{2}b}{m}} \\
            &= \sum_{\substack{a' \tmod{(b,m)} \\ a'' \tmod{\frac{m}{(b,m)}}}}e^{\frac{2\pi i\left(a'\frac{m}{(b,m)}+a''\right)^{2}b}{m}} \\
            &= \sum_{a'' \tmod{\frac{m}{(b,m)}}}e^{\frac{2\pi i(a'')^{2}b}{m}}\sum_{a' \tmod{(b,m)}}e^{\frac{2\pi i\left(2a''a'\frac{m}{(b,m)}+\left(a'\frac{m}{(b,m)}\right)^{2}\right)b}{m}} \\
            &= \sum_{a'' \tmod{\frac{m}{(b,m)}}}e^{\frac{2\pi i(a'')^{2}\frac{b}{(b,m)}}{\frac{m}{(b,m)}}}\sum_{a' \tmod{(b,m)}}e^{\frac{2\pi i\left(2a''a'\frac{m}{(b,m)}+\left(a'\frac{m}{(b,m)}\right)^{2}\right)\frac{b}{(b,m)}}{\frac{m}{(b,m)}}} \\
            &= (b,m)\sum_{a'' \tmod{\frac{m}{(b,m)}}}e^{\frac{2\pi i(a'')^{2}\frac{b}{(b,m)}}{\frac{m}{(b,m)}}},
          \end{align*}
          where the last line follows because $\left(2a''a'\frac{m}{(b,m)}+\left(a'\frac{m}{(b,m)}\right)^{2}\right) \equiv 0 \tmod{\frac{m}{(b,m)}}$ and thus the second sum is $(b,m)$. The remaining sum is $g\left(\frac{b}{(b,m)},\frac{m}{(b,m)}\right)$ which finishes the proof.
        \end{proof}

        As a consequence of \cref{prop:quadratic_Gauss_sum_relatively_prime_reduction}, we may always assume $(b,m) = 1$. Now we give an equivalent formulation of the Gauss sum attached to quadratic characters given by Jacobi symbols and show that in the case $m = p$ an odd prime, our two notions of quadratic Gauss sums agree:

        \begin{proposition}\label{prop:Gauss_sum_equivalence_for_primes}
          Let $m$ be a positive odd integer and let $b \in \Z$ such that $(b,m) = 1$. Also let $\chi_{m}$ be the quadratic Dirichlet character given by the Jacobi symbol. Then
          \[
            \tau(b,\chi_{m}) = \sum_{a \tmod{m}}\left(1+\legendre{a}{m}\right)e^{\frac{2\pi iab}{m}}.
          \]
          Moreover, when $m = p$ is prime,
          \[
            \tau(b,\chi_{p}) = g(b,p).
          \]
        \end{proposition}
        \begin{proof}
          If $m = 1$ the claim is obvious since $\tau(b,\chi_{1}) = 1$ so assume $m > 1$. To prove the first statement, observe
          \[
            \sum_{a \tmod{m}}\left(1+\legendre{a}{m}\right)e^{\frac{2\pi iab}{m}} = \sum_{a \tmod{m}}e^{\frac{2\pi iab}{m}}+\sum_{a \tmod{m}}\legendre{a}{m}e^{\frac{2\pi iab}{m}}.
          \]
          The first sum on the right-hand side is zero as it is the sum over all $m$-th roots of unity since $(b,m) = 1$. This proves the first claim. Now let $m = p$ be an odd prime. From the definition of the Jacobi symbol we see that $1+\tlegendre{a}{p} = 2,0$ depending on if $a$ is a quadratic residue modulo $p$ or not provided $a \not\equiv 0 \tmod{p}$. If $a \equiv 0 \tmod{p}$, then $1+\tlegendre{a}{p} = 1$. Moreover, if $a$ is a quadratic residue modulo $p$, then $a \equiv (a')^{2} \tmod{p}$ for some $a'$. So one the one hand,
          \[
            \tau(b,\chi_{p}) = \sum_{a \tmod{p}}\left(1+\legendre{a}{p}\right)e^{\frac{2\pi iab}{p}} = 1+2\sum_{\substack{a \tmod{p} \\ a \equiv (a')^{2} \tmod{p} \\ a \not\equiv 0 \tmod{p}}}e^{\frac{2\pi i(a')^{2}b}{p}}.
          \]
          On the other hand,
          \[
            g(b,p) = 1+\sum_{\substack{a \tmod{p} \\ a \not\equiv 0 \tmod{p}}}e^{\frac{2\pi ia^{2}b}{p}},
          \]
          but this last sum counts every quadratic residue twice because $(-a)^{2} = a^{2}$. Hence the two previous sums are equal.
        \end{proof}

        \cref{prop:Gauss_sum_equivalence_for_primes} gives an equivalence between our two notions of quadratic Gauss sums, but we would like a similar result when $m$ is square-free. In this direction, a series of reduction properties will be helpful:

        \begin{proposition}\label{prop:quadratic_Gauss_sum_reduction}
          Let $m$ and $n$ be positive integers, $p$ be an odd prime, and let $b \in \Z$. Then the following hold:
          \begin{enumerate}[label=(\roman*)]
            \item If $(b,p) = 1$, then $g(b,p^{r}) = pg(b,p^{r-2})$ for all $r \in \Z$ with $r \ge 2$.
            \item If $(m,n) = 1$ and $(b,mn) = 1$, then $g(b,mn) = g(bn,m)g(bm,n)$.
            \item If $m$ is odd and $(b,m) = 1$, then $g(b,m) = \tlegendre{b}{m}g(m)$ where $\tlegendre{b}{m}$ is the Jacobi symbol.
          \end{enumerate}
        \end{proposition}
        \begin{proof}
          We will prove the statements separately.
          \begin{enumerate}[label=(\roman*)]
            \item First notice that
            \[
              g(b,p^{r}) = \sum_{a \tmod{p^{r}}}e^{\frac{2\pi ia^{2}b}{p^{r}}} = \psum_{a \tmod{p^{r}}}e^{\frac{2\pi ia^{2}b}{p^{r}}}+\sum_{a \tmod{p^{r-1}}}e^{\frac{2\pi ia^{2}b}{p^{r-2}}},
            \]
            since every $a$ modulo $p$ satisfies $(a,p) = 1$ or not. By Euclidean division every element $a$ modulo $p^{r-1}$ is of the form $a = a'p^{r-2}+a''$ with $a'$ taken modulo $p$ and $a''$ taken modulo $p^{r-2}$. Since $(a'p^{r-2}+a'') \equiv a'' \tmod{p^{r-2}}$, every $a''$ is counted $p$ times modulo $p^{r-2}$. Along with the fact that $(a'p^{r-2}+a'')^{2} \equiv (a'')^{2} \tmod{p^{r-2}}$, these facts give the middle equality in the following chain:
            \[
              \sum_{a \tmod{p^{r-1}}}e^{\frac{2\pi ia^{2}b}{p^{r-2}}} = \sum_{\substack{a' \tmod{p} \\ a'' \tmod{p^{r-2}}}}e^{\frac{2\pi i\left(a'p^{r-2}+a''\right)^{2}b}{p^{r-2}}} = p\sum_{a'' \tmod{p}}e^{\frac{2\pi i(a'')^{2}b}{p^{r-2}}} = pg(b,p^{r-2}).
            \]
            It remains to show
            \[
              \psum_{a \tmod{p^{r}}}e^{\frac{2\pi ia^{2}b}{p^{r}}},
            \]
            is zero. This sum is exactly $r(b;p^{r})$ so by \cref{prop:Ramanujan_sum_evaluation}, and that $(b,p) = 1$, we conclude
            \[
              \psum_{a \tmod{p^{r}}}e^{\frac{2\pi ia^{2}b}{p^{r}}} = \mu(p^{r}) = 0,
            \]
            because $r \ge 2$. This proves (i).
            \item Observe
              \[
                g(bn,m)g(bm,n) = \left(\sum_{a \tmod{m}}e^{\frac{2\pi ia^{2}bn}{m}}\right)\left(\sum_{a' \tmod{n}}e^{\frac{2\pi i(a')^{2}bm}{n}}\right) = \sum_{\substack{a \tmod{m} \\ a' \tmod{n}}}e^{\frac{2\pi i\left((an)^{2}+(a'm)^{2}\right)b}{mn}}.
              \]
              Note that $e^{\frac{2\pi i\left((an)^{2}+(a'm)^{2}\right)b}{mn}}$ only depends upon $(an)^{2}+(a'm)^{2}$ modulo $mn$. Clearly $(an+a'm)^{2} \equiv (an)^{2}+(a'm)^{2} \tmod{mn}$, so set $a'' = an+a'm$ taken modulo $mn$. Since $(m,n) = 1$, the Chinese remainder theorem implies that $(\Z/m\Z) \x (\Z/n\Z) \cong (\Z/mn\Z)$ via the isomorphism $(a,a') \to an+a'm$. Thus the last sum above is equal to
              \[
                \sum_{a'' \tmod{mn}}e^{\frac{2\pi i(a'')^{2}b}{mn}},
              \]
              which is precisely $g(b,mn)$. So (ii) is proven.
            \item The claim is obvious if $m = 1$ because $g(b,1) = 1$ so assume $m > 1$. If $m = p$, then \cref{prop:Gauss_sum_equivalence_for_primes}, \cref{prop:Gauss_sum_reduction} (ii), and that quadratic characters are their own conjugate altogether imply the claim. Now let $r \ge 1$ and assume by strong induction that the claim holds when $m = p^{r'}$ for all positive integers $r'$ such that $r' < r$. Then by (i), we have
            \begin{equation}\label{equ:quadratic_Gauss_sum_reduction_1}
              g(b,p^{r}) = pg(b,p^{r-2}) = \legendre{b}{p^{r-2}}pg(p^{r-2}) = \legendre{b}{p^{r-2}}g(p^{r}) = \legendre{b}{p^{r}}g(p^{r}).
            \end{equation}
            It now suffices to prove the claim when $m = p^{r}q^{s}$ where $q$ is another odd prime and $s \ge 1$. Then by (ii) and \cref{equ:quadratic_Gauss_sum_reduction_1}, we compute
            \begin{align*}
              g(b,p^{r}q^{s}) &= g(bq^{s},p^{r})g(bp^{r},q^{s}) \\
              &= \legendre{bq^{s}}{p^{r}}\legendre{bp^{r}}{q^{s}}g(p^{r})g(q^{s}) \\
              &= \legendre{b}{p^{r}}\legendre{q^{s}}{p^{r}}\legendre{b}{q^{s}}\legendre{p^{r}}{q^{s}}g(p^{r})g(q^{s}) \\
              &= \legendre{b}{p^{r}q^{s}}\legendre{q^{s}}{p^{r}}\legendre{p^{r}}{q^{s}}g(p^{r})g(q^{s}) \\
              &= \legendre{b}{p^{r}q^{s}}g(q^{s},p^{r})g(p^{r},q^{s}) \\
              &= \legendre{b}{p^{r}q^{s}}g(p^{r}q^{s}).
            \end{align*}
            This proves (iii).
          \end{enumerate}
        \end{proof}

        At last we can prove when our two notions of quadratic Gauss sums agree:

        \begin{theorem}
          Suppose $m$ is a positive square-free odd integer and let $\chi_{m}$ be the quadratic Dirichlet character given by the Jacobi symbol. Let $b \in \mathbb{Z}$ such that $(b,m) = 1$. Then
          \[
            \tau(b,\chi_{m}) = g(b,m).
          \]
        \end{theorem}
        \begin{proof}
          The claim is obvious if $m = 1$ because $\tau(b,\chi_{1}) = 1$ and $g(b,1) = 1$ so assume $m > 1$. Since $\chi_{m}$ is quadratic, it suffices to prove the claim when $b = 1$ by \cref{prop:Gauss_sum_reduction} (ii) and \cref{prop:quadratic_Gauss_sum_reduction} (iii). Now let $m = p_{1}p_{2} \cdots p_{k}$ be the prime decomposition of $m$. Repeated application of \cref{prop:Gauss_sum_reduction} (iv) gives the first equality in the chain
          \begin{align*}
            \tau(\chi) &= \prod_{1 \le i < j \le k}\chi_{p_{i}}(p_{j})\chi_{p_{j}}(p_{i})\tau(\chi_{p_{i}})\tau(\chi_{p_{j}}) \\
            &= \prod_{1 \le i < j \le k}\chi_{p_{i}}(p_{j})\chi_{p_{j}}(p_{i})g(p_{i})g(p_{j}) \\
            &= \prod_{1 \le i < j \le k}g(p_{j},p_{i})g(p_{i},p_{j}) \\
            &= g(q).
          \end{align*}
          This proves the claim.
        \end{proof}

        Now let's turn to \cref{prop:quadratic_Gauss_sum_reduction} and the evaluation of the quadratic Gauss sum. \cref{prop:quadratic_Gauss_sum_reduction} (ii) and (iii) reduce the evaluation of $g(b,m)$ for odd $m$ and $(b,m) = 1$ to computing $g(p)$ for $p$ an odd prime. As with the Gauss sum, it is not difficult to compute the modulus of the quadratic Gauss sum:

        \begin{theorem}\label{thm:quadratic_Gauss_sum_modulus}
          Let $m$ be a positive odd integer. Then
          \[
            |g(m)| = \sqrt{m}.
          \]
        \end{theorem}
        \begin{proof}
          By \cref{prop:quadratic_Gauss_sum_reduction} (ii), it suffices to prove this when $m = p^{r}$ is a power of an odd prime. By Euclidean division write $r = 2n+r'$ for some positive integer $n$ and with $r' = 0,1$ depending on if $r$ is even or odd respectively. Then \cref{prop:quadratic_Gauss_sum_reduction} (i) implies
          \[
            |g(p^{r})|^{2} = p^{2n}|g(p^{r'})|^{2}.
          \]
          If $r' = 0$, then $2n = r$ so that $p^{2n} = p^{r}$. Thus $|g(p^{r})| = \sqrt{p^{r}}$. If $r' = 1$, then \cref{thm:Gauss_sum_modulus,prop:Gauss_sum_equivalence_for_primes} together imply $|g(p^{r'})|^{2} = p$ so that the right-hand side above is $p^{2n+1} = p^{r}$ and again we have $|g(p^{r})| = \sqrt{p^{r}}$.
        \end{proof}

        Accordingly, we define the \textbf{epsilon factor}\index{epsilon factor} $\e_{m}$ for a positive integer $m$ by
        \[
          \e_{m} = \frac{g(m)}{\sqrt{m}}.
        \]
        \cref{thm:quadratic_Gauss_sum_modulus} says that this value lies on the unit circle when $m$ is odd. Thus the question of the evaluation of quadratic Gauss sums reduces to determining what the epsilon factor is. This was completely resolved and the original proof is due to Gauss in 1808 (see \cite{Gauss1808summatio}). He actually treated the case $m$ is even as well. We have avoided discussing this because we will not need it in the following and many of the previous proofs need to be augmented when $m$ is even (see \cite{lang1994algebraic} for a treatment of the even case). As for the evaluation, one of the cleanest proofs uses analytic techniques (see \cite{lang1994algebraic}) and the precise statement is the following:

        \begin{theorem}\label{thm:Gauss's_evaluation}
          Let $m$ be a positive integer. Then
          \[
            \e_{m} = \begin{cases} (1+i) & \text{if $m \equiv 0 \tmod{4}$}, \\ 1 & \text{if $m \equiv 1 \tmod{4}$}, \\ 0 & \text{if $m \equiv 2 \tmod{4}$}, \\ i & \text{if $m \equiv 3 \tmod{4}$}. \end{cases}
          \]
        \end{theorem}

        As an immediate corollary, this implies the evaluation of the epsilon factor $\e_{\chi_{p}}$ where $\chi_{p}$ is the quadratic Dirichlet character given by the Jacobi symbol for an odd prime $p$:

        \begin{corollary}
          Let $p$ be an odd prime and $\chi_{p}$ be the quadratic Dirichlet character given by the Jacobi symbol. Then
          \[
            \e_{\chi_{p}} = \begin{cases} 1 & \text{if $p \equiv 1 \tmod{4}$}, \\ i & \text{if $p \equiv 3 \tmod{4}$}. \end{cases}
          \]
        \end{corollary}
        \begin{proof}
          The statement follows immediately from \cref{thm:Gauss's_evaluation,prop:Gauss_sum_equivalence_for_primes}.
        \end{proof}
      \subsection*{Kloosterman \& Sali\'e Sums}
        Our last class of sums generalize Ramanujan and Gauss sums. For a positive integer $c$ and any integers $n$ and $m$, the \textbf{Kloosterman sum}\index{Kloosterman sum} $K(n,m;c)$ is defined by
        \[
          K(n,m;c) = \sum_{\substack{a \tmod{c} \\ (a,c) = 1}}e^{\frac{2\pi i(an+\conj{a}m)}{c}} = \psum_{a \tmod{c}}e^{\frac{2\pi i(an+\conj{a}m)}{c}}.
        \]
        Notice that if either $n = 0$ or $m = 0$ then the Kloosterman sum reduces to a Ramanujan sum. Kloosterman sums have similar properties to those of Ramanujan and Gauss sums, but we will not need them. The only result we will need is a famous bound, often called the \textbf{Weil bound}\index{Weil bound} for Kloosterman sums, proved by Weil (see \cite{weil1948some} for a proof):

        \begin{theorem}[Weil bound]
          Let $c$ be a positive integer and $n$ and $m$ be integers. Then
          \[
            |K(n,m;c)| \le \s_{0}(c)\sqrt{(n,m,c)}\sqrt{c},
          \]
          where $\s_{0}(c)$ is the divisor function.
        \end{theorem}

        Lastly, Sali\'e sums are Kloosterman sums with Dirichlet characters. To be precise, for a positive integer $c$, any integers $n$ and $m$, and a Dirichlet character $\chi$ with conductor $q \mid c$, the \textbf{Sali\'e sum}\index{Sali\'e sum} $S_{\chi}(n,m;c)$ is defined by
        \[
          S_{\chi}(n,m;c) = \sum_{\substack{a \tmod{c} \\ (a,c) = 1}}\chi(a)e^{\frac{2\pi i(an+\conj{a}m)}{c}} = \psum_{a \tmod{c}}\chi(a)e^{\frac{2\pi i(an+\conj{a}m)}{c}}.
        \]
        If either $n = 0$ or $m = 0$ then the Sali\'e sum reduces to a Gauss sum.
    \section{Integral Methods \& Transforms}
      \subsection*{Integral Methods}
        Complex integrals are a core backbone of analytic number theory and all too often the domain we are integrating over is unbounded. Accordingly, the functions we would like to work with should be integrable over these domains. One way to accomplish this would be to require that our functions are bounded:

        \begin{method}\label{met:decay_compacta_integral}
          Suppose $f(z,x)$ is analytic on $\W \x D$ for some region $\W$ and we are given an integral
          \[
            \int_{D}f(z,x)\,d\mu,
          \]
          where $D$ is an unbounded domain, $d\mu$ is a measure on $D$, and such that the following hold:
          \begin{enumerate}[label=(\roman*)]
            \item For any $z \in \W$, $f(z,x)$ is bounded on $D$.
            \item $D$ has finite volume with respect to $d\mu$.
          \end{enumerate}
          Then the integral is holomorphic in $z$. By \cref{thm:analytic_integral}, it suffices to show that the integral is locally absolutely uniformly bounded. Let $K$ be a compact subset of $\W$. As $f(z,x)$ is bounded on $D$ for any $z$, $f(z,x)$ is locally absolutely uniformly bounded on $K \x D$. Then
          \[
            \int_{D}f(z,x)\,d\mu \ll \int_{D}\,d\mu \ll 1, 
          \]
          because $D$ has finite volume with respect to $d\mu$. Therefore the integral is  locally absolutely uniformly bounded. 
        \end{method}

        In particular, \cref{met:decay_compacta_integral} holds if $f(z,x)$ admits any type of decay on $D$ for any $z \in \W$. There is also another useful analytic technique called \textbf{shifting the line of integration}\index{shifting the line of integration}:

        \begin{method}[Shifting the line of integration]
          Suppose we are given an integral
          \[
            \int_{\Re(z) = a}f(z)\,dz \quad \text{or} \quad \int_{\Im(z) = a}f(z)\,dz,
          \]
          and some real $b$ with $b < a$ in the first case and $b > a$ in the second case. Also suppose the following conditions hold corresponding to each case:
          \begin{enumerate}[label=(\roman*)]
            \item $f(z)$ is meromorphic on a strip containing the lines $\Re(z) = a,b$ or $\Im(z) = a,b$ respectively.
            \item $f(z)$ is holomorphic about the lines $\Re(z) = a,b$ or $\Im(z) = a,b$ respectively.
            \item $f(z) \to 0$ as $y \to \infty$ or $x \to \infty$ respectively.
          \end{enumerate}
          To collect these cases, let $(a)$ stand for the line $\Re(z) = a$ or $\Im(z) = a$ respectively with positive orientation. Then the line of integration $(a)$ can be shifted to the line of integration $(b)$ with the possible addition of residues. Take a rectangle $R_{T}$ given positive orientation and with its edges on $(a)$ and $(b)$ respectively and consider
          \[
            \lim_{T \to \infty}\int_{R_{T}}f(z)\,dz.
          \]
          On the one hand, the residue theorem implies the integral is a sum of a $2\pi i$ multiple of the residues $r_{i}$ in the rectangle $R_{T}$ and hence the limit is a sum of a $2\pi i$ multiple of the residues in the strip bounded by $(a)$ and $(b)$. Denote the corresponding set of poles inside this strip by $P$. On the other hand, the integral can be decomposed into a sum of four integrals along the edges of $R_{T}$ and by taking the limit the edges other than $(a)$ and $(b)$ will tend to zero because of the assumptions on $f(z)$. The remaining two pieces is the difference between the integral along $(a)$ and $(b)$. So in total,
          \[
            \int_{(a)}f(z)\,dz = \int_{(b)}f(z)\,dz+2\pi i\sum_{\rho \in P}\Res_{z = \rho}f(z).
          \]
        \end{method}

        A particular application of interest is when the integral in question is real and over the entire real line, the integrand is entire as a complex function, and one is trying to shift the line of integration of the complexified integral to $\Im(z) = a$. In this case, shifting the line of integration amounts to making the change of variables $x \to x-ia$ without affecting the initial line of integration.
      \subsection*{The Fourier Transform}
        The first type of integral transform we will need is the Fourier transform. Suppose $f(x)$ is absolutely integrable. The \textbf{Fourier transform}\index{Fourier transform} $\hat{f}(t)$ of $f(x)$ is defined by
        \[
          \hat{f}(t) = \int_{-\infty}^{\infty}f(x)e^{-2\pi itx}\,dx.
        \]
        This integral is absolutely convergent precisely because $f(x)$ is absolutely integrable. As a first application of \cref{met:decay_compacta_integral}, if $f(x)$ is analytic and has exponential decay then its Fourier transform exists. In practical settings however, we usually restrict $f(x)$ to be a \textbf{Schwarz function}\index{Schwarz function} which means that $f(x)$ is smooth and $f^{(n)}(x) = o(x^{c})$ for all $c \in \R$. In other words, $f(x)$ is a smooth function such that it and all of its derivatives have exponential decay. In this case, we say that $f(x)$ is of \textbf{rapid decay}\index{rapid decay}. For example, $e^{-x^{2}}$ is a Schwarz function. Schwarz functions are very important because they are functions for which the \textbf{Poisson summation formula}\index{Poisson summation formula} applies:

        \begin{theorem}[Poisson summation formula]
          Suppose $f(x)$ is a Schwarz function. Then
          \[
            \sum_{n \in \Z}f(n) = \sum_{t \in \Z}\hat{f}(t).
          \]
        \end{theorem}
        \begin{proof}
          Set
          \[
            F(x) = \sum_{n \in \Z}f(x+n).
          \]
          Since $f(x)$ has exponential decay, $F(x)$ is locally absolutely uniformly convergent by the Weierstrass $M$-test. Actually since $f(x)$ is Schwarz, $F(x)$ and all of its derivatives are locally absolutely uniformly convergent. By the uniform limit theorem $F(x)$ is smooth. Since $F(x)$ is also $1$-periodic it admits a Fourier series (see \cref{append:Fourier_Series}). The $t$-th Fourier coefficient of $F(x)$ is
          \begin{align*}
            \hat{F}(t) &= \int_{0}^{1}F(x)e^{-2\pi itx}\,dx \\
            &= \int_{0}^{1}\sum_{n \in \Z}f(x+n)e^{-2\pi itx}\,dx \\
            &= \sum_{n \in \Z}\int_{0}^{1}f(x+n)e^{-2\pi itx}\,dx && \text{DCT} \\
            &= \sum_{n \in \Z}\int_{n}^{n+1}f(x)e^{-2\pi itx}\,dx \\
            &= \int_{-\infty}^{\infty}f(x)e^{-2\pi itx}\,dx && \text{DCT} \\
            &= \hat{f}(t).
          \end{align*}
          Therefore the Fourier series of $F(x)$ is
          \[
            F(x) = \sum_{t \in \Z}\hat{f}(t)e^{2\pi itx}.
          \]
          Setting $x = 0$ gives the desired identity.
        \end{proof}

        The Poisson summation formula is immensely useful (this cannot be overstated). It's sort of like a train in that it takes one where one wants to got to and back when one is done. Our primary application is that the Poisson summation formula will allow us to derive very striking transformation laws which are the key ingredient for analytically continuing many important objects.
      \subsection*{The Mellin Transform}
        Like the Fourier transform, the Mellin transform is another type of integral transform. If $f(x)$ is a continuous function, then the \textbf{Mellin transform}\index{Mellin transform} $F(s)$ of $f(x)$ is given by
        \[
          F(s) = \int_{0}^{\infty}f(x)x^{s}\,\frac{dx}{x}.
        \]
        If $f(x)$ is a sufficiently nice function then the integral will be bounded in some half-plane in $s$. For example, this happens if $f(x)$ has exponential decay and remains bounded as $x \to 0$. In this case, the integral is locally absolutely uniformly bounded for $\s > 0$. If the Mellin transform $F(s)$ is sufficiently nice, then the initial function can be recovered via means of the \textbf{inverse Mellin transform}\index{inverse Mellin transform} $(\mc{M}^{-1}F)(x)$:
        \[
          (\mc{M}^{-1}F)(x) = \frac{1}{2\pi i}\int_{(c)}F(s)x^{-s}\,ds.
        \]
        It is not immediately clear that this integral converges or is independent of $c$. The following theorem makes precise what properties $F(s)$ needs to satisfy and for which $c$ the inverse Mellin transform recovers the original function $f(x)$ (see \cite{debnath2002integral} for a proof):

        \begin{theorem}[Mellin inversion formula]
          Let $a$ and $b$ be reals such that $a < b$. Suppose $F(s)$ is analytic in the strip vertical $a < \s < b$, tends to zero uniformly as $t \to \infty$ along any line $\s = c$ for $a < c < b$, and that the integral of $F(s)$ along this line is locally absolutely uniformly bounded. Then if
          \[
            f(x) = \frac{1}{2\pi i}\int_{(c)}F(s)x^{-s}\,ds,
          \]
          this integral is independent of $c$ and moreover $F(s) = (\mc{M}f)(s)$. Conversely, suppose $f(x)$ is piecewise continuous such that its value is halfway between the limit values at any jump discontinuity and
          \[
            F(s) = \int_{0}^{\infty}f(x)x^{s}\,\frac{dx}{x},
          \]
          is locally absolutely uniformly bounded in the vertical strip $a < \s < b$. Then $f(x) = (\mc{M}^{-1}F)(x)$.
        \end{theorem}
    \section{The Gamma Function}
      The gamma function is ubiquitous in analytic number theory and the better one understands it the better one will be at seeing the forest for the trees in any problem involving analytic number theory. The \textbf{gamma function}\index{gamma function} $\G(s)$ is defined to be the Mellin transform of $e^{-x}$:
      \[
        \G(s) = \int_{0}^{\infty}e^{-x}x^{s-1}\,dx,
      \]
      for $\s > 0$. The integral is locally absolutely uniformly bounded in this region. Indeed, if $K$ is a compact subset in the region $\s > 0$, then upon splitting the integral we have
      \begin{equation}\label{equ:Gamma_integral_bounded_1}
        \G(s) = \int_{0}^{1}e^{-x}x^{s-1}\,dx+\int_{1}^{\infty}e^{-x}x^{s-1}\,dx.
      \end{equation}
      By \cref{met:decay_compacta_integral}, the second integral in \cref{equ:Gamma_integral_bounded_1} is locally absolutely uniformly bounded in this region. As for the first integral, let $\b = \min_{s \in K}\{\s\}$. Then
      \begin{equation}\label{equ:Gamma_integral_bounded_2}
        \int_{0}^{1}e^{-x}x^{s-1}\,dx \ll \int_{0}^{1}x^{\s-1}\,dx \ll_{\b} 1.
      \end{equation}
      \cref{equ:Gamma_integral_bounded_2} implies that the first integral in \cref{equ:Gamma_integral_bounded_1} is locally absolutely uniformly bounded too. Altogether, this means $\G(s)$ is as well. Also note that for $s >0$, $\G(s)$ is real. The most basic properties of $\G(s)$ are the following:

      \begin{proposition}\label{prop:Factorial_properties_of_gamma_function}
        $\G(s)$ satisfies the following properties:
        \begin{enumerate}[label=(\roman*)]
          \item $\G(1) = 1$.
          \item $\G(s+1) = s\G(s)$.
          \item $\G(\conj{s}) = \conj{\G(s)}$.
        \end{enumerate}
      \end{proposition}
      \begin{proof}
        We obtain (i) by direct computation:
        \[
          \G(1) = \int_{0}^{\infty}e^{-x}\,dx = -e^{-x}\bigg|_{0}^{\infty} = 1.
        \]
        An application of integration by parts gives (ii):
        \[
          \G(s+1) = \int_{0}^{\infty}e^{-x}x^{s}\,dx = -e^{-x}x^{s}\bigg|_{0}^{\infty}+s\int_{0}^{\infty}e^{-x}x^{s-1}\,dx = s\int_{0}^{\infty}e^{-x}x^{s-1}\,dx = s\G(s).
        \]
        For (iii), since $\G(s)$ is real for $s >0$ we have $\G(\conj{s}) = \conj{\G(s)}$ on this half-line and then the identity theorem implies that this holds on the entire domain of $\G(s)$.
      \end{proof}

      From \cref{prop:Factorial_properties_of_gamma_function} we see that for $s = n$ a positive integer, $\G(n) = (n-1)!$. So $\G(s)$ can be thought of as a holomorphic extension of the factorial function. We can use property (ii) of \cref{prop:Factorial_properties_of_gamma_function} to extended $\G(s)$ to a meromorphic function on all of $\C$:

      \begin{theorem}\label{thm:continuation_of_gamma_function}
        $\G(s)$ admits meromorphic continuation to $\C$ with poles at $s = -n$ for $n \ge 0$. All of these poles are simple and with residue $\frac{(-1)^{n}}{n!}$ at $s = -n$.
      \end{theorem}
      \begin{proof}
        Using \cref{prop:Factorial_properties_of_gamma_function}, (ii) repeatedly, for any integer $n \ge 0$ we have
        \[
          \G(s) = \frac{\G(s+1+n)}{s(s+1) \cdots (s+n)}.
        \]
        The right-hand side defines an meromorphic function in the region $\s > -n$ and away from the points $0,-1,\ldots,-n$. Letting $n$ be arbitrary, we see that $\G(s)$ has meromorphic continuation to $\C$ with poles at $0,-1,-2,\ldots$. We now compute the residue at $s = -n$. Around this point $\G(s)$ admits meromorphic continuation with representation
        \[
          \frac{\G(s+1+n)}{s(s+1) \cdots (s+n)},
        \]
        where all of the factors except for $s+n$ are holomorphic at $s = -n$. Thus the pole is simple, and
        \[
          \Res_{s = -n}\G(s) = \lim_{z \to -n}\frac{\G(s+1+n)(s+n)}{s(s+1) \cdots (s+n)} = \frac{\G(1)}{(-n)(1-n) \cdots (-1)} = \frac{(-1)^{n}}{n!}.
        \]
      \end{proof}

      In particular, \cref{thm:continuation_of_gamma_function} implies $\Res_{s = 0}\G(s) = 1$ and $\Res_{s = 1}\G(s) = -1$. There are a few other properties of the gamma function that are famous and which we will use frequently. The first of which is the \textbf{Legendre duplication formula}\index{Legendre duplication formula} (see \cite{remmert1998classical} for a proof):

      \begin{theorem}[Legendre duplication formula]
        For any $s \in \C-\{0,-1,-2,\ldots\}$,
        \[
          \G(s)\G\left(s+\frac{1}{2}\right) = 2^{1-2s}\sqrt{\pi}\G(2s).
        \]
      \end{theorem}

      As a first application, we can use this formula to compute $\G\left(\frac{1}{2}\right)$. Letting $z = \frac{1}{2}$ in the Legendre duplication formula and recalling $\G(1) = 1$, we see that $\G\left(\frac{1}{2}\right) = \sqrt{\pi}$. There is also the important Hadamard factorization of the reciprocal of $\G(s)$ (see \cite{stein2003complex} for a proof):

      \begin{proposition}\label{prop:Hadamard_factorization_for_reciprocial_of_gamma}
        For all $s \in \C$,
        \[
          \frac{1}{\G(s)} = se^{\g s}\prod_{n \ge 1}\left(1+\frac{s}{n}\right)e^{-\frac{s}{n}},
        \]
        where $\g$ is the Euler-Mascheroni constant.
      \end{proposition}

      In particular, $\frac{1}{\G(s)}$ is entire so that $\G(s)$ is nowhere vanishing on $\C$. Also, $\frac{1}{\G(s)}$ is of order $1$ (see \cref{append:Factorizations_and_Finite_Order}). In particular, this means that $\G(s)$ is also order $1$ for $\s > 0$. We call $\frac{\G'}{\G}(s)$ the \textbf{digamma function}\index{digamma function}. Equivalently, the digamma function is the logarithmic derivative of the gamma function. If we take the logarithmic derivative of the Hadamard factorization for $\frac{1}{s\G(s)}$, we obtain a useful expression for the digamma function:

      \begin{corollary}\label{cor:logarithmic_derivative_of_gamma}
        For all $s \in \C$,
        \[
          \frac{\G'}{\G}(s+1) = -\g+\sum_{n \ge 1}\left(\frac{1}{n}-\frac{1}{s+n}\right),
        \]
        where $\g$ is the Euler-Mascheroni constant. In particular, the digamma function has simple poles of residue $-1$ at the poles of the gamma function.
      \end{corollary}
      \begin{proof}
        By \cref{prop:Factorial_properties_of_gamma_function} (ii), $\frac{1}{\G(s+1)} = \frac{1}{s\G(s)}$. Taking the logarithmic derivative using \cref{prop:Hadamard_factorization_for_reciprocial_of_gamma} we obtain
        \[
          -\frac{\G'}{\G}(s+1) = \g+\sum_{n \ge 1}\left(\frac{1}{s+n}-\frac{1}{n}\right),
        \]
        provided $s$ is distance $\e$ away from the poles of $\G(s)$. This is the desired formula and the statement regarding the poles follows immediately.
      \end{proof}
      
      We will also require a well-known approximation for the gamma function known as \textbf{Stirling's formula}\index{Stirling's formula} (see \cite{remmert1998classical} for a proof):

      \begin{theorem}[Stirling's formula]
      \phantom{}
        \[
          \G(s) \sim_{\e,\d} \sqrt{2\pi}s^{s-\frac{1}{2}}e^{-s},
        \]
        provided $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$.
      \end{theorem}

      If $\s$ lies inside some compact set then Stirling's formula gives a useful estimate showing that $\G(s)$ exhibits exponential decay as $s \to \infty$:
      
      \begin{corollary}\label{equ:weaker_Stirling_formula}
      Let $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$. Then if $\s$ is bounded, we have
        \[
          \G(s) \sim_{\e,\d} \sqrt{2\pi}t^{\s-\frac{1}{2}}e^{-\frac{\pi}{2}|t|}.
        \]
      \end{corollary}
      \begin{proof}
        Stirling's formula can be equivalently expressed as
        \[
          \G(s) \sim_{\e,\d} \sqrt{2\pi}(\s+it)^{\s-\frac{1}{2}+it}e^{-\s-it}.
        \]
        Since $\s$ is bounded, $e^{-\s-it} \ll 1$ and we obtain the the simplified asymptotic
        \[
          \G(s) \sim_{\e,\d} \sqrt{2\pi}(it)^{\s-\frac{1}{2}+it}.
        \]
        Similarly, $x$ being bounded implies $i^{\s-\frac{1}{2}} \ll 1$ and we compute
        \[
          (it)^{it} = e^{i|t|\log(i|t|)} = e^{i|t|(\log(i)+\log(|t|))} = e^{-\frac{\pi}{2}|t|+i|t|\log(|t|)} \sim e^{-\frac{\pi}{2}|t|},
        \]
        where we have used the fact that $\log(i) = i\frac{\pi}{2}$. Together, we obtain the further simplified asymptotic
        \[
          \G(s) \sim_{\e,\d} \sqrt{2\pi}t^{\s-\frac{1}{2}}e^{-\frac{\pi}{2}|t|},
        \]
        which is the desired result
      \end{proof}
      Strictly weaker than the asymptotic equivalence in Stirling's formula is the estimate
      \begin{equation}
          \G(s) = \sqrt{2\pi}s^{s-\frac{1}{2}}e^{-s}(1+O_{\e,\d}(1)).
      \end{equation}
      Taking the logarithm (since $|\arg(s)| < \pi-\e$ the logarithm is defined) of this estimate gives
      \begin{equation}\label{equ:log_gamma_estimate}
        \log\G(s) = \frac{1}{2}\log(2\pi)+\left(s-\frac{1}{2}\right)\log(s)-s+O_{\e,\d}\left(1\right),
      \end{equation}
      which will be useful. Using \cref{equ:log_gamma_estimate} we can obtain a useful asymptotic formula for the digamma function:

      \begin{proposition}\label{equ:approximtion_for_digamma}
      \[
        \frac{\G'}{\G}(s) = \log(s)+O_{\e,\d}(1),
      \]
      provided $|\arg(s)| < \pi-\e$ and $|s| > \d$ for some $\e,\d > 0$.
      \end{proposition}
      \begin{proof}
        \cref{equ:log_gamma_estimate} give the simplified asymptotic
        \[
          \log\G(s) = \frac{1}{2}\log(2\pi)+s\log(s)-s+O_{\e,\d}(1).
        \]
        Set $g(s) = \frac{1}{2}\log(2\pi)+s\log(s)-s$ so that $\log\G(s) = g(s)+O_{\e,\d}(1)$. Then $\log\G(s)-g(s) = O_{\e,\d}(1)$, and by Cauchy's integral formula, we have
        \begin{align*}
          \frac{\G'}{\G}(s) &= \frac{d}{ds}\left(g(s)+O_{\e,\d}(1)\right) \\
          &= g'(s)+\frac{d}{ds}(\log\G(s)-g(s)) \\
          &= \log(s)+\frac{1}{2\pi i}\int_{|u-s| = \eta}\frac{\log\G(u)-g(u)}{(u-s)^{2}}\,du,
        \end{align*}
        for some sufficiently small radius $\eta > 0$ depending upon $\e$ and $\d$. Therefore
        \[
          \left|\frac{\G'}{\G}(s)-\log(s)\right| \le \frac{1}{2\pi}\int_{|u-s| = \eta}\frac{|\log\G(u)-g(u)|}{\eta^{2}}\,|du| \ll_{\e,d} 1,
        \]
        where the last estimate follows because $\log\G(s)-g(s) = O_{\e,d}(1)$.
      \end{proof}

      The last result we will need is an explicit representation for $\log\G(s)$ known as \textbf{Binet's log gamma formula}\index{Binet's log gamma formula}:

      \begin{proposition}[Binet's log gamma formula]
        \phantom{ }
        \[
          \log\G(s) = \left(s-\frac{1}{2}\right)\G(s)-s+\frac{1}{2}\log(2\pi)+2\int_{0}^{\infty}\frac{\tan^{-1}\left(\frac{x}{s}\right)}{e^{2\pi x}-1}\,dx.
        \]
      \end{proposition}